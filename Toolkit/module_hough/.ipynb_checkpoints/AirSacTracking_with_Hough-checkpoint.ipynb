{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8982f1e",
   "metadata": {},
   "source": [
    "# Module to process video with hough transform\n",
    "\n",
    "This module belongs to the manuscript \"Burchardt, L., van der Sande, Y., Kehy, M., Gamba, M., Ravignani, A., Pouw, W.\". This code takes in an example video and tracks any semi-circular objects in the video using the hough transform. The results folder will contain a video and time series containing the estimate radii and their locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15f17836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import cv2                       #image/video processing\n",
    "import pandas as pd              #data wranlging/csv\n",
    "from skimage import io, feature, color, measure, draw, img_as_float #image processing\n",
    "import numpy as np               #data wrangling\n",
    "import os                        #folder structuring\n",
    "from os.path import isfile, join #for basic file operations\n",
    "from tqdm import tqdm            #for a process bar\n",
    "from IPython.display import Video #for showing a video\n",
    "# set videofolder\n",
    "videofolder = '../input/'\n",
    "outputfolder = './results/'\n",
    "#version 2, using videos #################### loading in the videos\n",
    "vids = [f for f in os.listdir(videofolder) if isfile(join(videofolder, f))]\n",
    "vidlist = []\n",
    "\n",
    "for i in vids: #add the image folder name to get the full path\n",
    "    vidlist.append(videofolder +i) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df7f0351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"https://tsg-131-174-75-200.hosting.ru.nl/samples_airsactoolkit/example8_tracked_rec.mp4\" controls  width=\"600\"  height=\"400\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example video\n",
    "Video('https://tsg-131-174-75-200.hosting.ru.nl/samples_airsactoolkit/example8_tracked_rec.mp4', width=600, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8405b78d",
   "metadata": {},
   "source": [
    "# Main presets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e618d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preset settings preprocessing (thresh 1 and 2 are also weighted and then passed to hough transform)\n",
    "medianblur_preset = 27\n",
    "dilation_preset = 5\n",
    "alpha_preset = 2\n",
    "beta_preset = 30\n",
    "thresh_div_1_preset = 5\n",
    "thresh_div_2_preset = 14\n",
    "\n",
    "# hough presets\n",
    "dp_preset = 1\n",
    "minDist_preset = 10000\n",
    "maxRadius_preset = 270"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544025a3",
   "metadata": {},
   "source": [
    "## Main Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "faf57f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(image, medianblur = medianblur_preset,\n",
    "                              dilation = dilation_preset,\n",
    "                              alpha = alpha_preset,\n",
    "                              beta= beta_preset,\n",
    "                              thresh_div_1= thresh_div_1_preset,\n",
    "                              thresh_div_2= thresh_div_2_preset):\n",
    "    #image0 = hougdraw(image)\n",
    "    #convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    #brightness change\n",
    "    gray = cv2.convertScaleAbs(gray, alpha = alpha, beta = beta)\n",
    "    #set dynamic tresholds for canny (we will also pass this to the hough)\n",
    "    mean_intensity = np.median(gray)\n",
    "    threshold1 = int(max(0, (1.0 - 0.33) * mean_intensity/thresh_div_1))\n",
    "    threshold2 = int(min(255, (1.0 + 0.33) * mean_intensity/thresh_div_2))    \n",
    "    #blur\n",
    "    image2 = cv2.medianBlur(gray, medianblur)\n",
    "    #dynamic thresholds for canny edge detection based on intensity of image\n",
    "    #Thresholds one standard deviation above and below median intensity\n",
    "    #edge detection\n",
    "    image3 = cv2.Canny(image2, threshold1, threshold2)\n",
    "    #dilation and second blur\n",
    "    submitted = cv2.dilate(image3, None, iterations= dilation)  \n",
    "    image4 = cv2.medianBlur(submitted, medianblur) \n",
    "    #add hough\n",
    "    image4 = np.float32(image4)\n",
    "    return image4, threshold1, threshold2\n",
    "\n",
    "def preprocess_hough_apply_to_frame(image, mindist=10000, maxradius=250):\n",
    "    image, param1, param2 = preprocessing(image=image)\n",
    "    image = cv2.normalize(src= image, dst=None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U) \n",
    "    circles = cv2.HoughCircles(image, cv2.HOUGH_GRADIENT,param1 = param1, param2 = param2, dp = dp_preset, minDist = minDist_preset, maxRadius = maxRadius_preset)   \n",
    "    return(circles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6a3fb7",
   "metadata": {},
   "source": [
    "# Loop throuh video folder and process each video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2ab8631",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "Processing example8: 100%|██████████████████████████████████████████████████| 1195/1195 [01:44<00:00, 11.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with processing video example8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "for video in vidlist:\n",
    "    name = os.path.basename(video)[0:-4]\n",
    "    #set up empty output dataframe\n",
    "    column_names = ['frame', # info on region of interest for repetability\n",
    "                            'x','y', 'r', 'namefr', 'sample_rate']# parameters of hough circle transform \n",
    "    df = pd.DataFrame(columns = column_names)  \n",
    "    ####################set up video settings\n",
    "    cap = cv2.VideoCapture(video)                       #set video to capture\n",
    "    frameWidth = cap.get(cv2.CAP_PROP_FRAME_WIDTH)      #frame width\n",
    "    frameHeight = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)    #frame height\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)                     #fps = frames per second\n",
    "    num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) #number of frames\n",
    "            #set up video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V') #for different video formats you could use e.g., *'XVID'\n",
    "    out = cv2.VideoWriter(outputfolder + name + '_tracked.mp4', fourcc, \n",
    "                          fps = fps, frameSize = (int(frameWidth), int(frameHeight)))\n",
    "    ###################loop over frames of the original video\n",
    "    j = 0   #fame counter\n",
    "    \n",
    "    #set up progress bar\n",
    "    with tqdm(total=num_frames, desc=\"Processing \" + name, bar_format=\"{l_bar}{bar:50}{r_bar}\") as pbar:\n",
    "        #the loop over frames (will close when no more frames are left to process)\n",
    "        while(cap.isOpened()):\n",
    "            ret, frame = cap.read()\n",
    "            if ret == False:\n",
    "                break\n",
    "            j=j+1 #add to the frame counter\n",
    "            namefr = 'framenr_' + str(j) + '_framevid_' + os.path.basename(video[0:-4])\n",
    "            ############################detect circles   \n",
    "            to_be_processed_frame=frame.copy() #we keep the original frame\n",
    "            #apply hough\n",
    "            circles = preprocess_hough_apply_to_frame(to_be_processed_frame)        \n",
    "            #draw the circles\n",
    "            if circles is not None:\n",
    "                circles = np.round(circles[0, 0:1]).astype(\"int\")\n",
    "                x = circles[0,0] #x  + plus the shift from the roi\n",
    "                y = circles[0,1] #y  + plus the shift from the roi\n",
    "                r = circles[0,2]\n",
    "                cv2.circle(frame, (x, y), r, (255, 255, 0), 2) #version without drawing roi back on whole image \n",
    "                #save it to a row\n",
    "            if circles is None:\n",
    "                x = \"NA\"\n",
    "                y = \"NA\"\n",
    "                r = \"NA\"\n",
    "            #write frame\n",
    "            out.write(frame) #save the frame to the new masked video\n",
    "            #write x,y,r data\n",
    "            new_row = [j, x, y, r, namefr, fps]\n",
    "            df.loc[len(df)] = new_row\n",
    "            #now update the progress bar\n",
    "            pbar.update(1)\n",
    "        #release video writer\n",
    "        out.release()\n",
    "        cap.release()\n",
    "        #save csv file with the timeseries results\n",
    "        df.to_csv(outputfolder+name+'.csv', sep = ',') \n",
    "    print('done with processing video ' + name)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
