{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b047a8b",
   "metadata": {},
   "source": [
    "# Module to process video DLC model\n",
    "\n",
    "This module belongs to the manuscript \"Burchardt, L., Kehy, M., Gamba, M., Ravignani, A., Pouw, W. A complete computational and data toolkit for the dynamic study of laryngeal air sacs in Siamang (Symphalangus syndactylus) with applications for spherical tracking in other animals\".\n",
    "\n",
    "This contains a module for tracking Siamang head and air sack postures. The following keypoints will be tracked by a trained resnet 101 model:\n",
    "- UpperLip\n",
    "- LowerLip\n",
    "- Nose\n",
    "- EyeBridge\n",
    "- Start_outline_outer_left\n",
    "- Start_outline_outer_right\n",
    "- LowestPoint_outline\n",
    "- MidLowleft_outline\n",
    "- MidLowright_outline\n",
    "\n",
    "Note that Deeplabcut needs to be installed (in command prompt \"pip install -r requirements.txt\"). By default the CPU version is installed. Please see the original documentation of DeepLabCut to ensure GPU compatibility if you want to speed up the tracking process. We do recommend to use a GPU supported deeplabcut.\n",
    "\n",
    "The trained resnet101 model needs to be downloaded first from google drive; so please go to the following folder and follow the download link and download to that folder: \"./AirSacTracker/Toolkit/module_process_video_DLC_model/trained_model_and_metainfo/dlc-models/iteration-0/Deep_AirSacTrackingV1Jan1-trainset95shuffle1/train/\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d17ceed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in the packages\n",
    "import deeplabcut\n",
    "import os\n",
    "import shutil\n",
    "from os.path import isfile, join\n",
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22a52aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model settings\n",
    "config_path = './trained_model_and_metainfo/config.yaml'\n",
    "\n",
    "#where are we going to save our tracked results to?\n",
    "output_dir = './results/'\n",
    "\n",
    "# set videofolder from which we are going to process\n",
    "videofolder = './videos/'\n",
    "\n",
    "#loading in the videos\n",
    "vids = [f for f in os.listdir(videofolder) if isfile(join(videofolder, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50b19cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"./videos/example8.mp4\" controls  width=\"300\"  height=\"200\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first video in the set\n",
    "Video(videofolder+vids[0], width=300, height=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e5cba31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-500000 for model ./trained_model_and_metainfo\\dlc-models\\iteration-0\\Deep_AirSacTrackingV1Jan1-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ResearchTools\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  ./videos/example8.mp4\n",
      "Loading  ./videos/example8.mp4\n",
      "Duration of video [s]:  23.9 , recorded with  50.0 fps!\n",
      "Overall # of frames:  1195  found with (before cropping) frame dimensions:  1920 1080\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▏                                                                          | 48/1195 [03:27<1:22:35,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Starting to process video: ./videos/example8.mp4\n",
      "Loading ./videos/example8.mp4 and data.\n",
      "[WinError 3] The system cannot find the path specified: './results/'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#loop through each video and track using DLC\n",
    "for i in vids: #add the image folder name to get the full path\n",
    "    video_path = videofolder+i\n",
    "    # Analyze the video using the pre-trained model\n",
    "    deeplabcut.analyze_videos(config_path, [video_path], save_as_csv=False, videotype='.mp4', destfolder=output_dir)\n",
    "    # if you only want csv's than you uncomment the next line instead (note though that the labeling from deeplabcut requires .h5 instead of csv)\n",
    "    # deeplabcut.analyze_videos(config_path, [video_path],save_as_csv=False, videotype='.mp4', destfolder=output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c659b49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through each video and create labeled keypoints in the video\n",
    "for i in vids: #add the image folder name to get the full path\n",
    "    video_path = videofolder+i\n",
    "    #copy the original video to the results\n",
    "    shutil.copy2(video_path, output_dir+i)\n",
    "    # Create labeled videos\n",
    "    deeplabcut.create_labeled_video(config_path, [output_dir+i], destfolder=output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
