{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3560a640",
   "metadata": {},
   "source": [
    "# Air Sac Tracking Prototype code\n",
    "Lara S. Burchardt & Wim Pouw\n",
    "\n",
    "lara.burchardt@donders.ru.nl\n",
    "\n",
    "Next to body movements and acoustics, we would also like to track the air sac's inflation of the Siamangs. The air sac naturally forms a spherical(3D) or circular (2D) shape, and such shapes are retrievable from an image using the hough transform, and a bit of pre-processing of the images to get the optimal representation of the relevent edges of the air sac.\n",
    "\n",
    "This code takes as input a sample video with a close up of a Siamang, and then tracks the air sac when it takes a sufficiently circular shape. The result is shown below; it is not perfect, but with a bit of smoothing this can function as a good air sac tracker. This code is very much under development, there are many ways to improve further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6f75694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from skimage import io, feature, color, measure, draw, img_as_float\n",
    "import numpy as np\n",
    "import csv\n",
    "import random2\n",
    "import statistics\n",
    "\n",
    "#resused code from \n",
    "#https://pyimagesearch.com/2014/07/21/detecting-circles-images-using-opencv-hough-circles/\n",
    "#https://stackoverflow.com/questions/31705355/how-to-detect-circlular-region-in-images-and-centre-it-with-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df270ef4",
   "metadata": {},
   "source": [
    "## Circular Tracker\n",
    "\n",
    "First approach: Using a video sample as input, the user first defines a region of interest in which to look for circular objects.\n",
    "After a few pre-processing steps to increase tracking success, the Hough Transform is used to find circles. \n",
    "The radius and position of the circle is saved together with the used parameter combination used in pre-processing and tracking. \n",
    "\n",
    "Optimized approach: run hough circles transform on 50 random images of the video without roi, let tracked data define the roi for the actual tracking --> selfoptimizing the hough transform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0142aa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing, choosing a roi on the tracking results of 50 random samples from input file\n",
    "\n",
    "videofolder= '../Video/'\n",
    "videofilename = 'June12_01.mp4'\n",
    "# Opens the Video file\n",
    "cap = cv2.VideoCapture(videofolder+videofilename)\n",
    "totalFrames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "frameWidth = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "frameHeight = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)   #fps = frames per second\n",
    "\n",
    "\n",
    "#set up empty output dataframe\n",
    "column_names = ['x','y', 'r', 'frame'] # what do we need to save from this?  \n",
    "df_round_1 = pd.DataFrame(columns = column_names)\n",
    "\n",
    "# initialize parameters for pre-processing (used in cv2.convertScaleAbs)\n",
    "alpha = 2 #1.5\n",
    "beta = 20 #30\n",
    "\n",
    "#croppedFrame = frame[int(roi[1]): int(roi[1]+roi[3]),\n",
    "#                     int(roi[0]):int(roi[0]+roi[2])] \n",
    "\n",
    "#we define a sequence of 50 ints first, with random numbers of \"totalFrames\" using sample() because that is sampling without replacement\n",
    "# then we loop over that list of numbers\n",
    "# we need an if to check, whether there is >= 50 frames in the video\n",
    "\n",
    "vector = range(0, int(totalFrames), 1)\n",
    "samp = random2.sample(vector, 46)\n",
    "\n",
    "for rand in samp:\n",
    "  \n",
    "    # set frame position\n",
    "    #samp = samp[rand]\n",
    "    #samp = float(samp)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES,rand)\n",
    "    ret, frame = cap.read()\n",
    "   # do we need to save which frames were used?\n",
    "\n",
    "         \n",
    "    ############################detect circles   \n",
    "    output=frame.copy()\n",
    "    # transform to grayscale image only using the roi part of the image\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    output_gray=gray.copy()\n",
    "    # increasing brightness and contrast\n",
    "    gray_light = cv2.convertScaleAbs(gray, alpha=alpha, beta=beta)\n",
    "    # apply GuassianBlur to reduce noise. medianBlur is also added for smoothening, reducing noise.\n",
    "    gray = cv2.GaussianBlur(gray_light,(11,11),0)\n",
    "    gray = cv2.medianBlur(gray, 19)\n",
    "    ##thresholded edge contouring\n",
    "    hist = cv2.equalizeHist(gray)\n",
    "    gamma = 2\n",
    "    invGamma = 1/gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "                      for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "    gamm = cv2.LUT(hist, table, hist)\n",
    "    submitted = cv2.Canny(gamm, 20, 30)        # was 10 and 50    # why is minVal bigger than maxValue? original code was (gamm, 20, 10)\n",
    "    submitted = cv2.GaussianBlur(submitted,(7,7),0)\n",
    "    submitted = cv2.threshold(submitted, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "    submitted = cv2.dilate(submitted, None, iterations=9)  \n",
    "    submitted = cv2.erode(submitted, None, iterations=10) \n",
    "    submitted = cv2.GaussianBlur(submitted,(7,7),0) \n",
    "    submitted = cv2.erode(submitted, None, iterations=5) #iterations was 4\n",
    "    \n",
    "    #track demicircles \n",
    "    # define parameters for HoughTransform outside of function to be able to save and manipulate easier\n",
    "    \n",
    "    dp = 1\n",
    "    minDist = 10000\n",
    "    param1 = 10\n",
    "    param2 = 22 # war 10\n",
    "    minRadius = 5\n",
    "    maxRadius = 250\n",
    "    \n",
    "    # original values: dp = 1, minDist = 10000, param1=1, param2=10, minRadius = 5, maxRadius= 250\n",
    "    circles = cv2.HoughCircles(submitted, cv2.HOUGH_GRADIENT, \n",
    "                               dp = dp,minDist = minDist,  \n",
    "                               param1 = param1,param2 = param2, \n",
    "                               minRadius = minRadius, maxRadius = maxRadius)\n",
    "    if circles is not None:\n",
    "        circles = np.round(circles[0, 0:1]).astype(\"int\")\n",
    "        #for (x, y, r) in circles:\n",
    "            #cv2.circle(output, (x, y), r, (255, 255, 0), 2) #version without drwaing roi back on whole image\n",
    "        #    cv2.circle(output[int(roi[1]): int(roi[1]+roi[3]),\n",
    "        #             int(roi[0]):int(roi[0]+roi[2])], (x, y), r, (255, 255, 0), 2)\n",
    "        #    cv2.circle(submitted, (x, y), r, (200, 0, 0), 2)\n",
    "            #print(x,y,r)\n",
    "    cv2.waitKey(1)\n",
    "    #out.write(output)\n",
    "    #cv2.imshow(\"output\", submitted)\n",
    "\n",
    "# canny min and max value should be added here, if they turn out to be sensitive\n",
    "    new_row = [circles[0,0], circles[0,1],circles [0,2], rand]\n",
    "    \n",
    "    df_round_1.loc[len(df_round_1)] = new_row\n",
    "    \n",
    "    median_x = df_round_1['x'].median() #order in pos : same as in original dataframe, so x,y, r\n",
    "    median_y = df_round_1['y'].median()\n",
    "    max_r = df_round_1['r'].max()\n",
    "    # order of parameters saved as roi with cv2.selectROI [Top_Left_X, Top_Left_Y, Width, Height]\n",
    "    # if we want to have a consistent syntax with that, we also need those 4 parameters\n",
    "   \n",
    "    # explanation: height_1 is the maximum radius detected plus 20 pixels, that is used to determine the position of the \n",
    "    # upper left corner of the roi, same goes for width_1, both are currently the same, but that could change, so they are both\n",
    "    # coded independently\n",
    "    height_1 = max_r + 20\n",
    "    width_1 = max_r + 20\n",
    "    pos_x = median_x - width_1\n",
    "    pos_y = median_y - height_1\n",
    "    \n",
    "    # to be consistent with the roi nomenclature, we then calculate the width/height of the whole roi which is width_1 *2\n",
    "    # all those values will then be used to crop picture in next round of tracking\n",
    "    \n",
    "    width_2 = width_1 * 2\n",
    "    height_2 = height_1 *2\n",
    "    \n",
    "    \n",
    "            \n",
    "# cleaning up\n",
    "#out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "03df20f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "videofolder= '../Video/'\n",
    "videofilename = 'June12_01.mp4'\n",
    "# Opens the Video file\n",
    "cap = cv2.VideoCapture(videofolder+videofilename)\n",
    "frameWidth = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "frameHeight = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)   #fps = frames per second\n",
    "\n",
    "#output video\n",
    "out = cv2.VideoWriter('./Output/output_'+videofilename,cv2.VideoWriter_fourcc(*'MP4V'), fps, \n",
    "                      (int(frameWidth), int(frameHeight)))\n",
    "\n",
    "#set up empty output dataframe\n",
    "column_names = ['frame','roi_x1','roi_y1','roi_x2', 'roi_y2', # info on region of interest for repetability\n",
    "                'x','y', 'r', 'inputfile',                    # actual results \n",
    "                'alpha', 'beta',                              # values of brightness and contrast pre processing\n",
    "                'dp', 'minDist', 'param1', 'param2', 'minRadius',' maxRadius'] # parameters of hough circle transform \n",
    "df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "#initialize iterator\n",
    "i=0\n",
    "# initialize parameters for pre-processing (used in cv2.convertScaleAbs)\n",
    "alpha = 2 #1.5\n",
    "beta = 20 #30\n",
    "\n",
    "# ROI, define a region of interest by mouse click on the first frame\n",
    "#ret,frame = cap.read()\n",
    "    # select ROI\n",
    "#roi  = cv2.selectROI('select the area', frame)\n",
    "\n",
    "# order of parameters saved as roi with cv2.selectROI [Top_Left_X, Top_Left_Y, Width, Height]\n",
    "#roi = [821, 351, 612, 488]       # if you want to re run a particular roi, input the roi values here\n",
    "\n",
    "#croppedFrame = frame[int(roi[1]): int(roi[1]+roi[3]),\n",
    "#                     int(roi[0]):int(roi[0]+roi[2])] \n",
    "\n",
    "roi = [pos_x, pos_y, width_2, height_2]\n",
    "\n",
    "#main loop                      \n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "          \n",
    "    ############################detect circles   \n",
    "    output=frame.copy()\n",
    "    # transform to grayscale image only using the roi part of the image\n",
    "    gray = cv2.cvtColor(frame[int(roi[1]): int(roi[1]+roi[3]),\n",
    "                     int(roi[0]):int(roi[0]+roi[2])] , cv2.COLOR_BGR2GRAY)\n",
    "    output_gray=gray.copy()\n",
    "    # increasing brightness and contrast\n",
    "    gray_light = cv2.convertScaleAbs(gray, alpha=alpha, beta=beta)\n",
    "    # apply GuassianBlur to reduce noise. medianBlur is also added for smoothening, reducing noise.\n",
    "    gray = cv2.GaussianBlur(gray_light,(11,11),0)\n",
    "    gray = cv2.medianBlur(gray, 19)\n",
    "    ##thresholded edge contouring\n",
    "    hist = cv2.equalizeHist(gray)\n",
    "    gamma = 2\n",
    "    invGamma = 1/gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "                      for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "    gamm = cv2.LUT(hist, table, hist)\n",
    "    submitted = cv2.Canny(gamm, 20, 30)        # was 10 and 50    # why is minVal bigger than maxValue? original code was (gamm, 20, 10)\n",
    "    submitted = cv2.GaussianBlur(submitted,(7,7),0)\n",
    "    submitted = cv2.threshold(submitted, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "    submitted = cv2.dilate(submitted, None, iterations=9)  \n",
    "    submitted = cv2.erode(submitted, None, iterations=10) \n",
    "    submitted = cv2.GaussianBlur(submitted,(7,7),0) \n",
    "    submitted = cv2.erode(submitted, None, iterations=5) #iterations was 4\n",
    "    \n",
    "    #track demicircles \n",
    "    # define parameters for HoughTransform outside of function to be able to save and manipulate easier\n",
    "    \n",
    "    dp = 1\n",
    "    minDist = 10000\n",
    "    param1 = 10\n",
    "    param2 = 22 # war 10\n",
    "    minRadius = 5\n",
    "    maxRadius = 250\n",
    "    \n",
    "    # original values: dp = 1, minDist = 10000, param1=1, param2=10, minRadius = 5, maxRadius= 250\n",
    "    circles = cv2.HoughCircles(submitted, cv2.HOUGH_GRADIENT, \n",
    "                               dp = dp,minDist = minDist,  \n",
    "                               param1 = param1,param2 = param2, \n",
    "                               minRadius = minRadius, maxRadius = maxRadius)\n",
    "    if circles is not None:\n",
    "        circles = np.round(circles[0, 0:1]).astype(\"int\")\n",
    "        for (x, y, r) in circles:\n",
    "            #cv2.circle(output, (x, y), r, (255, 255, 0), 2) #version without drawing roi back on whole image\n",
    "            cv2.circle(output[int(roi[1]): int(roi[1]+roi[3]),\n",
    "                     int(roi[0]):int(roi[0]+roi[2])], (x, y), r, (255, 255, 0), 2)\n",
    "            cv2.circle(submitted, (x, y), r, (200, 0, 0), 2)\n",
    "            #print(x,y,r)\n",
    "    cv2.waitKey(1)\n",
    "    out.write(output)\n",
    "    cv2.imshow(\"output\", submitted)\n",
    "    i=i+1\n",
    "\n",
    "# saving results and used parameters row wise during loop into a dataframe\n",
    "\n",
    "# canny min and max value should be added here, if they turn out to be sensitive\n",
    "    new_row = [i+1, roi[0],roi[1], roi[2], roi[3], circles[0,0], circles[0,1],circles [0,2], videofilename,\n",
    "               alpha, beta, dp, minDist, param1, param2, minRadius, maxRadius]\n",
    "    \n",
    "    df.loc[len(df)] = new_row\n",
    "            \n",
    "# filename and saving dataframe as cvs file       \n",
    "    filename =  'airsacradius_results_' + videofilename + '.csv'\n",
    "    df.to_csv(filename, sep = ',')\n",
    "\n",
    "# cleaning up\n",
    "out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f57d53",
   "metadata": {},
   "source": [
    "# Code to track manually labeled image sequences\n",
    "\n",
    "We can't use the ROI here, as very different images are in the sequence, so that the roi doesn't work.\n",
    "\n",
    "Currently this doesn't work at all, only one example scene (comprised of multiple images) in batch 1 was tracked well\n",
    "\n",
    "## Finding the best parameter combination\n",
    "\n",
    "In this section we try different parameter combinations for pre-processing and tracking to find the parameter combination giving the highest correlation coefficient with the manually tracked results.\n",
    "\n",
    "Parameters to differ:\n",
    "- alpha (0.5;1;1.5;2)\n",
    "- beta  (10,20,30,40,50)\n",
    "- param2 (Hough Transform) (5;10;15;20)\n",
    "- eroding iterations (first time: 6,7,8,9,10,11,12; second time: 2,3,4,5,6)\n",
    "- canny parameters min 5,10,15,20,25,30 max 30,35,40,45,50,55,60\n",
    "\n",
    "### To do:\n",
    "\n",
    "1. combine 24 frames of manually tracked frames into video sequence (without the manuall track), 3 frames from all 6 videos?\n",
    "2. define saving routine\n",
    "3. define loops for different parameter combinations\n",
    "4. calculate correlation coefficients for all combinations and manually tracked radii. (maybe in different program) \n",
    "5. choose 5 parameters spaces with best correlation coefficient, rerun with roi to see whether there is an increase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ccc5d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "videofolder= '../Video/'\n",
    "videofilename = 'video_batch_01.mp4'\n",
    "\n",
    "column_names = ['frame','x','y', 'r', 'inputfile',                                    # actual results \n",
    "                'alpha', 'beta','canny_min', 'canny_max','erode_it_1','erode_it_2',   # values of brightness and contrast pre processing\n",
    "                'param2']                                                             # parameters of hough circle transform \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# constants (define parameters for HoughTransform outside of function to be able to save and manipulate easier)\n",
    "dp = 1\n",
    "minDist = 10000\n",
    "param1 = 10\n",
    "# param2 is defined in loops\n",
    "minRadius = 5\n",
    "maxRadius = 250\n",
    "\n",
    "# set up dataframe to save results \n",
    "global df\n",
    "df = pd.DataFrame(columns = column_names)         \n",
    "\n",
    "# loops for different parameter combinations\n",
    "for alpha in [0.5,1,1.5,2]:\n",
    "#for alpha in [0.5]:\n",
    "    for beta in [10,20,30,40,50,60]:\n",
    "    #for beta in [10]:\n",
    "        for canny_min in [5,10,15,20,25,30]:\n",
    "        #for canny_min in [5]:\n",
    "            for canny_max in [30,35,40,45,50,55,60]:\n",
    "            #for canny_max in [30]:\n",
    "                for erode_it_1 in [6,7,8,9,10,11,12]:\n",
    "                #for erode_it_1 in [10]:\n",
    "                    for erode_it_2 in [2,3,4,5,6]:\n",
    "                    #for erode_it_2 in [2]:                     \n",
    "                        for param2 in [5,10,15,20]:\n",
    "                            # Opens the Video file\n",
    "                            cap = cv2.VideoCapture(videofolder+videofilename)\n",
    "                            frameWidth = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "                            frameHeight = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "                            fps = cap.get(cv2.CAP_PROP_FPS)   #fps = frames per second\n",
    "                            #initialize iterator\n",
    "                            i=0\n",
    "                            while(cap.isOpened()):\n",
    "                                ret, frame = cap.read()\n",
    "                                if ret == False:\n",
    "                                    break\n",
    "                                ############################detect circles   \n",
    "                                output=frame.copy()\n",
    "                                # transform to grayscale image only using the roi part of the image\n",
    "                                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                                output_gray=gray.copy()\n",
    "                                # increasing brightness and contrast\n",
    "                                gray_light = cv2.convertScaleAbs(gray, alpha=alpha, beta=beta)\n",
    "                                # apply GuassianBlur to reduce noise. medianBlur is also added for smoothening, reducing noise.\n",
    "                                gray = cv2.GaussianBlur(gray_light,(11,11),0)\n",
    "                                gray = cv2.medianBlur(gray, 19)\n",
    "                                ##thresholded edge contouring\n",
    "                                hist = cv2.equalizeHist(gray)\n",
    "                                gamma = 2\n",
    "                                invGamma = 1/gamma\n",
    "                                table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "                                                  for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "                                gamm = cv2.LUT(hist, table, hist)\n",
    "                                #submitted = cv2.Canny(gamm, 10, 50)            # why is minVal bigger than maxValue? original code was (gamm, 20, 10)\n",
    "                                submitted = cv2.Canny(gamm, canny_min, canny_max)\n",
    "                                submitted = cv2.GaussianBlur(submitted,(7,7),0)\n",
    "                                submitted = cv2.threshold(submitted, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "                                submitted = cv2.dilate(submitted, None, iterations=9)  \n",
    "                                #submitted = cv2.erode(submitted, None, iterations=10) \n",
    "                                submitted = cv2.erode(submitted, None, iterations=erode_it_1)\n",
    "                                submitted = cv2.GaussianBlur(submitted,(7,7),0) \n",
    "                                #submitted = cv2.erode(submitted, None, iterations=4)\n",
    "                                submitted = cv2.erode(submitted, None, iterations=erode_it_2)\n",
    "\n",
    "                                #track demicircles (note original prototype values: dp = 1, minDist = 10000, param1=1, param2=10, minRadius = 5, maxRadius= 250)                              \n",
    "                                circles = cv2.HoughCircles(submitted, cv2.HOUGH_GRADIENT, \n",
    "                                                           dp = dp,minDist = minDist,  \n",
    "                                                           param1 = param1,param2 = param2, \n",
    "                                                           minRadius = minRadius, maxRadius = maxRadius)\n",
    "                                \n",
    "                                if circles is not None:\n",
    "                                    circles = np.round(circles[0, 0:1]).astype(\"int\")\n",
    "                                cv2.waitKey(1)\n",
    "                                i=i+1\n",
    "\n",
    "                                new_row = [i, circles[0,0], circles[0,1],circles [0,2], videofilename, alpha, beta, canny_min, canny_max,erode_it_1,erode_it_2,param2]\n",
    "                                df.loc[len(df)]=new_row\n",
    "            \n",
    "print('done')\n",
    "#we will save after the loop is done            \n",
    "videofilename_input = videofilename.split('.')[0]\n",
    "#filename =  'sens_analysis_' + str(alpha) + '_' + str(beta) + '_' + str(canny_min)+ '_' + str(canny_max) + '_' + str(erode_it_1) + '_' + str(erode_it_2)+ '_' + str(param2) + '_' + videofilename_input + '.csv'\n",
    "filename = 'sens_analysis_all_comb_' + videofilename_input + '.csv'\n",
    "df.to_csv(filename, sep = ',')\n",
    "\n",
    "# cleaning up\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9717f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROI, define a region of interest by mouse click on the first frame\n",
    "#ret,frame = cap.read()\n",
    "    # select ROI\n",
    "#roi  = cv2.selectROI('select the area', frame)\n",
    "#roi = [821, 351, 612, 488]       # if you want to re run a particular roi, input the roi values here\n",
    "\n",
    "#croppedFrame = frame[int(roi[1]): int(roi[1]+roi[3]),\n",
    "#                     int(roi[0]):int(roi[0]+roi[2])] \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69a7e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do\n",
    "\n",
    "# 1. include timepoints in output\n",
    "#    for each extracted radius, we also want to have the timepoint in the snippet to be able to correlate it with f0 as analyzed \n",
    "#    in praat or else, as we won't have the values for exactly the same timepoints \n",
    "#    for that we need the fps, that we already write, then multiply fps with frame number (should be i?) and write into output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ca8cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9ef6a7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1358.0, 818.0, 528, 528]\n"
     ]
    }
   ],
   "source": [
    "roi = [pos_x, pos_y, width_2, height_2]\n",
    "print(roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2aa0dd98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1920.0\n",
      "1080.0\n"
     ]
    }
   ],
   "source": [
    "print(frameWidth)\n",
    "print(frameHeight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8faa29c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244\n"
     ]
    }
   ],
   "source": [
    "max_r = df_round_1['r'].max()\n",
    "print(max_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2609cfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "<class 'int'>\n",
      "42\n",
      "<class 'int'>\n",
      "4\n",
      "<class 'int'>\n",
      "44\n",
      "<class 'int'>\n",
      "31\n",
      "<class 'int'>\n",
      "19\n",
      "<class 'int'>\n",
      "1\n",
      "<class 'int'>\n",
      "5\n",
      "<class 'int'>\n",
      "27\n",
      "<class 'int'>\n",
      "0\n",
      "<class 'int'>\n",
      "13\n",
      "<class 'int'>\n",
      "18\n",
      "<class 'int'>\n",
      "34\n",
      "<class 'int'>\n",
      "32\n",
      "<class 'int'>\n",
      "6\n",
      "<class 'int'>\n",
      "30\n",
      "<class 'int'>\n",
      "38\n",
      "<class 'int'>\n",
      "15\n",
      "<class 'int'>\n",
      "21\n",
      "<class 'int'>\n",
      "28\n",
      "<class 'int'>\n",
      "33\n",
      "<class 'int'>\n",
      "8\n",
      "<class 'int'>\n",
      "41\n",
      "<class 'int'>\n",
      "35\n",
      "<class 'int'>\n",
      "23\n",
      "<class 'int'>\n",
      "11\n",
      "<class 'int'>\n",
      "12\n",
      "<class 'int'>\n",
      "22\n",
      "<class 'int'>\n",
      "36\n",
      "<class 'int'>\n",
      "37\n",
      "<class 'int'>\n",
      "20\n",
      "<class 'int'>\n",
      "39\n",
      "<class 'int'>\n",
      "17\n",
      "<class 'int'>\n",
      "2\n",
      "<class 'int'>\n",
      "40\n",
      "<class 'int'>\n",
      "16\n",
      "<class 'int'>\n",
      "25\n",
      "<class 'int'>\n",
      "24\n",
      "<class 'int'>\n",
      "9\n",
      "<class 'int'>\n",
      "45\n",
      "<class 'int'>\n",
      "29\n",
      "<class 'int'>\n",
      "10\n",
      "<class 'int'>\n",
      "14\n",
      "<class 'int'>\n",
      "3\n",
      "<class 'int'>\n",
      "43\n",
      "<class 'int'>\n",
      "26\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "vector = range(0, int(totalFrames), 1)\n",
    "samp = random2.sample(vector, 46)\n",
    "\n",
    "for rand in samp:\n",
    "    \n",
    "    print(rand)\n",
    "    print(type(rand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bd8a5ff9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument 'value' can not be treated as a double",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [49]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCAP_PROP_POS_FRAMES\u001b[49m\u001b[43m,\u001b[49m\u001b[43msamp\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: Argument 'value' can not be treated as a double"
     ]
    }
   ],
   "source": [
    "    cap.set(cv2.CAP_PROP_POS_FRAMES,samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2a1878",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
