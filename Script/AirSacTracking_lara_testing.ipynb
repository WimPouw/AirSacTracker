{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ca97fbe",
   "metadata": {},
   "source": [
    "# Air Sac Tracking Prototype code\n",
    "Lara S. Burchardt & Wim Pouw\n",
    "\n",
    "lara.burchardt@donders.ru.nl\n",
    "\n",
    "Next to body movements and acoustics, we would also like to track the air sac's inflation of the Siamangs. The air sac naturally forms a spherical(3D) or circular (2D) shape, and such shapes are retrievable from an image using the hough transform, and a bit of pre-processing of the images to get the optimal representation of the relevent edges of the air sac.\n",
    "\n",
    "This code takes as input a sample video with a close up of a Siamang, and then tracks the air sac when it takes a sufficiently circular shape. The result is shown below; it is not perfect, but with a bit of smoothing this can function as a good air sac tracker. This code is very much under development, there are many ways to improve further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34a7ceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from skimage import io, feature, color, measure, draw, img_as_float\n",
    "import numpy as np\n",
    "import csv\n",
    "import random2\n",
    "import statistics\n",
    "import scipy\n",
    "from scipy import signal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#resused code from \n",
    "#https://pyimagesearch.com/2014/07/21/detecting-circles-images-using-opencv-hough-circles/\n",
    "#https://stackoverflow.com/questions/31705355/how-to-detect-circlular-region-in-images-and-centre-it-with-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca3e374",
   "metadata": {},
   "source": [
    "## Circular Tracker\n",
    "\n",
    "First approach: Using a video sample as input, the user first defines a region of interest in which to look for circular objects.\n",
    "After a few pre-processing steps to increase tracking success, the Hough Transform is used to find circles. \n",
    "The radius and position of the circle is saved together with the used parameter combination used in pre-processing and tracking. \n",
    "\n",
    "Optimized approach: run hough circles transform on 50 random images of the video without roi, let tracked data define the roi for the actual tracking --> selfoptimizing the hough transform \n",
    "\n",
    "\n",
    "To do:\n",
    "\n",
    "- run analysis on the six videos that were used for manual tracking, compare results\n",
    "- code some smoothing on x, y and radius of the tracking as post-processing (Wim mentioned butterworth for example) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6c26bb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before running a different video remove the necessary dataframes etc. from memory \n",
    "\n",
    "del df_round_1, df, df2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "84b80bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing, choosing a roi on the tracking results of 50 random samples from input file\n",
    "\n",
    "videofolder= '../Video/'\n",
    "videofilename = 'June16_20.mp4'\n",
    "# Opens the Video file\n",
    "cap = cv2.VideoCapture(videofolder+videofilename)\n",
    "totalFrames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "frameWidth = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "frameHeight = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)   #fps = frames per second\n",
    "\n",
    "\n",
    "#set up empty output dataframe\n",
    "column_names = ['x','y', 'r', 'frame'] # what do we need to save from this?  \n",
    "df_round_1 = pd.DataFrame(columns = column_names)\n",
    "\n",
    "# initialize parameters for pre-processing (used in cv2.convertScaleAbs)\n",
    "alpha = 2 #1.5\n",
    "beta = 20 #30\n",
    "\n",
    "#croppedFrame = frame[int(roi[1]): int(roi[1]+roi[3]),\n",
    "#                     int(roi[0]):int(roi[0]+roi[2])] \n",
    "\n",
    "#we define a sequence of 50 ints first, with random numbers of \"totalFrames\" using sample() because that is sampling without replacement\n",
    "# then we loop over that list of numbers\n",
    "# we need an if to check, whether there is >= 50 frames in the video\n",
    "\n",
    "vector = range(0, int(totalFrames), 1)\n",
    "samp = random2.sample(vector, 50)\n",
    "#samp = random2.sample(vector, int(totalFrames))\n",
    "\n",
    "for rand in samp:\n",
    "  \n",
    "    # set frame position\n",
    "    #samp = samp[rand]\n",
    "    #samp = float(samp)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES,rand)\n",
    "    ret, frame = cap.read()\n",
    "   # do we need to save which frames were used?\n",
    "\n",
    "         \n",
    "    ############################detect circles   \n",
    "    output=frame.copy()\n",
    "    # transform to grayscale image only using the roi part of the image\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    output_gray=gray.copy()\n",
    "    # increasing brightness and contrast\n",
    "    gray_light = cv2.convertScaleAbs(gray, alpha=alpha, beta=beta)\n",
    "    # apply GuassianBlur to reduce noise. medianBlur is also added for smoothening, reducing noise.\n",
    "    gray = cv2.GaussianBlur(gray_light,(11,11),0)\n",
    "    gray = cv2.medianBlur(gray, 19)\n",
    "    ##thresholded edge contouring\n",
    "    hist = cv2.equalizeHist(gray)\n",
    "    gamma = 2\n",
    "    invGamma = 1/gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "                      for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "    gamm = cv2.LUT(hist, table, hist)\n",
    "    submitted = cv2.Canny(gamm, 20, 30)        # was 10 and 50    # why is minVal bigger than maxValue? original code was (gamm, 20, 10)\n",
    "    submitted = cv2.GaussianBlur(submitted,(7,7),0)\n",
    "    submitted = cv2.threshold(submitted, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "    submitted = cv2.dilate(submitted, None, iterations=9)  \n",
    "    submitted = cv2.erode(submitted, None, iterations=10) \n",
    "    submitted = cv2.GaussianBlur(submitted,(7,7),0) \n",
    "    submitted = cv2.erode(submitted, None, iterations=5) #iterations was 4\n",
    "    \n",
    "    #track demicircles \n",
    "    # define parameters for HoughTransform outside of function to be able to save and manipulate easier\n",
    "    \n",
    "    dp = 1\n",
    "    minDist = 10000\n",
    "    param1 = 10\n",
    "    param2 = 22 # war 10\n",
    "    minRadius = 5\n",
    "    maxRadius = 250\n",
    "    \n",
    "    # original values: dp = 1, minDist = 10000, param1=1, param2=10, minRadius = 5, maxRadius= 250\n",
    "    circles = cv2.HoughCircles(submitted, cv2.HOUGH_GRADIENT, \n",
    "                               dp = dp,minDist = minDist,  \n",
    "                               param1 = param1,param2 = param2, \n",
    "                               minRadius = minRadius, maxRadius = maxRadius)\n",
    "    if circles is not None:\n",
    "        circles = np.round(circles[0, 0:1]).astype(\"int\")\n",
    "        #for (x, y, r) in circles:\n",
    "            #cv2.circle(output, (x, y), r, (255, 255, 0), 2) #version without drwaing roi back on whole image\n",
    "        #    cv2.circle(output[int(roi[1]): int(roi[1]+roi[3]),\n",
    "        #             int(roi[0]):int(roi[0]+roi[2])], (x, y), r, (255, 255, 0), 2)\n",
    "        #    cv2.circle(submitted, (x, y), r, (200, 0, 0), 2)\n",
    "            #print(x,y,r)\n",
    "    cv2.waitKey(1)\n",
    "    #out.write(output)\n",
    "    #cv2.imshow(\"output\", submitted)\n",
    "\n",
    "# canny min and max value should be added here, if they turn out to be sensitive\n",
    "    new_row = [circles[0,0], circles[0,1],circles [0,2], rand]\n",
    "    \n",
    "    df_round_1.loc[len(df_round_1)] = new_row\n",
    "    \n",
    "    median_x = df_round_1['x'].median() #order in pos : same as in original dataframe, so x,y, r\n",
    "    median_y = df_round_1['y'].median()\n",
    "    max_r = df_round_1['r'].max()\n",
    "    min_r = df_round_1['r'].min()\n",
    "    # order of parameters saved as roi with cv2.selectROI [Top_Left_X, Top_Left_Y, Width, Height]\n",
    "    # if we want to have a consistent syntax with that, we also need those 4 parameters\n",
    "   \n",
    "    # explanation: height_1 is the maximum radius detected plus 20 pixels, that is used to determine the position of the \n",
    "    # upper left corner of the roi, same goes for width_1, both are currently the same, but that could change, so they are both\n",
    "    # coded independently\n",
    "    height_1 = max_r + 30\n",
    "    width_1 = max_r + 30\n",
    "    pos_x = median_x - width_1\n",
    "    pos_y = median_y - height_1\n",
    "    \n",
    "    # to be consistent with the roi nomenclature, we then calculate the width/height of the whole roi which is width_1 *2\n",
    "    # all those values will then be used to crop picture in next round of tracking\n",
    "    \n",
    "    width_2 = width_1 * 2\n",
    "    height_2 = height_1 *2\n",
    "    \n",
    "    \n",
    "            \n",
    "# cleaning up\n",
    "#out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ffabeabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "videofolder= '../Video/'\n",
    "videofilename = 'June16_20.mp4'\n",
    "# Opens the Video file\n",
    "cap = cv2.VideoCapture(videofolder+videofilename)\n",
    "frameWidth = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "frameHeight = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)   #fps = frames per second\n",
    "\n",
    "#output video\n",
    "out = cv2.VideoWriter('./Output/output_'+videofilename,cv2.VideoWriter_fourcc(*'MP4V'), fps, \n",
    "                      (int(frameWidth), int(frameHeight)))\n",
    "\n",
    "#set up empty output dataframe\n",
    "column_names = ['frame','roi_x1','roi_y1','roi_x2', 'roi_y2', # info on region of interest for repetability\n",
    "                'x','y', 'r', 'inputvideo','input_id',                    # actual results \n",
    "                'alpha', 'beta',                              # values of brightness and contrast pre processing\n",
    "                'dp', 'minDist', 'param1', 'param2', 'minRadius',' maxRadius'] # parameters of hough circle transform \n",
    "df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "#initialize iterator\n",
    "i=0\n",
    "# initialize parameters for pre-processing (used in cv2.convertScaleAbs)\n",
    "alpha = 2 #1.5\n",
    "beta = 20 #30\n",
    "\n",
    "# ROI, define a region of interest by mouse click on the first frame\n",
    "#ret,frame = cap.read()\n",
    "    # select ROI\n",
    "#roi  = cv2.selectROI('select the area', frame)\n",
    "\n",
    "# order of parameters saved as roi with cv2.selectROI [Top_Left_X, Top_Left_Y, Width, Height]\n",
    "#roi = [821, 351, 612, 488]       # if you want to re run a particular roi, input the roi values here\n",
    "\n",
    "#croppedFrame = frame[int(roi[1]): int(roi[1]+roi[3]),\n",
    "#                     int(roi[0]):int(roi[0]+roi[2])] \n",
    "\n",
    "roi = [pos_x, pos_y, width_2, height_2]\n",
    "\n",
    "#main loop                      \n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "          \n",
    "    ############################detect circles   \n",
    "    output=frame.copy()\n",
    "    # transform to grayscale image only using the roi part of the image\n",
    "    gray = cv2.cvtColor(frame[int(roi[1]): int(roi[1]+roi[3]),\n",
    "                     int(roi[0]):int(roi[0]+roi[2])] , cv2.COLOR_BGR2GRAY)\n",
    "    output_gray=gray.copy()\n",
    "    # increasing brightness and contrast\n",
    "    gray_light = cv2.convertScaleAbs(gray, alpha=alpha, beta=beta)\n",
    "    # apply GuassianBlur to reduce noise. medianBlur is also added for smoothening, reducing noise.\n",
    "    gray = cv2.GaussianBlur(gray_light,(11,11),0)\n",
    "    gray = cv2.medianBlur(gray, 19)\n",
    "    ##thresholded edge contouring\n",
    "    hist = cv2.equalizeHist(gray)\n",
    "    gamma = 2\n",
    "    invGamma = 1/gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "                      for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "    gamm = cv2.LUT(hist, table, hist)\n",
    "    submitted = cv2.Canny(gamm, 20, 30)        # was 10 and 50    # why is minVal bigger than maxValue? original code was (gamm, 20, 10)\n",
    "    submitted = cv2.GaussianBlur(submitted,(7,7),0)\n",
    "    submitted = cv2.threshold(submitted, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "    submitted = cv2.dilate(submitted, None, iterations=9)  \n",
    "    submitted = cv2.erode(submitted, None, iterations=10) \n",
    "    submitted = cv2.GaussianBlur(submitted,(7,7),0) \n",
    "    submitted = cv2.erode(submitted, None, iterations=5) #iterations was 4\n",
    "    \n",
    "    #track demicircles \n",
    "    # define parameters for HoughTransform outside of function to be able to save and manipulate easier\n",
    "    \n",
    "    dp = 1\n",
    "    minDist = 10000\n",
    "    param1 = 10\n",
    "    param2 = 22 # was 10\n",
    "    minRadius = min_r - 10\n",
    "    maxRadius = 270\n",
    "    name = 'framenr_' + str(i+1) + '_framevid_' + videofilename[0:-4] \n",
    "    \n",
    "    # original values: dp = 1, minDist = 10000, param1=1, param2=10, minRadius = 5, maxRadius= 250\n",
    "    circles = cv2.HoughCircles(submitted, cv2.HOUGH_GRADIENT, \n",
    "                               dp = dp,minDist = minDist,  \n",
    "                               param1 = param1,param2 = param2, \n",
    "                               minRadius = minRadius, maxRadius = maxRadius)\n",
    "    if circles is not None:\n",
    "        #circles = np.round(circles[0, 0:1]).astype(\"int\")\n",
    "        if circles is not None:\n",
    "            circles = np.round(circles[0, 0:1]).astype(\"int\")\n",
    "            circle1 = circles[0,0]\n",
    "            circle2 = circles[0,1]\n",
    "            circle3 = circles[0,2]\n",
    "        #save it to a row\n",
    "        if circles is None:\n",
    "            circle1 = \"NA\"\n",
    "            circle2 = \"NA\"\n",
    "            circle3 = \"NA\"\n",
    "            \n",
    "  \n",
    "            \n",
    "            \n",
    "        # code for drawing the found circles onto the original video    \n",
    "        for (x, y, r) in circles:\n",
    "            #cv2.circle(output, (x, y), r, (255, 255, 0), 2) #version without drawing roi back on whole image\n",
    "            cv2.circle(output[int(roi[1]): int(roi[1]+roi[3]),\n",
    "                     int(roi[0]):int(roi[0]+roi[2])], (x, y), r, (255, 255, 0), 2)\n",
    "            cv2.circle(submitted, (x, y), r, (200, 0, 0), 2)\n",
    "            #print(x,y,r)\n",
    "    cv2.waitKey(1)\n",
    "    out.write(output)\n",
    "    cv2.imshow(\"output\", submitted)\n",
    "    i=i+1\n",
    "\n",
    "# saving results and used parameters row wise during loop into a dataframe\n",
    "\n",
    "# canny min and max value should be added here, if they turn out to be sensitive\n",
    "    new_row = [i+1, roi[0],roi[1], roi[2], roi[3], circle1, circle2,circle3, videofilename, name,\n",
    "               alpha, beta, dp, minDist, param1, param2, minRadius, maxRadius]\n",
    "    \n",
    "    df.loc[len(df)] = new_row\n",
    "\n",
    "# filename and saving dataframe as cvs file       \n",
    "filename =  'airsacradius_results_' + videofilename + '.csv'\n",
    "df.to_csv(filename, sep = ',')\n",
    "\n",
    "# cleaning up\n",
    "out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "56c6beea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#smoothing of x,y and r of circles\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.filtfilt.html\n",
    "#read raw data\n",
    "videofolder= '../Video/'\n",
    "videofilename = 'June16_20.mp4'\n",
    "filename =  'airsacradius_results_' + videofilename + '.csv'\n",
    "dfraw = pd.read_csv(filename)\n",
    "# Opens the Video file\n",
    "cap = cv2.VideoCapture(videofolder+videofilename)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) \n",
    "frameWidth = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "frameHeight = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "#outputfile smoothed\n",
    "out_smoothed = cv2.VideoWriter('./Output/output_smoothed'+videofilename,cv2.VideoWriter_fourcc(*'MP4V'), fps, \n",
    "                      (int(frameWidth), int(frameHeight)))\n",
    "\n",
    "b, a = scipy.signal.butter(8, 3,'low', fs = 25)\n",
    "        \n",
    "smooth_x = scipy.signal.filtfilt(b, a, dfraw['x'], axis=- 1, padtype='odd', padlen=None, method='pad', irlen=None)  \n",
    "smooth_y = scipy.signal.filtfilt(b, a, dfraw['y'], axis=- 1, padtype='odd', padlen=None, method='pad', irlen=None)\n",
    "smooth_r = scipy.signal.filtfilt(b, a, dfraw['r'], axis=- 1, padtype='odd', padlen=None, method='pad', irlen=None)\n",
    "\n",
    "circles_draw = list(np.column_stack((smooth_x, smooth_y, smooth_r)))\n",
    "\n",
    "\n",
    "name = dfraw['input_id']\n",
    "circles_save = list(np.column_stack((smooth_x, smooth_y, smooth_r, name)))\n",
    "\n",
    "column_names = ['x', 'y', 'r', 'inputfile']\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame(circles_save, columns = column_names)\n",
    "filename =  'airsacradius_results_smoothed' + videofilename + '.csv'\n",
    "df2.to_csv(filename, sep = ',')\n",
    "\n",
    "i = 0\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret == False:\n",
    "        break\n",
    "    output=frame.copy()\n",
    "    x,y,r = circles_draw[i]\n",
    "    cv2.circle(output[int(roi[1]): int(roi[1]+roi[3]),\n",
    "                     int(roi[0]):int(roi[0]+roi[2])], (int(x), int(y)), int(r), (255, 255, 0), 2)\n",
    "    i = i+1\n",
    "            \n",
    "    #cv2.imshow(\"output\", output)\n",
    "    out_smoothed.write(output)\n",
    "\n",
    "    \n",
    "    \n",
    "# cleaning up\n",
    "out_smoothed.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# to do: filtering is too heavy with (8,0.125) check other combinations, also check whether filter is set correctly for\n",
    "# our sampling rate --> changed that, fs is now in the function, what does the 8 mean? \n",
    "# automatic roi seems to be amiss quite heavily for all videos but 16_20...check again how to improve\n",
    "# we need to read in roi from the data sheet, otherwise weird things can happen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fc759e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        framenr_1_framevid_June16_20\n",
       "1        framenr_2_framevid_June16_20\n",
       "2        framenr_3_framevid_June16_20\n",
       "3        framenr_4_framevid_June16_20\n",
       "4        framenr_5_framevid_June16_20\n",
       "                    ...              \n",
       "164    framenr_165_framevid_June16_20\n",
       "165    framenr_166_framevid_June16_20\n",
       "166    framenr_167_framevid_June16_20\n",
       "167    framenr_168_framevid_June16_20\n",
       "168    framenr_169_framevid_June16_20\n",
       "Name: input_id, Length: 169, dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to do:\n",
    "\n",
    "#save smoothed parameters in a way, that per row ( i.e. per frame) framenr and videoname are saved in the\n",
    "# format of the manually tracked ones: framenr_1_framevid_June09_01.jpeg\n",
    "# --> delete the jpeg part in the manully tracked ones, built the name for the saving by pasting it together\n",
    "\n",
    "#'framenr_' + i + '_framevid_' + videofilename \n",
    "\n",
    "#something like that, check whether it has to be i-1, because of how python indexes and how we start counting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d8ed86",
   "metadata": {},
   "source": [
    "# Code to track manually labeled image sequences\n",
    "\n",
    "We can't use the ROI here, as very different images are in the sequence, so that the roi doesn't work.\n",
    "\n",
    "Currently this doesn't work at all, only one example scene (comprised of multiple images) in batch 1 was tracked well\n",
    "\n",
    "## Finding the best parameter combination\n",
    "\n",
    "In this section we try different parameter combinations for pre-processing and tracking to find the parameter combination giving the highest correlation coefficient with the manually tracked results.\n",
    "\n",
    "Parameters to differ:\n",
    "- alpha (0.5;1;1.5;2)\n",
    "- beta  (10,20,30,40,50)\n",
    "- param2 (Hough Transform) (5;10;15;20)\n",
    "- eroding iterations (first time: 6,7,8,9,10,11,12; second time: 2,3,4,5,6)\n",
    "- canny parameters min 5,10,15,20,25,30 max 30,35,40,45,50,55,60\n",
    "\n",
    "### To do:\n",
    "\n",
    "1. combine 24 frames of manually tracked frames into video sequence (without the manuall track), 3 frames from all 6 videos?\n",
    "2. define saving routine\n",
    "3. define loops for different parameter combinations\n",
    "4. calculate correlation coefficients for all combinations and manually tracked radii. (maybe in different program) \n",
    "5. choose 5 parameters spaces with best correlation coefficient, rerun with roi to see whether there is an increase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66df3bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3c218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "videofolder= '../Video/'\n",
    "videofilename = 'video_batch_01.mp4'\n",
    "\n",
    "column_names = ['frame','x','y', 'r', 'inputfile',                                    # actual results \n",
    "                'alpha', 'beta','canny_min', 'canny_max','erode_it_1','erode_it_2',   # values of brightness and contrast pre processing\n",
    "                'param2']                                                             # parameters of hough circle transform \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# constants (define parameters for HoughTransform outside of function to be able to save and manipulate easier)\n",
    "dp = 1\n",
    "minDist = 10000\n",
    "param1 = 10\n",
    "# param2 is defined in loops\n",
    "minRadius = 5\n",
    "maxRadius = 250\n",
    "\n",
    "# set up dataframe to save results \n",
    "global df\n",
    "df = pd.DataFrame(columns = column_names)         \n",
    "\n",
    "# loops for different parameter combinations\n",
    "for alpha in [0.5,1,1.5,2]:\n",
    "#for alpha in [0.5]:\n",
    "    for beta in [10,20,30,40,50,60]:\n",
    "    #for beta in [10]:\n",
    "        for canny_min in [5,10,15,20,25,30]:\n",
    "        #for canny_min in [5]:\n",
    "            for canny_max in [30,35,40,45,50,55,60]:\n",
    "            #for canny_max in [30]:\n",
    "                for erode_it_1 in [6,7,8,9,10,11,12]:\n",
    "                #for erode_it_1 in [10]:\n",
    "                    for erode_it_2 in [2,3,4,5,6]:\n",
    "                    #for erode_it_2 in [2]:                     \n",
    "                        for param2 in [5,10,15,20]:\n",
    "                            # Opens the Video file\n",
    "                            cap = cv2.VideoCapture(videofolder+videofilename)\n",
    "                            frameWidth = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "                            frameHeight = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "                            fps = cap.get(cv2.CAP_PROP_FPS)   #fps = frames per second\n",
    "                            #initialize iterator\n",
    "                            i=0\n",
    "                            while(cap.isOpened()):\n",
    "                                ret, frame = cap.read()\n",
    "                                if ret == False:\n",
    "                                    break\n",
    "                                ############################detect circles   \n",
    "                                output=frame.copy()\n",
    "                                # transform to grayscale image only using the roi part of the image\n",
    "                                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                                output_gray=gray.copy()\n",
    "                                # increasing brightness and contrast\n",
    "                                gray_light = cv2.convertScaleAbs(gray, alpha=alpha, beta=beta)\n",
    "                                # apply GuassianBlur to reduce noise. medianBlur is also added for smoothening, reducing noise.\n",
    "                                gray = cv2.GaussianBlur(gray_light,(11,11),0)\n",
    "                                gray = cv2.medianBlur(gray, 19)\n",
    "                                ##thresholded edge contouring\n",
    "                                hist = cv2.equalizeHist(gray)\n",
    "                                gamma = 2\n",
    "                                invGamma = 1/gamma\n",
    "                                table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "                                                  for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "                                gamm = cv2.LUT(hist, table, hist)\n",
    "                                #submitted = cv2.Canny(gamm, 10, 50)            # why is minVal bigger than maxValue? original code was (gamm, 20, 10)\n",
    "                                submitted = cv2.Canny(gamm, canny_min, canny_max)\n",
    "                                submitted = cv2.GaussianBlur(submitted,(7,7),0)\n",
    "                                submitted = cv2.threshold(submitted, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "                                submitted = cv2.dilate(submitted, None, iterations=9)  \n",
    "                                #submitted = cv2.erode(submitted, None, iterations=10) \n",
    "                                submitted = cv2.erode(submitted, None, iterations=erode_it_1)\n",
    "                                submitted = cv2.GaussianBlur(submitted,(7,7),0) \n",
    "                                #submitted = cv2.erode(submitted, None, iterations=4)\n",
    "                                submitted = cv2.erode(submitted, None, iterations=erode_it_2)\n",
    "\n",
    "                                #track demicircles (note original prototype values: dp = 1, minDist = 10000, param1=1, param2=10, minRadius = 5, maxRadius= 250)                              \n",
    "                                circles = cv2.HoughCircles(submitted, cv2.HOUGH_GRADIENT, \n",
    "                                                           dp = dp,minDist = minDist,  \n",
    "                                                           param1 = param1,param2 = param2, \n",
    "                                                           minRadius = minRadius, maxRadius = maxRadius)\n",
    "                                \n",
    "                                if circles is not None:\n",
    "                                    circles = np.round(circles[0, 0:1]).astype(\"int\")\n",
    "                                cv2.waitKey(1)\n",
    "                                i=i+1\n",
    "\n",
    "                                new_row = [i, circles[0,0], circles[0,1],circles [0,2], videofilename, alpha, beta, canny_min, canny_max,erode_it_1,erode_it_2,param2]\n",
    "                                df.loc[len(df)]=new_row\n",
    "            \n",
    "print('done')\n",
    "#we will save after the loop is done            \n",
    "videofilename_input = videofilename.split('.')[0]\n",
    "#filename =  'sens_analysis_' + str(alpha) + '_' + str(beta) + '_' + str(canny_min)+ '_' + str(canny_max) + '_' + str(erode_it_1) + '_' + str(erode_it_2)+ '_' + str(param2) + '_' + videofilename_input + '.csv'\n",
    "filename = 'sens_analysis_all_comb_' + videofilename_input + '.csv'\n",
    "df.to_csv(filename, sep = ',')\n",
    "\n",
    "# cleaning up\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cadb4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do\n",
    "\n",
    "# 1. include timepoints in output\n",
    "#    for each extracted radius, we also want to have the timepoint in the snippet to be able to correlate it with f0 as analyzed \n",
    "#    in praat or else, as we won't have the values for exactly the same timepoints \n",
    "#    for that we need the fps, that we already write, then multiply fps with frame number (should be i?) and write into output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5858f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "85195cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(filename, sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "33180966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'June16_20'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videofilename[0:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f5752545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(totalFrames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a3bce2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
