{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aedee532",
   "metadata": {},
   "source": [
    "# Air Sac Tracking Prototype code\n",
    "Lara S. Burchardt & Wim Pouw\n",
    "\n",
    "lara.burchardt@donders.ru.nl\n",
    "\n",
    "Next to body movements and acoustics, we would also like to track the air sac's inflation of the Siamangs. The air sac naturally forms a spherical(3D) or circular (2D) shape, and such shapes are retrievable from an image using the hough transform, and a bit of pre-processing of the images to get the optimal representation of the relevent edges of the air sac.\n",
    "\n",
    "This code takes as input a sample video with a close up of a Siamang, and then tracks the air sac when it takes a sufficiently circular shape. The result is shown below; it is not perfect, but with a bit of smoothing this can function as a good air sac tracker. This code is very much under development, there are many ways to improve further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4313bfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from skimage import io, feature, color, measure, draw, img_as_float\n",
    "import numpy as np\n",
    "import csv\n",
    "import random2\n",
    "import statistics\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy.signal import savgol_filter\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "\n",
    "#resused code from \n",
    "#https://pyimagesearch.com/2014/07/21/detecting-circles-images-using-opencv-hough-circles/\n",
    "#https://stackoverflow.com/questions/31705355/how-to-detect-circlular-region-in-images-and-centre-it-with-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544025a3",
   "metadata": {},
   "source": [
    "## Define Prepocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faf57f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define parameters for HoughTransform outside of function to be able to save and manipulate easier\n",
    "def hougdraw(submitted_image, dp = 1, mindist = 10000, param1 = 10, param2=22, minradius = 5, maxradius=250):\n",
    "    circles = cv2.HoughCircles(submitted_image, cv2.HOUGH_GRADIENT, \n",
    "                               dp = dp,minDist = mindist,  \n",
    "                               param1 = param1, param2 = param2, \n",
    "                               minRadius = minradius, maxRadius = maxradius)\n",
    "    if circles is not None:\n",
    "        circles = np.round(circles[0, 0:1]).astype(\"int\")\n",
    "        circle1 = circles[0,0]\n",
    "        circle2 = circles[0,1]\n",
    "        circle3 = circles[0,2]\n",
    "        for(x, y, r) in circles:\n",
    "            cv2.circle(submitted_image, (x, y), r, (255, 255, 0), 2) #version without drawing roi back on whole image \n",
    "    return(submitted_image)\n",
    "    \n",
    "# define function for preprocessing\n",
    "def preprocessing(image, phase1_medianblur = 27, \n",
    "                              phase2_dilate = 7, \n",
    "                              phase2_medianblur = 19, \n",
    "                              alpha = 2, \n",
    "                              beta= 30,\n",
    "                              thresh_div_1=10,\n",
    "                              thresh_div_2=15):\n",
    "    #image0 = hougdraw(image)\n",
    "    #convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    #brightness change\n",
    "    gray = cv2.convertScaleAbs(gray, alpha = alpha, beta = beta)\n",
    "    #set dynamic tresholds for canny (and thus also for hough)\n",
    "    mean_intensity = np.median(gray)\n",
    "    threshold1 = int(max(0, (1.0 - 0.33) * mean_intensity/thresh_div_1))\n",
    "    threshold2 = int(min(255, (1.0 + 0.33) * mean_intensity/thresh_div_2))    \n",
    "    image1_h = hougdraw(gray,param1= threshold1, param2 =threshold2)\n",
    "    #blur\n",
    "    image2 = cv2.medianBlur(gray, phase1_medianblur)\n",
    "    image2_h = hougdraw(image2.copy(),param1= threshold1, param2 =threshold2)\n",
    "    #dynamic thresholds for canny edge detection based on intensity of image\n",
    "    #Thresholds one standard deviation above and below median intensity\n",
    "    #edge detection\n",
    "    image3 = cv2.Canny(image2, threshold1, threshold2)\n",
    "    image3_h = hougdraw(image3.copy(), param1= threshold1, param2 =threshold2)\n",
    "    #dilation and second blur\n",
    "    submitted = cv2.dilate(image3, None, iterations= phase2_dilate)  \n",
    "    image4 = cv2.medianBlur(submitted, phase2_medianblur) \n",
    "    image4_h = hougdraw(image4.copy(), param1= threshold1, param2 =threshold2)\n",
    "    #add hough\n",
    "    return image1_h, image2_h, image3_h, image4_h\n",
    "############################################\n",
    "\n",
    "def preprocessing2(image, phase1_medianblur = 27, \n",
    "                              phase2_dilate = 5, \n",
    "                              phase2_medianblur = 27, \n",
    "                              alpha = 2, \n",
    "                              beta= 30,\n",
    "                              param1canny=10,\n",
    "                              param2canny=15):\n",
    "    #image0 = hougdraw(image)\n",
    "    #convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    #brightness change\n",
    "    gray = cv2.convertScaleAbs(gray, alpha = alpha, beta = beta)\n",
    "    #set dynamic tresholds for canny (and thus also for hough)\n",
    "    mean_intensity = np.median(gray)\n",
    "    threshold1 = int(max(0, (1.0 - 0.33) * mean_intensity/param1canny))\n",
    "    threshold2 = int(min(255, (1.0 + 0.33) * mean_intensity/param2canny))    \n",
    "    #blur\n",
    "    image2 = cv2.medianBlur(gray, phase1_medianblur)\n",
    "    #dynamic thresholds for canny edge detection based on intensity of image\n",
    "    #Thresholds one standard deviation above and below median intensity\n",
    "    #edge detection\n",
    "    image3 = cv2.Canny(image2, threshold1, threshold2)\n",
    "    #dilation and second blur\n",
    "    submitted = cv2.dilate(image3, None, iterations= phase2_dilate)  \n",
    "    image4 = cv2.medianBlur(submitted, phase2_medianblur) \n",
    "    #add hough\n",
    "    image4 = np.float32(image4)\n",
    "    return image4, threshold1, threshold2\n",
    "\n",
    "def matriximages(outputname, wimagenumber, himagenumber, imagelist, marginbetweenimages, vertnames, hornames):\n",
    "    \"\"\"\n",
    "    matrix images takes in the full path name of the outputfolder for storing the images\n",
    "    it takes as input a list of full path names of the images\n",
    "    the height is given in image numbers and same for width\n",
    "    the vert names is a list of column names\n",
    "    the hor names is a list of row names\n",
    "    \"\"\"\n",
    "    margin = marginbetweenimages\n",
    "    #img = imagelist  \n",
    "    w = wimagenumber\n",
    "    h = himagenumber\n",
    "    n = w*h\n",
    "\n",
    "    #imgs = [cv2.imread(i) for i in imagelist]\n",
    "    imgs = imagelist\n",
    "    #if any(i.shape != imgs[0].shape for i in imgs[1:]):\n",
    "    #    raise ValueError('Not all images have the same shape.')\n",
    "\n",
    "    img_h, img_w = imgs[0].shape#img_h, img_w, img_c = imgs[0].shape\n",
    "\n",
    "    m_x = 0\n",
    "    m_y = 0\n",
    "    if marginbetweenimages is not None:\n",
    "        margin = marginbetweenimages\n",
    "        m_x = int(margin*img_w)\n",
    "        m_y = int(margin*img_h)\n",
    "        \n",
    "    imgmatrix = np.zeros((img_h * h + m_y * (h - 1),\n",
    "                          img_w * w + m_x * (w - 1)),\n",
    "                         np.uint8)\n",
    "\n",
    "    imgmatrix.fill(255)    \n",
    "\n",
    "    positions = itertools.product(range(w), range(h))\n",
    "    for (x_i, y_i), img in zip(positions, imgs):\n",
    "        x = x_i * (img_w + m_x)\n",
    "        y = y_i * (img_h + m_y)\n",
    "        imgmatrix[y:y+img_h, x:x+img_w] = img #imgmatrix[y:y+img_h, x:x+img_w, :] = img\n",
    "    #add text\n",
    "    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "    cv2.putText(imgmatrix, hornames[0], (0*img_w, int(img_h/4)), font, 10, (255, 255, 255), 5, cv2.LINE_AA)\n",
    "    cv2.putText(imgmatrix, hornames[1], (1*img_w,  int(img_h/4)), font, 10, (255, 255, 255), 5, cv2.LINE_AA)\n",
    "    cv2.putText(imgmatrix, hornames[2], (2*img_w, int(img_h/4)), font, 10, (255, 255, 255), 5, cv2.LINE_AA)\n",
    "    cv2.putText(imgmatrix, hornames[3], (3*img_w, int(img_h/4)), font, 10, (255, 255, 255), 5, cv2.LINE_AA)\n",
    "    cv2.putText(imgmatrix, hornames[4], (4*img_w, int(img_h/4)), font, 10, (255, 255, 255), 5, cv2.LINE_AA)\n",
    "    cv2.putText(imgmatrix, vertnames[0], (0, 1*img_h), font, 10, (255, 255, 255), 5, cv2.LINE_AA)\n",
    "    cv2.putText(imgmatrix, vertnames[1], (0, 2*img_h), font, 10, (255, 255, 255), 5, cv2.LINE_AA)\n",
    "    cv2.putText(imgmatrix, vertnames[2], (0, 3*img_h), font, 10, (255, 255, 255), 5, cv2.LINE_AA)\n",
    "    cv2.putText(imgmatrix, vertnames[3], (0, 4*img_h), font, 10, (255, 255, 255), 5, cv2.LINE_AA)\n",
    "    #cv2.putText(imgmatrix, vertnames[4], (0, 5*img_h), font, 10, (0, 255, 0), 5, cv2.LINE_AA)\n",
    "    cv2.imwrite(outputname, imgmatrix)   \n",
    "    \n",
    "    print('done, look in your folder: '+ outputname)\n",
    "    \n",
    "    \n",
    "def roidefinition(video, height_buffer, width_buffer, dp, minRadius, maxRadius):\n",
    "    cap = cv2.VideoCapture(video)\n",
    "    totalFrames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    #frameWidth = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    #frameHeight = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "    #fps = cap.get(cv2.CAP_PROP_FPS)   #fps = frames per second\n",
    "    #set up empty output dataframe\n",
    "    column_names = ['x','y', 'r', 'frame'] # we are going to collect hough generated x,y,r,frame from random set of frames\n",
    "    df_round_1 = pd.DataFrame(columns = column_names) \n",
    "    vector = range(0, int(totalFrames), 1)\n",
    "    samp = random2.sample(vector, 45) #50 is the setting\n",
    "    for rand in samp:\n",
    "        # set frame position\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES,rand)\n",
    "        ret, frame = cap.read()\n",
    "        ############################detect circles   \n",
    "        output=frame.copy()\n",
    "        # transform to grayscale image only using the roi part of the image\n",
    "        image4, param1, param2 = preprocessing2(image=output)\n",
    "        final_im = cv2.normalize(src=image4, dst=None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "        #final_im = image4\n",
    "        circles = cv2.HoughCircles(final_im, cv2.HOUGH_GRADIENT, \n",
    "                                   dp = dp,minDist = minDist,  \n",
    "                                   param1 = param1,param2 = param2, \n",
    "                                   minRadius = minRadius, maxRadius = maxRadius)\n",
    "        #if circles is not None:\n",
    "        #    circles = np.round(circles[0, 0:1]).astype(\"int\")\n",
    "        if circles is not None:\n",
    "            #circles = np.round(circles[0, 0:1]).astype(\"int\")\n",
    "            if circles is not None:\n",
    "                circles = np.round(circles[0, 0:1]).astype(\"int\")\n",
    "                circle1 = circles[0,0]\n",
    "                circle2 = circles[0,1]\n",
    "                circle3 = circles[0,2]\n",
    "            #save it to a row\n",
    "            if circles is None:\n",
    "                circle1 = \"NA\"\n",
    "                circle2 = \"NA\"\n",
    "                circle3 = \"NA\"\n",
    "        new_row = [circles[0,0], circles[0,1],circles [0,2], rand]\n",
    "        df_round_1.loc[len(df_round_1)] = new_row\n",
    "\n",
    "    #when collected take some info\n",
    "    median_x = df_round_1['x'].median() #order in pos : same as in original dataframe, so x,y, r\n",
    "    median_y = df_round_1['y'].median()\n",
    "    max_r = df_round_1['r'].max()\n",
    "    min_r = df_round_1['r'].min()\n",
    "    # order of parameters saved as roi with cv2.selectROI [Top_Left_X, Top_Left_Y, Width, Height]\n",
    "\n",
    "    # explanation: height_1 is the maximum radius detected plus 30 pixels, that is used to determine the position of the \n",
    "    # upper left corner of the roi, same goes for width_1, both are currently the same, but that could change, so they are both\n",
    "    # coded independently\n",
    "    height_1 = max_r + height_buffer #i.e.100, in pixels\n",
    "    width_1 = max_r + width_buffer #250, in pixels\n",
    "    pos_x = median_x - width_1\n",
    "    pos_y = median_y - height_1  \n",
    "    # to be consistent with the roi nomenclature, we then calculate the width/height of the whole roi which is width_1 *2\n",
    "        # all those values will then be used to crop picture in next round of tracking\n",
    "    width_2 = width_1 * 2\n",
    "    height_2 = height_1 *2\n",
    "    #\n",
    "    roi = [pos_x, pos_y, width_2, height_2]\n",
    "    cap.release() #release the video\n",
    "    return roi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d675c31",
   "metadata": {},
   "source": [
    "## Main Function\n",
    "\n",
    "This function is also used in the looper: process_all_videos.py\n",
    "\n",
    "The tracker is run on the full video, it first defines an ROI defined in the first step. \n",
    "The output is saved in a table format and as a video with the detected circles drawn on top. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80836419",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# preprocessing, choosing a roi on the tracking results of 50 random samples from input file\n",
    "#https://github.com/patchy631/machine-learning/blob/main/computer_vision/cv2_edge_detection.ipynb\n",
    "\n",
    "############settings that worked: c1_5_c2_10_al_1_b_12_dil_7_blur_27\n",
    "alpha = 2\n",
    "beta = 20\n",
    "dp = 1\n",
    "dilation = 5\n",
    "phase1_medianblur = 27\n",
    "#cannyt1 = 5\n",
    "#cannyt2 = 12 \n",
    "minDist = 10000\n",
    "minRadius = 5 #minus 2times std\n",
    "maxRadius = 260 #dynamic? \n",
    "###################\n",
    "videofolder= '../Video/'\n",
    "nameforfiles = 'June16_02'\n",
    "videofilename = nameforfiles +'.mp4'\n",
    "# Opens the Video file\n",
    "cap = cv2.VideoCapture(videofolder+videofilename)\n",
    "totalFrames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "frameWidth = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "frameHeight = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)   #fps = frames per second\n",
    "\n",
    "#set up empty output dataframe\n",
    "column_names = ['x','y', 'r', 'frame'] # we are going to collect hough generated x,y,r,frame from random set of frames\n",
    "df_round_1 = pd.DataFrame(columns = column_names) \n",
    "vector = range(0, int(totalFrames), 1)\n",
    "samp = random2.sample(vector, 50) #50 is the setting\n",
    "\n",
    "for rand in samp:\n",
    "    # set frame position\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES,rand)\n",
    "    ret, frame = cap.read()\n",
    "    ############################detect circles   \n",
    "    output=frame.copy()\n",
    "    # transform to grayscale image only using the roi part of the image\n",
    "    image4, param1, param2 = preprocessing2(image=output)\n",
    "    final_im = cv2.normalize(src=image4, dst=None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    circles = cv2.HoughCircles(final_im, cv2.HOUGH_GRADIENT, \n",
    "                               dp = dp,minDist = minDist,  \n",
    "                               param1 = param1,param2 = param2, \n",
    "                               minRadius = minRadius, maxRadius = maxRadius)\n",
    "    #if circles is not None:\n",
    "    #    circles = np.round(circles[0, 0:1]).astype(\"int\")\n",
    "    if circles is not None:\n",
    "        #circles = np.round(circles[0, 0:1]).astype(\"int\")\n",
    "        if circles is not None:\n",
    "            circles = np.round(circles[0, 0:1]).astype(\"int\")\n",
    "            circle1 = circles[0,0]\n",
    "            circle2 = circles[0,1]\n",
    "            circle3 = circles[0,2]\n",
    "        #save it to a row\n",
    "        if circles is None:\n",
    "            circle1 = \"NA\"\n",
    "            circle2 = \"NA\"\n",
    "            circle3 = \"NA\"\n",
    "    new_row = [circles[0,0], circles[0,1],circles [0,2], rand]\n",
    "    df_round_1.loc[len(df_round_1)] = new_row\n",
    "    cv2.waitKey(1)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#when collected take some info\n",
    "median_x = df_round_1['x'].median() #order in pos : same as in original dataframe, so x,y, r\n",
    "median_y = df_round_1['y'].median()\n",
    "max_r = df_round_1['r'].max()\n",
    "min_r = df_round_1['r'].min()\n",
    "    # order of parameters saved as roi with cv2.selectROI [Top_Left_X, Top_Left_Y, Width, Height]\n",
    "   \n",
    "    # explanation: height_1 is the maximum radius detected plus 30 pixels, that is used to determine the position of the \n",
    "    # upper left corner of the roi, same goes for width_1, both are currently the same, but that could change, so they are both\n",
    "    # coded independently\n",
    "height_1 = max_r + 100\n",
    "width_1 = max_r + 250\n",
    "pos_x = median_x - width_1\n",
    "pos_y = median_y - height_1  \n",
    "# to be consistent with the roi nomenclature, we then calculate the width/height of the whole roi which is width_1 *2\n",
    "    # all those values will then be used to crop picture in next round of tracking\n",
    "width_2 = width_1 * 2\n",
    "height_2 = height_1 *2\n",
    "#\n",
    "roi = [pos_x, pos_y, width_2, height_2]\n",
    "\n",
    "# cleaning up\n",
    "#cap.set(cv2.CAP_PROP_POS_FRAMES,samp[1])\n",
    "#ret, frame = cap.read()\n",
    "#cv2.rectangle(frame,(int(roi[0]), int(roi[1])), (int(roi[0]+roi[2]), int(roi[1]+roi[3])), (0,0,0), 2) \n",
    "#cv2.imshow(\"output\", frame) #ROI)\n",
    "cv2.waitKey(0)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "################################\n",
    "\n",
    "# Opens the Video file\n",
    "cap = cv2.VideoCapture(videofolder+videofilename)\n",
    "frameWidth = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "frameHeight = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)   #fps = frames per second\n",
    "\n",
    "#output video\n",
    "out = cv2.VideoWriter('./Output/videos/output_'+videofilename,cv2.VideoWriter_fourcc(*'MP4V'), fps, \n",
    "                      (int(frameWidth), int(frameHeight)))\n",
    "#set up empty output dataframe\n",
    "column_names = ['frame','roi_x1','roi_y1','roi_x2', 'roi_y2', # info on region of interest for repetability\n",
    "                'x','y', 'r', 'inputvideo','input_id',                    # actual results \n",
    "                'alpha', 'beta',                              # values of brightness and contrast pre processing\n",
    "                'dp', 'minDist', 'param1', 'param2', 'minRadius',' maxRadius'] # parameters of hough circle transform \n",
    "df = pd.DataFrame(columns = column_names)\n",
    "print(\"parameters set\")\n",
    "#initialize iterator\n",
    "i=0\n",
    "#ROI as automatically detected beforehand\n",
    "pos_x =0 \n",
    "pos_y= 0\n",
    "width_2=0\n",
    "height_2=0\n",
    "\n",
    "#main loop                      \n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "  ############################detect circles   \n",
    "    output=frame.copy()\n",
    "    print(\"preprocessing image\")\n",
    "    image4, param1, param2 = preprocessing2(image=output)\n",
    "    print(\"done\")\n",
    "    #track demicircles \n",
    "    name = 'framenr_' + str(i+1) + '_framevid_' + videofilename[0:-4] \n",
    "    # original values: dp = 1, minDist = 10000, param1=1, param2=10, minRadius = 5, maxRadius= 250\n",
    "    #submit to \n",
    "    image4 = image4[int(roi[1]):int(roi[1]+roi[3]), int(roi[0]):int(roi[0]+roi[2])]\n",
    "    \n",
    "    final_im = cv2.normalize(src=image4, dst=None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U) \n",
    "    circles = cv2.HoughCircles(final_im, cv2.HOUGH_GRADIENT, \n",
    "                               dp = dp,minDist = minDist,  \n",
    "                               param1 = param1,param2 = param2, minRadius = minRadius, maxRadius = maxRadius)   \n",
    "    #cv2.rectangle(image, start_point, end_point, color, thickness)    \n",
    "    cv2.rectangle(frame,(int(roi[0]), int(roi[1])), (int(roi[0]+roi[2]), int(roi[1]+roi[3])), (0,0,0), 2)    \n",
    "\n",
    "    if circles is not None:\n",
    "        #circles = np.round(circles[0, 0:1]).astype(\"int\")\n",
    "        if circles is not None:\n",
    "            circles = np.round(circles[0, 0:1]).astype(\"int\")\n",
    "            circle1 = circles[0,0]+roi[0] #x  + plus the shift from the roi\n",
    "            circle2 = circles[0,1]+roi[1] #y  + plus the shift from the roi\n",
    "            circle3 = circles[0,2]\n",
    "    #    #save it to a row\n",
    "        if circles is None:\n",
    "            circle1 = \"NA\"\n",
    "            circle2 = \"NA\"\n",
    "            circle3 = \"NA\"\n",
    "        # code for drawing the found circles onto the original video    \n",
    "        for (x, y, r) in circles:\n",
    "            #cv2.circle(frame, (x, y), r, (255, 255, 0), 2) #version without drawing roi back on whole image\n",
    "            #cv2.circle(output[int(roi[1]): int(roi[1]+roi[3]),\n",
    "            #         int(roi[0]):int(roi[0]+roi[2])], (x, y), r, (255, 255, 0), 2)\n",
    "            cv2.circle(frame, (int(x+roi[0]), int(y+roi[1])), r, (200, 0, 0), 2)\n",
    "            \n",
    "            #print(x,y,r)\n",
    "    cv2.waitKey(1)\n",
    "    out.write(frame)\n",
    "    #cv2.imshow(\"output\", frame)#frame\n",
    "    i=i+1\n",
    "    print(i)\n",
    "    # saving results and used parameters row wise during loop into a dataframe\n",
    "    new_row = [i+1, roi[0],roi[1], roi[2], roi[3], circle1, circle2,circle3, videofilename, name,\n",
    "               alpha, beta, dp, minDist, param1, param2, minRadius, maxRadius]\n",
    "    df.loc[len(df)] = new_row\n",
    "\n",
    "# cleaning up\n",
    "out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# filename and saving dataframe as cvs file       \n",
    "filename =  './Output/timeseries/airsacradius_results_' + nameforfiles + '.csv'\n",
    "df.to_csv(filename, sep = ',')\n",
    "\n",
    "\n",
    "#smoothing of x,y and r of circles\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.filtfilt.html\n",
    "#filename =  './Output/timeseries/airsacradius_results_' + nameforfiles + '.csv'\n",
    "dfraw = pd.read_csv(filename)\n",
    "\n",
    "# Opens the Video file\n",
    "cap = cv2.VideoCapture(videofolder+videofilename)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) \n",
    "frameWidth = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "frameHeight = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "#outputfile smoothed\n",
    "out_smoothed = cv2.VideoWriter('./Output/videos/output_smoothed'+videofilename,cv2.VideoWriter_fourcc(*'MP4V'), fps, \n",
    "                      (int(frameWidth), int(frameHeight)))\n",
    "\n",
    "#delete outliers\n",
    "#how? dynamic? mean +- 2*std of position of centroid in x or y direction? everything under or over that will be deleted\n",
    "# calculate euclidean distance? to take x and y into account? \n",
    "\n",
    "# filter version using buterworth filter (low pass 10 Hz)\n",
    "#low = 12/(fps/2)\n",
    "#b, a = scipy.signal.butter(15, low,'low')\n",
    "        \n",
    "#smooth_x = scipy.signal.filtfilt(b, a, dfraw['x'], axis=- 1, padtype='odd', padlen=None, method='pad', irlen=None)  \n",
    "#smooth_y = scipy.signal.filtfilt(b, a, dfraw['y'], axis=- 1, padtype='odd', padlen=None, method='pad', irlen=None)\n",
    "#smooth_r = scipy.signal.filtfilt(b, a, dfraw['r'], axis=- 1, padtype='odd', padlen=None, method='pad', irlen=None)\n",
    "\n",
    "#filter version using Savitzky-golay filter\n",
    "wl = 11 #windowlength for savgol filter, must be odd (reduce the window length it becomes more jittery)\n",
    "p = 2   # polynomial for savgol filter, must be less than window_length\n",
    "\n",
    "roi = [dfraw['roi_x1'][0], dfraw['roi_y1'][1], dfraw['roi_x2'][2],dfraw['roi_y2'][3]]\n",
    "\n",
    "raw_x = dfraw['x']\n",
    "raw_y = dfraw['y']\n",
    "raw_r = dfraw['r']\n",
    "\n",
    "smooth_x = signal.savgol_filter(dfraw['x'], window_length=wl, polyorder=p)\n",
    "smooth_y = signal.savgol_filter(dfraw['y'], window_length=wl, polyorder=p)\n",
    "smooth_r = signal.savgol_filter(dfraw['r'], window_length=wl, polyorder=p)\n",
    "\n",
    "name = dfraw['input_id']\n",
    "circles_save = list(np.column_stack((smooth_x, smooth_y, smooth_r, name)))\n",
    "raw_circles = list(np.column_stack((dfraw['x'], dfraw['y'], dfraw['r'])))\n",
    "\n",
    "column_names = ['x', 'y', 'r', 'inputfile']\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame(circles_save, columns = column_names)\n",
    "filename =  './Output/timeseries/airsacradius_results_smoothed' + videofilename + '.csv'\n",
    "df2.to_csv(filename, sep = ',')\n",
    "\n",
    "i = 0\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret == False:\n",
    "        break\n",
    "    output=frame.copy()\n",
    "    x =int(smooth_x[i])\n",
    "    y =int(smooth_y[i])\n",
    "    r =int(smooth_r[i])\n",
    "    #a,b,c = raw_circles[i]\n",
    "    rx =int(raw_x[i])\n",
    "    ry =int(raw_y[i])\n",
    "    rr =int(raw_r[i])\n",
    "    #roi\n",
    "    cv2.rectangle(output,(int(roi[0]), int(roi[1])), (int(roi[0]+roi[2]), int(roi[1]+roi[3])), (0,0,0), 3)\n",
    "    #unsmoothedcircle\n",
    "    cv2.circle(output, (rx, ry), rr, (200, 0, 0), 1)\n",
    "    #smoothed cicle\n",
    "    cv2.circle(output, (x, y), r, (0,0, 255), 3)\n",
    "    i= i+1\n",
    "            \n",
    "    #cv2.imshow(\"output\", output)\n",
    "    out_smoothed.write(output)\n",
    "\n",
    "# cleaning up\n",
    "out_smoothed.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#other filter option: savgoy filter\n",
    "#from scipy.signal import savgol_filter\n",
    "#def savgol(x, wl=14, p=2):\n",
    "#    return savgol_filter(x, window_length=wl, polyorder=p)\n",
    "\n",
    "\n",
    "# to do: filtering is too heavy with (8,0.125) check other combinations, also check whether filter is set correctly for\n",
    "# our sampling rate --> changed that, fs is now in the function, what does the 8 mean? \n",
    "# automatic roi seems to be amiss quite heavily for all videos but 16_20...check again how to improve\n",
    "# we need to read in roi from the data sheet, otherwise weird things can happen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6a3fb7",
   "metadata": {},
   "source": [
    "# Loop to optimize parameters\n",
    "## looping through manully tracked videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2ab8631",
   "metadata": {},
   "outputs": [],
   "source": [
    "#version 1, using images ####################loading in the images\n",
    "#imagefolder = '../TestFrames/testframes_9112022/'\n",
    "#ims = [f for f in listdir(imagefolder) if isfile(join(imagefolder, f))]\n",
    "#imlist = []\n",
    "#for i in ims: #add the image folder name to get the full path\n",
    "#    imlist.append(imagefolder +i) \n",
    "#imgs = [cv2.imread(i) for i in imlist] #laod in the images\n",
    "#######################################\n",
    "import random\n",
    "#version 2, using videos #################### loading in the videos\n",
    "videofolder = '../Video/for_loop/'\n",
    "vids = [f for f in listdir(videofolder) if isfile(join(videofolder, f))]\n",
    "vidlist = []\n",
    "\n",
    "for i in vids: #add the image folder name to get the full path\n",
    "    vidlist.append(videofolder +i) \n",
    "#videos = [cv2.imread(i) for i in vidlist] #laod in the images\n",
    "#######################################\n",
    "\n",
    "# in comments is the first round of parameter optimization we ran\n",
    "alphas = [2, 2.5, 3]\n",
    "betas = [25,30,35] \n",
    "dilations = [5,6,7] #stayed the same\n",
    "phase1_medianblurs = [25, 27, 29] #medianblur 1 and 2 are now kept the same, in first otimization blur2 was static at 17\n",
    "threshs_div_1 = [8,10,12]\n",
    "threshs_div_2 = [13,15,17]\n",
    "\n",
    "#static settings\n",
    "minDist = 10000\n",
    "minRadius = 5\n",
    "maxRadius = 270\n",
    "dp=1\n",
    "\n",
    "randlistsettings = []\n",
    "for thresh_div_1 in threshs_div_1:\n",
    "    for thresh_div_2 in threshs_div_2:\n",
    "        for alpha in alphas:\n",
    "            for beta in betas:\n",
    "                for dilation in dilations:\n",
    "                    for phase1_medianblur in phase1_medianblurs:\n",
    "                        values = [thresh_div_1, thresh_div_2, alpha,  beta, dilation, phase1_medianblur]\n",
    "                        randlistsettings.append(values)\n",
    "random.shuffle(randlistsettings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17daf4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "            #rois for 9 manually tracked videos\n",
    "rois_dict = {'June09_01': [0,0,1503,1056],\n",
    "             'June09_02': [197,99,940,893],\n",
    "             'June09_03': [8,96,1156,925],\n",
    "             'June12_01': [773,302,707,597],\n",
    "             'June12_02': [655,1,913,1055],\n",
    "             'June12_03': [276,4,849,1052],\n",
    "             'June16_02': [617,83,810,838],\n",
    "             'June16_07': [836,240,858,720],\n",
    "             'June16_20': [463,122,1154,928]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846b61e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking for c1_10_c2_15_al_2.5_b_35_dil_6_blur_25\n",
      "working on ../TestResults/c1_10_c2_15_al_2.5_b_35_dil_6_blur_25_vid_June09_01.mp4.csv\n",
      "processed video\n",
      "checking for c1_10_c2_15_al_2.5_b_35_dil_6_blur_25\n",
      "working on ../TestResults/c1_10_c2_15_al_2.5_b_35_dil_6_blur_25_vid_June09_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_10_c2_15_al_2.5_b_35_dil_6_blur_25\n",
      "working on ../TestResults/c1_10_c2_15_al_2.5_b_35_dil_6_blur_25_vid_June09_03.mp4.csv\n",
      "processed video\n",
      "checking for c1_10_c2_15_al_2.5_b_35_dil_6_blur_25\n",
      "working on ../TestResults/c1_10_c2_15_al_2.5_b_35_dil_6_blur_25_vid_June12_01.mp4.csv\n",
      "processed video\n",
      "checking for c1_10_c2_15_al_2.5_b_35_dil_6_blur_25\n",
      "working on ../TestResults/c1_10_c2_15_al_2.5_b_35_dil_6_blur_25_vid_June12_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_10_c2_15_al_2.5_b_35_dil_6_blur_25\n",
      "working on ../TestResults/c1_10_c2_15_al_2.5_b_35_dil_6_blur_25_vid_June12_03.mp4.csv\n",
      "processed video\n",
      "checking for c1_10_c2_15_al_2.5_b_35_dil_6_blur_25\n",
      "working on ../TestResults/c1_10_c2_15_al_2.5_b_35_dil_6_blur_25_vid_June16_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_10_c2_15_al_2.5_b_35_dil_6_blur_25\n",
      "working on ../TestResults/c1_10_c2_15_al_2.5_b_35_dil_6_blur_25_vid_June16_07.mp4.csv\n",
      "processed video\n",
      "checking for c1_10_c2_15_al_2.5_b_35_dil_6_blur_25\n",
      "working on ../TestResults/c1_10_c2_15_al_2.5_b_35_dil_6_blur_25_vid_June16_20.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_17_al_2.5_b_35_dil_5_blur_29\n",
      "working on ../TestResults/c1_12_c2_17_al_2.5_b_35_dil_5_blur_29_vid_June09_01.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_17_al_2.5_b_35_dil_5_blur_29\n",
      "working on ../TestResults/c1_12_c2_17_al_2.5_b_35_dil_5_blur_29_vid_June09_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_17_al_2.5_b_35_dil_5_blur_29\n",
      "working on ../TestResults/c1_12_c2_17_al_2.5_b_35_dil_5_blur_29_vid_June09_03.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_17_al_2.5_b_35_dil_5_blur_29\n",
      "working on ../TestResults/c1_12_c2_17_al_2.5_b_35_dil_5_blur_29_vid_June12_01.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_17_al_2.5_b_35_dil_5_blur_29\n",
      "working on ../TestResults/c1_12_c2_17_al_2.5_b_35_dil_5_blur_29_vid_June12_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_17_al_2.5_b_35_dil_5_blur_29\n",
      "working on ../TestResults/c1_12_c2_17_al_2.5_b_35_dil_5_blur_29_vid_June12_03.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_17_al_2.5_b_35_dil_5_blur_29\n",
      "working on ../TestResults/c1_12_c2_17_al_2.5_b_35_dil_5_blur_29_vid_June16_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_17_al_2.5_b_35_dil_5_blur_29\n",
      "working on ../TestResults/c1_12_c2_17_al_2.5_b_35_dil_5_blur_29_vid_June16_07.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_17_al_2.5_b_35_dil_5_blur_29\n",
      "working on ../TestResults/c1_12_c2_17_al_2.5_b_35_dil_5_blur_29_vid_June16_20.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_15_al_2_b_35_dil_6_blur_29\n",
      "working on ../TestResults/c1_12_c2_15_al_2_b_35_dil_6_blur_29_vid_June09_01.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_15_al_2_b_35_dil_6_blur_29\n",
      "working on ../TestResults/c1_12_c2_15_al_2_b_35_dil_6_blur_29_vid_June09_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_15_al_2_b_35_dil_6_blur_29\n",
      "working on ../TestResults/c1_12_c2_15_al_2_b_35_dil_6_blur_29_vid_June09_03.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_15_al_2_b_35_dil_6_blur_29\n",
      "working on ../TestResults/c1_12_c2_15_al_2_b_35_dil_6_blur_29_vid_June12_01.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_15_al_2_b_35_dil_6_blur_29\n",
      "working on ../TestResults/c1_12_c2_15_al_2_b_35_dil_6_blur_29_vid_June12_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_15_al_2_b_35_dil_6_blur_29\n",
      "working on ../TestResults/c1_12_c2_15_al_2_b_35_dil_6_blur_29_vid_June12_03.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_15_al_2_b_35_dil_6_blur_29\n",
      "working on ../TestResults/c1_12_c2_15_al_2_b_35_dil_6_blur_29_vid_June16_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_15_al_2_b_35_dil_6_blur_29\n",
      "working on ../TestResults/c1_12_c2_15_al_2_b_35_dil_6_blur_29_vid_June16_07.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_15_al_2_b_35_dil_6_blur_29\n",
      "working on ../TestResults/c1_12_c2_15_al_2_b_35_dil_6_blur_29_vid_June16_20.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_15_al_3_b_25_dil_6_blur_27\n",
      "working on ../TestResults/c1_8_c2_15_al_3_b_25_dil_6_blur_27_vid_June09_01.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_15_al_3_b_25_dil_6_blur_27\n",
      "working on ../TestResults/c1_8_c2_15_al_3_b_25_dil_6_blur_27_vid_June09_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_15_al_3_b_25_dil_6_blur_27\n",
      "working on ../TestResults/c1_8_c2_15_al_3_b_25_dil_6_blur_27_vid_June09_03.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_15_al_3_b_25_dil_6_blur_27\n",
      "working on ../TestResults/c1_8_c2_15_al_3_b_25_dil_6_blur_27_vid_June12_01.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_15_al_3_b_25_dil_6_blur_27\n",
      "working on ../TestResults/c1_8_c2_15_al_3_b_25_dil_6_blur_27_vid_June12_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_15_al_3_b_25_dil_6_blur_27\n",
      "working on ../TestResults/c1_8_c2_15_al_3_b_25_dil_6_blur_27_vid_June12_03.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_15_al_3_b_25_dil_6_blur_27\n",
      "working on ../TestResults/c1_8_c2_15_al_3_b_25_dil_6_blur_27_vid_June16_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_15_al_3_b_25_dil_6_blur_27\n",
      "working on ../TestResults/c1_8_c2_15_al_3_b_25_dil_6_blur_27_vid_June16_07.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_15_al_3_b_25_dil_6_blur_27\n",
      "working on ../TestResults/c1_8_c2_15_al_3_b_25_dil_6_blur_27_vid_June16_20.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_17_al_2_b_30_dil_5_blur_27\n",
      "working on ../TestResults/c1_8_c2_17_al_2_b_30_dil_5_blur_27_vid_June09_01.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_17_al_2_b_30_dil_5_blur_27\n",
      "working on ../TestResults/c1_8_c2_17_al_2_b_30_dil_5_blur_27_vid_June09_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_17_al_2_b_30_dil_5_blur_27\n",
      "working on ../TestResults/c1_8_c2_17_al_2_b_30_dil_5_blur_27_vid_June09_03.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_17_al_2_b_30_dil_5_blur_27\n",
      "working on ../TestResults/c1_8_c2_17_al_2_b_30_dil_5_blur_27_vid_June12_01.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_17_al_2_b_30_dil_5_blur_27\n",
      "working on ../TestResults/c1_8_c2_17_al_2_b_30_dil_5_blur_27_vid_June12_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_17_al_2_b_30_dil_5_blur_27\n",
      "working on ../TestResults/c1_8_c2_17_al_2_b_30_dil_5_blur_27_vid_June12_03.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_17_al_2_b_30_dil_5_blur_27\n",
      "working on ../TestResults/c1_8_c2_17_al_2_b_30_dil_5_blur_27_vid_June16_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_17_al_2_b_30_dil_5_blur_27\n",
      "working on ../TestResults/c1_8_c2_17_al_2_b_30_dil_5_blur_27_vid_June16_07.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_17_al_2_b_30_dil_5_blur_27\n",
      "working on ../TestResults/c1_8_c2_17_al_2_b_30_dil_5_blur_27_vid_June16_20.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_13_al_3_b_25_dil_7_blur_25\n",
      "working on ../TestResults/c1_8_c2_13_al_3_b_25_dil_7_blur_25_vid_June09_01.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_13_al_3_b_25_dil_7_blur_25\n",
      "working on ../TestResults/c1_8_c2_13_al_3_b_25_dil_7_blur_25_vid_June09_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_13_al_3_b_25_dil_7_blur_25\n",
      "working on ../TestResults/c1_8_c2_13_al_3_b_25_dil_7_blur_25_vid_June09_03.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_13_al_3_b_25_dil_7_blur_25\n",
      "working on ../TestResults/c1_8_c2_13_al_3_b_25_dil_7_blur_25_vid_June12_01.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_13_al_3_b_25_dil_7_blur_25\n",
      "working on ../TestResults/c1_8_c2_13_al_3_b_25_dil_7_blur_25_vid_June12_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_13_al_3_b_25_dil_7_blur_25\n",
      "working on ../TestResults/c1_8_c2_13_al_3_b_25_dil_7_blur_25_vid_June12_03.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_13_al_3_b_25_dil_7_blur_25\n",
      "working on ../TestResults/c1_8_c2_13_al_3_b_25_dil_7_blur_25_vid_June16_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_13_al_3_b_25_dil_7_blur_25\n",
      "working on ../TestResults/c1_8_c2_13_al_3_b_25_dil_7_blur_25_vid_June16_07.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_13_al_3_b_25_dil_7_blur_25\n",
      "working on ../TestResults/c1_8_c2_13_al_3_b_25_dil_7_blur_25_vid_June16_20.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_13_al_2_b_25_dil_6_blur_25\n",
      "working on ../TestResults/c1_12_c2_13_al_2_b_25_dil_6_blur_25_vid_June09_01.mp4.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed video\n",
      "checking for c1_12_c2_13_al_2_b_25_dil_6_blur_25\n",
      "working on ../TestResults/c1_12_c2_13_al_2_b_25_dil_6_blur_25_vid_June09_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_13_al_2_b_25_dil_6_blur_25\n",
      "working on ../TestResults/c1_12_c2_13_al_2_b_25_dil_6_blur_25_vid_June09_03.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_13_al_2_b_25_dil_6_blur_25\n",
      "working on ../TestResults/c1_12_c2_13_al_2_b_25_dil_6_blur_25_vid_June12_01.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_13_al_2_b_25_dil_6_blur_25\n",
      "working on ../TestResults/c1_12_c2_13_al_2_b_25_dil_6_blur_25_vid_June12_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_13_al_2_b_25_dil_6_blur_25\n",
      "working on ../TestResults/c1_12_c2_13_al_2_b_25_dil_6_blur_25_vid_June12_03.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_13_al_2_b_25_dil_6_blur_25\n",
      "working on ../TestResults/c1_12_c2_13_al_2_b_25_dil_6_blur_25_vid_June16_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_13_al_2_b_25_dil_6_blur_25\n",
      "working on ../TestResults/c1_12_c2_13_al_2_b_25_dil_6_blur_25_vid_June16_07.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_13_al_2_b_25_dil_6_blur_25\n",
      "working on ../TestResults/c1_12_c2_13_al_2_b_25_dil_6_blur_25_vid_June16_20.mp4.csv\n",
      "processed video\n",
      "checking for c1_10_c2_13_al_3_b_25_dil_5_blur_25\n",
      "working on ../TestResults/c1_10_c2_13_al_3_b_25_dil_5_blur_25_vid_June09_01.mp4.csv\n",
      "processed video\n",
      "checking for c1_10_c2_13_al_3_b_25_dil_5_blur_25\n",
      "working on ../TestResults/c1_10_c2_13_al_3_b_25_dil_5_blur_25_vid_June09_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_10_c2_13_al_3_b_25_dil_5_blur_25\n",
      "working on ../TestResults/c1_10_c2_13_al_3_b_25_dil_5_blur_25_vid_June09_03.mp4.csv\n",
      "processed video\n",
      "checking for c1_10_c2_13_al_3_b_25_dil_5_blur_25\n",
      "working on ../TestResults/c1_10_c2_13_al_3_b_25_dil_5_blur_25_vid_June12_01.mp4.csv\n",
      "processed video\n",
      "checking for c1_10_c2_13_al_3_b_25_dil_5_blur_25\n",
      "working on ../TestResults/c1_10_c2_13_al_3_b_25_dil_5_blur_25_vid_June12_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_10_c2_13_al_3_b_25_dil_5_blur_25\n",
      "working on ../TestResults/c1_10_c2_13_al_3_b_25_dil_5_blur_25_vid_June12_03.mp4.csv\n",
      "processed video\n",
      "checking for c1_10_c2_13_al_3_b_25_dil_5_blur_25\n",
      "working on ../TestResults/c1_10_c2_13_al_3_b_25_dil_5_blur_25_vid_June16_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_10_c2_13_al_3_b_25_dil_5_blur_25\n",
      "working on ../TestResults/c1_10_c2_13_al_3_b_25_dil_5_blur_25_vid_June16_07.mp4.csv\n",
      "processed video\n",
      "checking for c1_10_c2_13_al_3_b_25_dil_5_blur_25\n",
      "working on ../TestResults/c1_10_c2_13_al_3_b_25_dil_5_blur_25_vid_June16_20.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_15_al_2_b_30_dil_6_blur_25\n",
      "working on ../TestResults/c1_8_c2_15_al_2_b_30_dil_6_blur_25_vid_June09_01.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_15_al_2_b_30_dil_6_blur_25\n",
      "working on ../TestResults/c1_8_c2_15_al_2_b_30_dil_6_blur_25_vid_June09_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_15_al_2_b_30_dil_6_blur_25\n",
      "working on ../TestResults/c1_8_c2_15_al_2_b_30_dil_6_blur_25_vid_June09_03.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_15_al_2_b_30_dil_6_blur_25\n",
      "working on ../TestResults/c1_8_c2_15_al_2_b_30_dil_6_blur_25_vid_June12_01.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_15_al_2_b_30_dil_6_blur_25\n",
      "working on ../TestResults/c1_8_c2_15_al_2_b_30_dil_6_blur_25_vid_June12_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_15_al_2_b_30_dil_6_blur_25\n",
      "working on ../TestResults/c1_8_c2_15_al_2_b_30_dil_6_blur_25_vid_June12_03.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_15_al_2_b_30_dil_6_blur_25\n",
      "working on ../TestResults/c1_8_c2_15_al_2_b_30_dil_6_blur_25_vid_June16_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_15_al_2_b_30_dil_6_blur_25\n",
      "working on ../TestResults/c1_8_c2_15_al_2_b_30_dil_6_blur_25_vid_June16_07.mp4.csv\n",
      "processed video\n",
      "checking for c1_8_c2_15_al_2_b_30_dil_6_blur_25\n",
      "working on ../TestResults/c1_8_c2_15_al_2_b_30_dil_6_blur_25_vid_June16_20.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_13_al_2_b_35_dil_5_blur_25\n",
      "working on ../TestResults/c1_12_c2_13_al_2_b_35_dil_5_blur_25_vid_June09_01.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_13_al_2_b_35_dil_5_blur_25\n",
      "working on ../TestResults/c1_12_c2_13_al_2_b_35_dil_5_blur_25_vid_June09_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_13_al_2_b_35_dil_5_blur_25\n",
      "working on ../TestResults/c1_12_c2_13_al_2_b_35_dil_5_blur_25_vid_June09_03.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_13_al_2_b_35_dil_5_blur_25\n",
      "working on ../TestResults/c1_12_c2_13_al_2_b_35_dil_5_blur_25_vid_June12_01.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_13_al_2_b_35_dil_5_blur_25\n",
      "working on ../TestResults/c1_12_c2_13_al_2_b_35_dil_5_blur_25_vid_June12_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_13_al_2_b_35_dil_5_blur_25\n",
      "working on ../TestResults/c1_12_c2_13_al_2_b_35_dil_5_blur_25_vid_June12_03.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_13_al_2_b_35_dil_5_blur_25\n",
      "working on ../TestResults/c1_12_c2_13_al_2_b_35_dil_5_blur_25_vid_June16_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_13_al_2_b_35_dil_5_blur_25\n",
      "working on ../TestResults/c1_12_c2_13_al_2_b_35_dil_5_blur_25_vid_June16_07.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_13_al_2_b_35_dil_5_blur_25\n",
      "working on ../TestResults/c1_12_c2_13_al_2_b_35_dil_5_blur_25_vid_June16_20.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_15_al_3_b_30_dil_7_blur_25\n",
      "working on ../TestResults/c1_12_c2_15_al_3_b_30_dil_7_blur_25_vid_June09_01.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_15_al_3_b_30_dil_7_blur_25\n",
      "working on ../TestResults/c1_12_c2_15_al_3_b_30_dil_7_blur_25_vid_June09_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_15_al_3_b_30_dil_7_blur_25\n",
      "working on ../TestResults/c1_12_c2_15_al_3_b_30_dil_7_blur_25_vid_June09_03.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_15_al_3_b_30_dil_7_blur_25\n",
      "working on ../TestResults/c1_12_c2_15_al_3_b_30_dil_7_blur_25_vid_June12_01.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_15_al_3_b_30_dil_7_blur_25\n",
      "working on ../TestResults/c1_12_c2_15_al_3_b_30_dil_7_blur_25_vid_June12_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_15_al_3_b_30_dil_7_blur_25\n",
      "working on ../TestResults/c1_12_c2_15_al_3_b_30_dil_7_blur_25_vid_June12_03.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_15_al_3_b_30_dil_7_blur_25\n",
      "working on ../TestResults/c1_12_c2_15_al_3_b_30_dil_7_blur_25_vid_June16_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_15_al_3_b_30_dil_7_blur_25\n",
      "working on ../TestResults/c1_12_c2_15_al_3_b_30_dil_7_blur_25_vid_June16_07.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_15_al_3_b_30_dil_7_blur_25\n",
      "working on ../TestResults/c1_12_c2_15_al_3_b_30_dil_7_blur_25_vid_June16_20.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_17_al_3_b_30_dil_6_blur_27\n",
      "working on ../TestResults/c1_12_c2_17_al_3_b_30_dil_6_blur_27_vid_June09_01.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_17_al_3_b_30_dil_6_blur_27\n",
      "working on ../TestResults/c1_12_c2_17_al_3_b_30_dil_6_blur_27_vid_June09_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_17_al_3_b_30_dil_6_blur_27\n",
      "working on ../TestResults/c1_12_c2_17_al_3_b_30_dil_6_blur_27_vid_June09_03.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_17_al_3_b_30_dil_6_blur_27\n",
      "working on ../TestResults/c1_12_c2_17_al_3_b_30_dil_6_blur_27_vid_June12_01.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_17_al_3_b_30_dil_6_blur_27\n",
      "working on ../TestResults/c1_12_c2_17_al_3_b_30_dil_6_blur_27_vid_June12_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_17_al_3_b_30_dil_6_blur_27\n",
      "working on ../TestResults/c1_12_c2_17_al_3_b_30_dil_6_blur_27_vid_June12_03.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_17_al_3_b_30_dil_6_blur_27\n",
      "working on ../TestResults/c1_12_c2_17_al_3_b_30_dil_6_blur_27_vid_June16_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_17_al_3_b_30_dil_6_blur_27\n",
      "working on ../TestResults/c1_12_c2_17_al_3_b_30_dil_6_blur_27_vid_June16_07.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_17_al_3_b_30_dil_6_blur_27\n",
      "working on ../TestResults/c1_12_c2_17_al_3_b_30_dil_6_blur_27_vid_June16_20.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_17_al_2.5_b_30_dil_5_blur_29\n",
      "working on ../TestResults/c1_12_c2_17_al_2.5_b_30_dil_5_blur_29_vid_June09_01.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_17_al_2.5_b_30_dil_5_blur_29\n",
      "working on ../TestResults/c1_12_c2_17_al_2.5_b_30_dil_5_blur_29_vid_June09_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_17_al_2.5_b_30_dil_5_blur_29\n",
      "working on ../TestResults/c1_12_c2_17_al_2.5_b_30_dil_5_blur_29_vid_June09_03.mp4.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed video\n",
      "checking for c1_12_c2_17_al_2.5_b_30_dil_5_blur_29\n",
      "working on ../TestResults/c1_12_c2_17_al_2.5_b_30_dil_5_blur_29_vid_June12_01.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_17_al_2.5_b_30_dil_5_blur_29\n",
      "working on ../TestResults/c1_12_c2_17_al_2.5_b_30_dil_5_blur_29_vid_June12_02.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_17_al_2.5_b_30_dil_5_blur_29\n",
      "working on ../TestResults/c1_12_c2_17_al_2.5_b_30_dil_5_blur_29_vid_June12_03.mp4.csv\n",
      "processed video\n",
      "checking for c1_12_c2_17_al_2.5_b_30_dil_5_blur_29\n",
      "working on ../TestResults/c1_12_c2_17_al_2.5_b_30_dil_5_blur_29_vid_June16_02.mp4.csv\n"
     ]
    }
   ],
   "source": [
    "from os.path import exists\n",
    "#loop through all parameters and videos \n",
    "for settings in randlistsettings:\n",
    "    thresh_div_1=settings[0]\n",
    "    thresh_div_2=settings[1]\n",
    "    alpha=settings[2]\n",
    "    dilation= settings[4]\n",
    "    beta=settings[3]\n",
    "    phase1_medianblur=settings[5]             \n",
    "    for video in vidlist:\n",
    "        outputcode = 'c1_'+str(thresh_div_1)+'_c2_'+\\\n",
    "                str(thresh_div_2)+'_al_'+str(alpha)+'_b_'+str(beta)+'_dil_'+\\\n",
    "                str(dilation)+'_blur_'+str(phase1_medianblur)\n",
    "        print('checking for ' + outputcode)\n",
    "        if not exists('../TestResults/' + outputcode + '_vid_' + os.path.basename(video) + '.csv'):\n",
    "            print('working on ' + '../TestResults/' + outputcode + '_vid_' + os.path.basename(video) + '.csv')\n",
    "            #if cannyt1 < cannyt2: #canny 2 needs to be lower\n",
    "\n",
    "            #set up empty output dataframe\n",
    "            column_names = ['frame','roi_x1','roi_y1','roi_x2', 'roi_y2', # info on region of interest for repetability\n",
    "                            'x','y', 'r', 'name',                    # actual results \n",
    "                            'alpha', 'beta',                              # values of brightness and contrast pre processing\n",
    "                            'minDist', 'threh_div1', 'threh_div2', 'dilation', 'phase1_medianblur'] # parameters of hough circle transform \n",
    "            df = pd.DataFrame(columns = column_names)\n",
    "            #outputf = os.path.abspath('./Output/'+outputcode+'.jpeg')\n",
    "            #if os.path.exists(outputf) == False:\n",
    "                #cnames = ['example1', 'example2', 'example3', 'example4', 'example5']\n",
    "                #rnames = ['original_'+str(alpha)+'_'+str(beta), 'blur_' + str(phase1_medianblur), 'dilation_' + str(dilation)]\n",
    "\n",
    "            #include roi here\n",
    "            #roi = roidefinition(video = video, height_buffer= 150, width_buffer = 300, dp =1, minRadius = minRadius, maxRadius = maxRadius)   \n",
    "            \n",
    "            roi = rois_dict[os.path.basename(video)[0:-4]]\n",
    "            \n",
    "                ####################DO ROUTINEand \n",
    "            cap = cv2.VideoCapture(video)\n",
    "            frameWidth = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "            frameHeight = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "            fps = cap.get(cv2.CAP_PROP_FPS)   #fps = frames per second\n",
    "            nameforfiles = i[0:-4]\n",
    "            imagesprocessed = []\n",
    "            #for imtoprocess in videos:\n",
    "            j = 0   \n",
    "            while(cap.isOpened()):\n",
    "                    ret, frame = cap.read()\n",
    "                    j=j+1\n",
    "                    name = 'framenr_' + str(j) + '_framevid_' +  os.path.basename(video)[0:-4]\n",
    "                    if ret == False:\n",
    "                        break\n",
    "                    ############################detect circles   \n",
    "                    output=frame.copy()\n",
    "                    image4, param1, param2 = preprocessing2(image=output)\n",
    "                        #track demicircles \n",
    "                    name = 'framenr_' + str(j) + '_framevid_' + os.path.basename(video[0:-4])\n",
    "                        # original values: dp = 1, minDist = 10000, param1=1, param2=10, minRadius = 5, maxRadius= 250\n",
    "                        #submit to \n",
    "                    image4 = image4[int(roi[1]):int(roi[1]+roi[3]), int(roi[0]):int(roi[0]+roi[2])]\n",
    "                    final_im = cv2.normalize(src=image4, dst=None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U) \n",
    "                    circles = cv2.HoughCircles(final_im, cv2.HOUGH_GRADIENT, \n",
    "                                                   dp = dp,minDist = minDist,  \n",
    "                                                   param1 = param1,param2 = param2,\n",
    "                                                   minRadius = minRadius, maxRadius = maxRadius)   \n",
    "\n",
    "                    if circles is not None:\n",
    "                            #circles = np.round(circles[0, 0:1]).astype(\"int\")\n",
    "                        if circles is not None:\n",
    "                            circles = np.round(circles[0, 0:1]).astype(\"int\")\n",
    "                            circle1 = circles[0,0]+roi[0] #x  + plus the shift from the roi\n",
    "                            circle2 = circles[0,1]+roi[1] #y  + plus the shift from the roi\n",
    "                            circle3 = circles[0,2]\n",
    "                        #    #save it to a row\n",
    "                        if circles is None:\n",
    "                            circle1 = \"NA\"\n",
    "                            circle2 = \"NA\"\n",
    "                            circle3 = \"NA\"\n",
    "                    new_row = [j, roi[0],roi[1], roi[2], roi[3], circle1, circle2,circle3, name,\n",
    "                                   alpha, beta, minDist, thresh_div_1, thresh_div_2, str(dilation), str(phase1_medianblur)]\n",
    "                    df.loc[len(df)] = new_row\n",
    "            print(\"processed video\")\n",
    "            filename =  '../TestResults/' + outputcode + '_vid_' + os.path.basename(video[0:-4]) + '.csv'\n",
    "            df.to_csv(filename, sep = ',')\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aa6c5d",
   "metadata": {},
   "source": [
    "# Loop through all videos in the video folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be886259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417fb269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c59903d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26952d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb3c35f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c23bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a4dd25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5369d01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
