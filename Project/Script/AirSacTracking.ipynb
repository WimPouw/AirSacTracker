{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3560a640",
   "metadata": {},
   "source": [
    "# Air Sac Tracking Prototype code\n",
    "Lara S. Burchardt & Wim Pouw\n",
    "\n",
    "lara.burchardt@donders.ru.nl\n",
    "\n",
    "Next to body movements and acoustics, we would also like to track the air sac's inflation of the Siamangs. The air sac naturally forms a spherical(3D) or circular (2D) shape, and such shapes are retrievable from an image using the hough transform, and a bit of pre-processing of the images to get the optimal representation of the relevent edges of the air sac.\n",
    "\n",
    "This code takes as input a sample video with a close up of a Siamang, and then tracks the air sac when it takes a sufficiently circular shape. The result is shown below; it is not perfect, but with a bit of smoothing this can function as a good air sac tracker. This code is very much under development, there are many ways to improve further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f75694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from skimage import io, feature, color, measure, draw, img_as_float\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "#resused code from \n",
    "#https://pyimagesearch.com/2014/07/21/detecting-circles-images-using-opencv-hough-circles/\n",
    "#https://stackoverflow.com/questions/31705355/how-to-detect-circlular-region-in-images-and-centre-it-with-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df270ef4",
   "metadata": {},
   "source": [
    "## Circular Tracker\n",
    "\n",
    "Using a video sample as input, the user first defines a region of interest in which to look for circular objects.\n",
    "After a few pre-processing steps to increase tracking success, the Hough Transform is used to find circles. \n",
    "The radius and position of the circle is saved together with the used parameter combination used in pre-processing and tracking. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03df20f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "videofolder= '../Video/'\n",
    "videofilename = 'sample.mp4'\n",
    "# Opens the Video file\n",
    "cap = cv2.VideoCapture(videofolder+videofilename)\n",
    "frameWidth = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "frameHeight = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)   #fps = frames per second\n",
    "\n",
    "#output video\n",
    "out = cv2.VideoWriter('./Output/output_'+videofilename,cv2.VideoWriter_fourcc(*'MP4V'), fps, \n",
    "                      (int(frameWidth), int(frameHeight)))\n",
    "\n",
    "#set up empty output dataframe\n",
    "column_names = ['frame','roi_x1','roi_y1','roi_x2', 'roi_y2', # info on region of interest for repetability\n",
    "                'x','y', 'r', 'inputfile',                    # actual results \n",
    "                'alpha', 'beta',                              # values of brightness and contrast pre processing\n",
    "                'dp', 'minDist', 'param1', 'param2', 'minRadius',' maxRadius'] # parameters of hough circle transform \n",
    "df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "#initialize iterator\n",
    "i=0\n",
    "# initialize parameters for pre-processing (used in cv2.convertScaleAbs)\n",
    "alpha = 1.5\n",
    "beta = 30\n",
    "\n",
    "# ROI, define a region of interest by mouse click on the first frame\n",
    "ret,frame = cap.read()\n",
    "    # select ROI\n",
    "roi  = cv2.selectROI('select the area', frame)\n",
    "#roi = [821, 351, 612, 488]       # if you want to re run a particular roi, input the roi values here\n",
    "\n",
    "#croppedFrame = frame[int(roi[1]): int(roi[1]+roi[3]),\n",
    "#                     int(roi[0]):int(roi[0]+roi[2])] \n",
    "\n",
    "\n",
    "#main loop                      \n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "          \n",
    "    ############################detect circles   \n",
    "    output=frame.copy()\n",
    "    # transform to grayscale image only using the roi part of the image\n",
    "    gray = cv2.cvtColor(frame[int(roi[1]): int(roi[1]+roi[3]),\n",
    "                     int(roi[0]):int(roi[0]+roi[2])] , cv2.COLOR_BGR2GRAY)\n",
    "    output_gray=gray.copy()\n",
    "    # increasing brightness and contrast\n",
    "    gray_light = cv2.convertScaleAbs(gray, alpha=alpha, beta=beta)\n",
    "    # apply GuassianBlur to reduce noise. medianBlur is also added for smoothening, reducing noise.\n",
    "    gray = cv2.GaussianBlur(gray_light,(11,11),0)\n",
    "    gray = cv2.medianBlur(gray, 19)\n",
    "    ##thresholded edge contouring\n",
    "    hist = cv2.equalizeHist(gray)\n",
    "    gamma = 2\n",
    "    invGamma = 1/gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "                      for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "    gamm = cv2.LUT(hist, table, hist)\n",
    "    submitted = cv2.Canny(gamm, 10, 50)            # why is minVal bigger than maxValue? original code was (gamm, 20, 10)\n",
    "    submitted = cv2.GaussianBlur(submitted,(7,7),0)\n",
    "    submitted = cv2.threshold(submitted, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "    submitted = cv2.dilate(submitted, None, iterations=9)  \n",
    "    submitted = cv2.erode(submitted, None, iterations=10) \n",
    "    submitted = cv2.GaussianBlur(submitted,(7,7),0) \n",
    "    submitted = cv2.erode(submitted, None, iterations=4)\n",
    "    \n",
    "    #track demicircles \n",
    "    # define parameters for HoughTransform outside of function to be able to save and manipulate easier\n",
    "    \n",
    "    dp = 1\n",
    "    minDist = 10000\n",
    "    param1 = 10\n",
    "    param2 = 10\n",
    "    minRadius = 5\n",
    "    maxRadius = 250\n",
    "    \n",
    "    # original values: dp = 1, minDist = 10000, param1=1, param2=10, minRadius = 5, maxRadius= 250\n",
    "    circles = cv2.HoughCircles(submitted, cv2.HOUGH_GRADIENT, \n",
    "                               dp = dp,minDist = minDist,  \n",
    "                               param1 = param1,param2 = param2, \n",
    "                               minRadius = minRadius, maxRadius = maxRadius)\n",
    "    if circles is not None:\n",
    "        circles = np.round(circles[0, 0:1]).astype(\"int\")\n",
    "        for (x, y, r) in circles:\n",
    "            #cv2.circle(output, (x, y), r, (255, 255, 0), 2) #version without drwaing roi back on whole image\n",
    "            cv2.circle(output[int(roi[1]): int(roi[1]+roi[3]),\n",
    "                     int(roi[0]):int(roi[0]+roi[2])], (x, y), r, (255, 255, 0), 2)\n",
    "            cv2.circle(submitted, (x, y), r, (200, 0, 0), 2)\n",
    "            #print(x,y,r)\n",
    "    cv2.waitKey(1)\n",
    "    out.write(output)\n",
    "    cv2.imshow(\"output\", submitted)\n",
    "    i=i+1\n",
    "\n",
    "# saving results and used parameters row wise during loop into a dataframe\n",
    "\n",
    "# canny min and max value should be added here, if they turn out to be sensitive\n",
    "    new_row = [i+1, roi[0],roi[1], roi[2], roi[3], circles[0,0], circles[0,1],circles [0,2], videofilename,\n",
    "               alpha, beta, dp, minDist, param1, param2, minRadius, maxRadius]\n",
    "    \n",
    "    df.loc[len(df)] = new_row\n",
    "            \n",
    "# filename and saving dataframe as cvs file       \n",
    "    filename =  'airsacradius_results_' + videofilename + '.csv'\n",
    "    df.to_csv(filename, sep = ',')\n",
    "\n",
    "# cleaning up\n",
    "out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db75575",
   "metadata": {},
   "source": [
    "# some more prototyping for auto ROI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1095714",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6f57d53",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9717f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROI, define a region of interest by mouse click on the first frame\n",
    "#ret,frame = cap.read()\n",
    "    # select ROI\n",
    "#roi  = cv2.selectROI('select the area', frame)\n",
    "#roi = [821, 351, 612, 488]       # if you want to re run a particular roi, input the roi values here\n",
    "\n",
    "#croppedFrame = frame[int(roi[1]): int(roi[1]+roi[3]),\n",
    "#                     int(roi[0]):int(roi[0]+roi[2])] \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69a7e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do\n",
    "\n",
    "# 1. include timepoints in output\n",
    "#    for each extracted radius, we also want to have the timepoint in the snippet to be able to correlate it with f0 as analyzed \n",
    "#    in praat or else, as we won't have the values for exactly the same timepoints \n",
    "#    for that we need the fps, that we already write, then multiply fps with frame number (should be i?) and write into output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ca8cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef6a7a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
