{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aedee532",
   "metadata": {},
   "source": [
    "# Air Sac Tracking Prototype code\n",
    "Lara S. Burchardt & Wim Pouw\n",
    "\n",
    "lara.burchardt@donders.ru.nl\n",
    "\n",
    "Next to body movements and acoustics, we would also like to track the air sac's inflation of the Siamangs. The air sac naturally forms a spherical(3D) or circular (2D) shape, and such shapes are retrievable from an image using the hough transform, and a bit of pre-processing of the images to get the optimal representation of the relevent edges of the air sac.\n",
    "\n",
    "This code takes as input a sample video with a close up of a Siamang, and then tracks the air sac when it takes a sufficiently circular shape. The result is shown below; it is not perfect, but with a bit of smoothing this can function as a good air sac tracker. This code is very much under development, there are many ways to improve further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4313bfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from skimage import io, feature, color, measure, draw, img_as_float\n",
    "import numpy as np\n",
    "import csv\n",
    "import random2\n",
    "import statistics\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy.signal import savgol_filter\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "\n",
    "#resused code from \n",
    "#https://pyimagesearch.com/2014/07/21/detecting-circles-images-using-opencv-hough-circles/\n",
    "#https://stackoverflow.com/questions/31705355/how-to-detect-circlular-region-in-images-and-centre-it-with-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544025a3",
   "metadata": {},
   "source": [
    "## Define Prepocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faf57f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define parameters for HoughTransform outside of function to be able to save and manipulate easier\n",
    "def hougdraw(submitted_image, dp = 1, mindist = 10000, param1 = 10, param2=22, minradius = 5, maxradius=250):\n",
    "    circles = cv2.HoughCircles(submitted_image, cv2.HOUGH_GRADIENT, \n",
    "                               dp = dp,minDist = mindist,  \n",
    "                               param1 = param1, param2 = param2, \n",
    "                               minRadius = minradius, maxRadius = maxradius)\n",
    "    if circles is not None:\n",
    "        circles = np.round(circles[0, 0:1]).astype(\"int\")\n",
    "        circle1 = circles[0,0]\n",
    "        circle2 = circles[0,1]\n",
    "        circle3 = circles[0,2]\n",
    "        for(x, y, r) in circles:\n",
    "            cv2.circle(submitted_image, (x, y), r, (255, 255, 0), 2) #version without drawing roi back on whole image \n",
    "    return(submitted_image)\n",
    "    \n",
    "# define function for preprocessing\n",
    "#def preprocessing(image, medianblur = 27, \n",
    "#                              dilation = 7, \n",
    "#                              alpha = 2, \n",
    "#                              beta= 30,\n",
    "#                              thresh_div_1=10,\n",
    "#                              thresh_div_2=15):\n",
    "#    #image0 = hougdraw(image)\n",
    "#    #convert to grayscale\n",
    "#    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "#    #brightness change\n",
    "#    gray = cv2.convertScaleAbs(gray, alpha = alpha, beta = beta)\n",
    "#    #set dynamic tresholds for canny (and thus also for hough)\n",
    "#    mean_intensity = np.median(gray)\n",
    "#    threshold1 = int(max(0, (1.0 - 0.33) * mean_intensity/thresh_div_1))\n",
    "#    threshold2 = int(min(255, (1.0 + 0.33) * mean_intensity/thresh_div_2))    \n",
    "#    image1_h = hougdraw(gray,param1= threshold1, param2 =threshold2)\n",
    "#    #blur\n",
    "#    image2 = cv2.medianBlur(gray, medianblur)\n",
    "#    image2_h = hougdraw(image2.copy(),param1= threshold1, param2 =threshold2)\n",
    "#    #dynamic thresholds for canny edge detection based on intensity of image\n",
    "#    #Thresholds one standard deviation above and below median intensity\n",
    "#    #edge detection\n",
    "#    image3 = cv2.Canny(image2, threshold1, threshold2)\n",
    "#    image3_h = hougdraw(image3.copy(), param1= threshold1, param2 =threshold2)\n",
    "#    #dilation and second blur\n",
    "#    submitted = cv2.dilate(image3, None, iterations= dilation)  \n",
    "#    image4 = cv2.medianBlur(submitted, medianblur) \n",
    "#    image4_h = hougdraw(image4.copy(), param1= threshold1, param2 =threshold2)\n",
    "#    #add hough\n",
    "#    return image1_h, image2_h, image3_h, image4_h\n",
    "############################################\n",
    "\n",
    "def preprocessing(image, medianblur = 27, \n",
    "                              dilation = 7, \n",
    "                              alpha = 2, \n",
    "                              beta= 30,\n",
    "                              thresh_div_1=10,\n",
    "                              thresh_div_2=15):\n",
    "    #image0 = hougdraw(image)\n",
    "    #convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    #brightness change\n",
    "    gray = cv2.convertScaleAbs(gray, alpha = alpha, beta = beta)\n",
    "    #set dynamic tresholds for canny (and thus also for hough)\n",
    "    mean_intensity = np.median(gray)\n",
    "    threshold1 = int(max(0, (1.0 - 0.33) * mean_intensity/thresh_div_1))\n",
    "    threshold2 = int(min(255, (1.0 + 0.33) * mean_intensity/thresh_div_2))    \n",
    "    #blur\n",
    "    image2 = cv2.medianBlur(gray, medianblur)\n",
    "    #dynamic thresholds for canny edge detection based on intensity of image\n",
    "    #Thresholds one standard deviation above and below median intensity\n",
    "    #edge detection\n",
    "    image3 = cv2.Canny(image2, threshold1, threshold2)\n",
    "    #dilation and second blur\n",
    "    submitted = cv2.dilate(image3, None, iterations= dilation)  \n",
    "    image4 = cv2.medianBlur(submitted, medianblur) \n",
    "    #add hough\n",
    "    image4 = np.float32(image4)\n",
    "    return image4, threshold1, threshold2\n",
    "\n",
    "def matriximages(outputname, wimagenumber, himagenumber, imagelist, marginbetweenimages, vertnames, hornames):\n",
    "    \"\"\"\n",
    "    matrix images takes in the full path name of the outputfolder for storing the images\n",
    "    it takes as input a list of full path names of the images\n",
    "    the height is given in image numbers and same for width\n",
    "    the vert names is a list of column names\n",
    "    the hor names is a list of row names\n",
    "    \"\"\"\n",
    "    margin = marginbetweenimages\n",
    "    #img = imagelist  \n",
    "    w = wimagenumber\n",
    "    h = himagenumber\n",
    "    n = w*h\n",
    "\n",
    "    #imgs = [cv2.imread(i) for i in imagelist]\n",
    "    imgs = imagelist\n",
    "    #if any(i.shape != imgs[0].shape for i in imgs[1:]):\n",
    "    #    raise ValueError('Not all images have the same shape.')\n",
    "\n",
    "    img_h, img_w = imgs[0].shape#img_h, img_w, img_c = imgs[0].shape\n",
    "\n",
    "    m_x = 0\n",
    "    m_y = 0\n",
    "    if marginbetweenimages is not None:\n",
    "        margin = marginbetweenimages\n",
    "        m_x = int(margin*img_w)\n",
    "        m_y = int(margin*img_h)\n",
    "        \n",
    "    imgmatrix = np.zeros((img_h * h + m_y * (h - 1),\n",
    "                          img_w * w + m_x * (w - 1)),\n",
    "                         np.uint8)\n",
    "\n",
    "    imgmatrix.fill(255)    \n",
    "\n",
    "    positions = itertools.product(range(w), range(h))\n",
    "    for (x_i, y_i), img in zip(positions, imgs):\n",
    "        x = x_i * (img_w + m_x)\n",
    "        y = y_i * (img_h + m_y)\n",
    "        imgmatrix[y:y+img_h, x:x+img_w] = img #imgmatrix[y:y+img_h, x:x+img_w, :] = img\n",
    "    #add text\n",
    "    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "    cv2.putText(imgmatrix, hornames[0], (0*img_w, int(img_h/4)), font, 10, (255, 255, 255), 5, cv2.LINE_AA)\n",
    "    cv2.putText(imgmatrix, hornames[1], (1*img_w,  int(img_h/4)), font, 10, (255, 255, 255), 5, cv2.LINE_AA)\n",
    "    cv2.putText(imgmatrix, hornames[2], (2*img_w, int(img_h/4)), font, 10, (255, 255, 255), 5, cv2.LINE_AA)\n",
    "    cv2.putText(imgmatrix, hornames[3], (3*img_w, int(img_h/4)), font, 10, (255, 255, 255), 5, cv2.LINE_AA)\n",
    "    cv2.putText(imgmatrix, hornames[4], (4*img_w, int(img_h/4)), font, 10, (255, 255, 255), 5, cv2.LINE_AA)\n",
    "    cv2.putText(imgmatrix, vertnames[0], (0, 1*img_h), font, 10, (255, 255, 255), 5, cv2.LINE_AA)\n",
    "    cv2.putText(imgmatrix, vertnames[1], (0, 2*img_h), font, 10, (255, 255, 255), 5, cv2.LINE_AA)\n",
    "    cv2.putText(imgmatrix, vertnames[2], (0, 3*img_h), font, 10, (255, 255, 255), 5, cv2.LINE_AA)\n",
    "    cv2.putText(imgmatrix, vertnames[3], (0, 4*img_h), font, 10, (255, 255, 255), 5, cv2.LINE_AA)\n",
    "    #cv2.putText(imgmatrix, vertnames[4], (0, 5*img_h), font, 10, (0, 255, 0), 5, cv2.LINE_AA)\n",
    "    cv2.imwrite(outputname, imgmatrix)   \n",
    "    \n",
    "    print('done, look in your folder: '+ outputname)\n",
    "    \n",
    "    \n",
    "def roidefinition(video, height_buffer, width_buffer, dp, minRadius, maxRadius):\n",
    "    cap = cv2.VideoCapture(video)\n",
    "    totalFrames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    #frameWidth = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    #frameHeight = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "    #fps = cap.get(cv2.CAP_PROP_FPS)   #fps = frames per second\n",
    "    #set up empty output dataframe\n",
    "    column_names = ['x','y', 'r', 'frame'] # we are going to collect hough generated x,y,r,frame from random set of frames\n",
    "    df_round_1 = pd.DataFrame(columns = column_names) \n",
    "    vector = range(0, int(totalFrames), 1)\n",
    "    samp = random2.sample(vector, 45) #50 is the setting\n",
    "    for rand in samp:\n",
    "        # set frame position\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES,rand)\n",
    "        ret, frame = cap.read()\n",
    "        ############################detect circles   \n",
    "        output=frame.copy()\n",
    "        # transform to grayscale image only using the roi part of the image\n",
    "        image4, param1, param2 = preprocessing(image=output)\n",
    "        final_im = cv2.normalize(src=image4, dst=None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "        #final_im = image4\n",
    "        circles = cv2.HoughCircles(final_im, cv2.HOUGH_GRADIENT, \n",
    "                                   dp = dp,minDist = minDist,  \n",
    "                                   param1 = param1,param2 = param2, \n",
    "                                   minRadius = minRadius, maxRadius = maxRadius)\n",
    "        #if circles is not None:\n",
    "        #    circles = np.round(circles[0, 0:1]).astype(\"int\")\n",
    "        if circles is not None:\n",
    "            #circles = np.round(circles[0, 0:1]).astype(\"int\")\n",
    "            if circles is not None:\n",
    "                circles = np.round(circles[0, 0:1]).astype(\"int\")\n",
    "                circle1 = circles[0,0]\n",
    "                circle2 = circles[0,1]\n",
    "                circle3 = circles[0,2]\n",
    "            #save it to a row\n",
    "            if circles is None:\n",
    "                circle1 = \"NA\"\n",
    "                circle2 = \"NA\"\n",
    "                circle3 = \"NA\"\n",
    "        new_row = [circles[0,0], circles[0,1],circles [0,2], rand]\n",
    "        df_round_1.loc[len(df_round_1)] = new_row\n",
    "\n",
    "    #when collected take some info\n",
    "    median_x = df_round_1['x'].median() #order in pos : same as in original dataframe, so x,y, r\n",
    "    median_y = df_round_1['y'].median()\n",
    "    max_r = df_round_1['r'].max()\n",
    "    min_r = df_round_1['r'].min()\n",
    "    # order of parameters saved as roi with cv2.selectROI [Top_Left_X, Top_Left_Y, Width, Height]\n",
    "\n",
    "    # explanation: height_1 is the maximum radius detected plus 30 pixels, that is used to determine the position of the \n",
    "    # upper left corner of the roi, same goes for width_1, both are currently the same, but that could change, so they are both\n",
    "    # coded independently\n",
    "    height_1 = max_r + height_buffer #i.e.100, in pixels\n",
    "    width_1 = max_r + width_buffer #250, in pixels\n",
    "    pos_x = median_x - width_1\n",
    "    pos_y = median_y - height_1  \n",
    "    # to be consistent with the roi nomenclature, we then calculate the width/height of the whole roi which is width_1 *2\n",
    "        # all those values will then be used to crop picture in next round of tracking\n",
    "    width_2 = width_1 * 2\n",
    "    height_2 = height_1 *2\n",
    "    #\n",
    "    roi = [pos_x, pos_y, width_2, height_2]\n",
    "    cap.release() #release the video\n",
    "    return roi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d675c31",
   "metadata": {},
   "source": [
    "# track a video with template matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80836419",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1105\n",
      "1105\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gray1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-9ff68bb07436>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[0mthreshold1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mskimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold_otsu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_a\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[0mthreshold2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mskimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold_otsu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_b\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m             \u001b[0mbinarized1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgray1\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mthreshold1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m             \u001b[0mbinarized2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgray2\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mthreshold2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[1;31m# measure of the structural similarity between the images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gray1' is not defined"
     ]
    }
   ],
   "source": [
    "# preprocessing, choosing a roi on the tracking results of 50 random samples from input file\n",
    "#https://github.com/patchy631/machine-learning/blob/main/computer_vision/cv2_edge_detection.ipynb\n",
    "import sys\n",
    "from skimage.measure import compare_ssim\n",
    "from skimage.transform import resize\n",
    "\n",
    "############settings that worked: c1_5_c2_10_al_1_b_12_dil_7_blur_27\n",
    "alpha = 2\n",
    "beta = 20\n",
    "dp = 1\n",
    "dilation = 5\n",
    "phase1_medianblur = 27\n",
    "#cannyt1 = 5\n",
    "#cannyt2 = 12 \n",
    "minDist = 10000\n",
    "minRadius = 5 #minus 2times std\n",
    "maxRadius = 260 #dynamic? \n",
    "###################\n",
    "videofolder= '../Video/'\n",
    "nameforfiles = 'example1'\n",
    "videofilename = nameforfiles +'.mp4'\n",
    "# Opens the Video file\n",
    "cap = cv2.VideoCapture(videofolder+videofilename)\n",
    "totalFrames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "frameWidth = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "frameHeight = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)   #fps = frames per second\n",
    "\n",
    "#set up empty output dataframe\n",
    "column_names = ['x','y', 'r', 'frame'] # we are going to collect hough generated x,y,r,frame from random set of frames\n",
    "df_round_1 = pd.DataFrame(columns = column_names) \n",
    "vector = range(0, int(totalFrames), 1)\n",
    "samp = random2.sample(vector, 40) #50 is the setting\n",
    "\n",
    "out = cv2.VideoWriter('./Output/videos/output_'+videofilename,cv2.VideoWriter_fourcc(*'MP4V'), fps, \n",
    "                      (int(frameWidth), int(frameHeight)))\n",
    "t_image = cv2.imread('./Output/videos/template_test.jpg')\n",
    "t_gray_image = cv2.cvtColor(t_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#main loop                      \n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    # set frame position\n",
    "\n",
    "    ############################detect circles   \n",
    "    output=frame.copy()\n",
    "    # transform to grayscale image only using the roi part of the image\n",
    "    image4, param1, param2 = preprocessing(image=output)\n",
    "    final_im = cv2.normalize(src=image4, dst=0.01, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    circles = cv2.HoughCircles(final_im, cv2.HOUGH_GRADIENT, \n",
    "                               dp = dp,minDist =10,#when you lower mindist, more candidate circles are given  \n",
    "                               param1 = param1,param2 = param2, \n",
    "                               minRadius = minRadius, maxRadius = maxRadius)\n",
    "    print(len(circles[0])) #how many circles?\n",
    "    #######NEW CHECK WIM to check for multiple circles and choose best match based on template matching\n",
    "    # Iterate over the detected circles\n",
    "    fits = []\n",
    "    circles = circles[0]\n",
    "    print(len(circles))\n",
    "    for i in circles:\n",
    "        # Get the coordinates of the center and the radius of the circle\n",
    "        x, y, r = i[0], i[1], abs(i[2])\n",
    "        tim = frame.copy()\n",
    "        tim = cv2.cvtColor(tim, cv2.COLOR_BGR2GRAY)\n",
    "        template1 = tim[int(y-r):int(y+r), int(x-r):int(x+r)]\n",
    "\n",
    "        height1, width1 =  template1.shape\n",
    "        height2, width2 =  t_gray_image.shape\n",
    "        res = 0\n",
    "        # Check if the images are the same size; and than compute a distance measure\n",
    "        if (height1 < height2) & (width1 < width2) & (height1 != 0) & (width1 !=0): \n",
    "            # get two images - resize both to 1024 x 1024\n",
    "            img_a = resize(template1, (2**10, 2**10))\n",
    "            img_b = resize(t_gray_image, (2**10, 2**10))\n",
    "\n",
    "            # measure of the structural similarity between the images\n",
    "            res, diff = compare_ssim(img_a, img_b, full=True)\n",
    "            print(res)\n",
    "        #    res = cv2.matchTemplate(t_gray_image, template1, cv2.TM_CCOEFF_NORMED)   \n",
    "        #    np.max(maxs)            \n",
    "        fits.append(res)\n",
    "    #which fits has the highest match? \n",
    "    index = fits.index(max(fits))\n",
    "    print(index)\n",
    "    circles = circles[index]   \n",
    "    #if circles is not None:\n",
    "    #    circles = np.round(circles[0, 0:1]).astype(\"int\")\n",
    "    if circles is not None:\n",
    "        #circles = np.round(circles[0, 0:1]).astype(\"int\")\n",
    "        if circles is not None:\n",
    "            circles = np.round(circles).astype(\"int\")\n",
    "            circle1 = circles[0]\n",
    "            circle2 = circles[1]\n",
    "            circle3 = circles[2]\n",
    "            cv2.circle(frame, (int(circle1), int(circle2)), circle3, (200, 0, 0), 2)\n",
    "        #save it to a row\n",
    "        if circles is None:\n",
    "            circle1 = \"NA\"\n",
    "            circle2 = \"NA\"\n",
    "            circle3 = \"NA\"\n",
    "    out.write(frame)\n",
    "    #new_row = [circle1, circle2,circle3]\n",
    "    #df_round_1.loc[len(df_round_1)] = new_row\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "# cleaning up\n",
    "out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af65e9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0.827359638002021,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0.6757403327393073,\n",
       " 0.6333686101924254,\n",
       " 0.6527063831644788,\n",
       " 0.47610972484885045,\n",
       " 0.7065066154390784,\n",
       " 0.74253207151064,\n",
       " 0.3982477924183871,\n",
       " 0.7492764962510086]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c293102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1316,  500,  114])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "cc28d19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "417fb269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3febacae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143.1"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2c59903d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1184.5  560.5  140.9]\n",
      "[1253.5  401.5  237.4]\n",
      "[1498.5  821.5  214.5]\n",
      "[1543.5  577.5  212.9]\n",
      "[1618.5  691.5  177.2]\n",
      "[1527.5  265.5  259.4]\n",
      "[1604.5  485.5  171.2]\n",
      "[1435.5  928.5  184.8]\n",
      "[1386.5  785.5   97.3]\n",
      "[1378.5  472.5   94.5]\n",
      "[1395.5  652.5  135.3]\n",
      "[1546.5  968.5  165.8]\n",
      "[1209.5  720.5  122.6]\n",
      "[1197.5  290.5  113.4]\n",
      "[1148.5  387.5  227.1]\n",
      "[1610.5  175.5  216. ]\n",
      "[1781.5  786.5  132.3]\n",
      "[1424.5 1031.5  216.2]\n",
      "[1078.5  258.5   32.3]\n",
      "[1498.5  676.5  183.9]\n",
      "[1688.5  580.5   96.9]\n",
      "[1423.5  349.5  133.4]\n",
      "[1585.5   30.5   55.1]\n",
      "[191.5 712.5  73.9]\n",
      "[1602.5  843.5   88.1]\n",
      "[1181.5  858.5  104.8]\n",
      "[1665.5  403.5   64.9]\n",
      "[324.5 523.5  47.2]\n",
      "[1766.5  652.5  103.6]\n",
      "[ 751.5 1024.5   48.1]\n",
      "[1276.5  499.5  110.6]\n",
      "[714.5 367.5  51.2]\n",
      "[1774.5   89.5   65.5]\n",
      "[1498.5  416.5   78.3]\n",
      "[ 82.5 655.5  64.6]\n",
      "[1100.5  751.5  144.7]\n",
      "[1350.5  272.5   46.3]\n",
      "[955.5 342.5 159.3]\n",
      "[1726.5  874.5  100.1]\n",
      "[1507.5  121.5   16.3]\n",
      "[1279.5  637.5   40.2]\n",
      "[1322.5 1006.5   46.3]\n",
      "[1846.5  993.5    9.6]\n",
      "[1720.5  316.5   60.7]\n",
      "[623.5 735.5  11.8]\n",
      "[1707.5 1013.5   35.8]\n",
      "[ 57.5 853.5  30.8]\n",
      "[1304.5  875.5   27.7]\n",
      "[175.5 588.5  17. ]\n",
      "[795.5 201.5  19. ]\n",
      "[1357.5  142.5   89.6]\n",
      "[1724.5  177.5   47.4]\n",
      "[1002.5   41.5   10.3]\n",
      "[1247.5  203.5   41.6]\n",
      "[1762.5  484.5   24.9]\n",
      "[1440.5  557.5   21.6]\n",
      "[1087.5  636.5   17.7]\n",
      "[1846.5   17.5   12.1]\n",
      "[1577.5  352.5   21.2]\n",
      "[142.5 948.5   7.1]\n",
      "[714.5 546.5  11.8]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26952d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb3c35f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c23bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a4dd25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5369d01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
