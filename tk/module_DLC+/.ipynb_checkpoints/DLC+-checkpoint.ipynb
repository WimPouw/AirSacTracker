{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module to process video DLC model\n",
    "\n",
    "This module belongs to the manuscript \"Burchardt, L., Van de Sande, Y., Kehy, M., Gamba, M., Ravignani, A., Pouw, W. A complete computational and data toolkit for the dynamic study of laryngeal air sacs in Siamang (Symphalangus syndactylus) with applications for spherical tracking in other animals\".\n",
    "\n",
    "This contains a module for tracking Siamang head and air sack postures. The following keypoints will be tracked by a trained resnet 101 model:\n",
    "- UpperLip\n",
    "- LowerLip\n",
    "- Nose\n",
    "- EyeBridge\n",
    "- Start_outline_outer_left\n",
    "- Start_outline_outer_right\n",
    "- LowestPoint_outline\n",
    "- MidLowleft_outline\n",
    "- MidLowright_outline\n",
    "\n",
    "Note that Deeplabcut needs to be installed (in command prompt \"pip install -r requirements.txt\"). By default the CPU version is installed. Please see the original documentation of DeepLabCut to ensure GPU compatibility if you want to speed up the tracking process. We do recommend to use a GPU supported deeplabcut.\n",
    "\n",
    "The trained resnet101 model needs to be downloaded first from google drive; so please go to the following folder and follow the download link and download to that folder: \"./AirSacTracker/Toolkit/module_process_video_DLC_model/trained_model_and_metainfo/dlc-models/iteration-0/Deep_AirSacTrackingV1Jan1-trainset95shuffle1/train/\". \n",
    "\n",
    "# Example Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"https://tsg-131-174-75-200.hosting.ru.nl/samples_airsactoolkit/June16_02_circle_rec.mp4\" controls  width=\"600\"  height=\"500\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "video_url = 'https://tsg-131-174-75-200.hosting.ru.nl/samples_airsactoolkit/June16_02_circle_rec.mp4'  # Replace this with your video URL\n",
    "Video(video_url, width=600, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in all the packages needed:\n",
    "\n",
    "# processing the videos with deeplabcut:\n",
    "import deeplabcut\n",
    "import os\n",
    "import shutil\n",
    "from os.path import isfile, join\n",
    "from IPython.display import Video\n",
    "\n",
    "# performing a circle estimation with Landau algorithm:\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "# plot landau circles on processed video:\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import cv2\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated your DLC version to 2.5.2 in your environment\n",
      "we updated your Pandas version to 2.0.2 in your environment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement deeplabcut==2.5.2 (from versions: 2.0.0.dev1, 2.0.0.dev2, 2.0.0.dev3, 2.0.0.dev4, 2.0.0.dev5, 2.0.0.dev6, 2.0.0.dev7, 2.0.0, 2.0.1, 2.0.2, 2.0.3, 2.0.4, 2.0.4.1, 2.0.5, 2.0.5.1, 2.0.6, 2.0.6.2, 2.0.6.3, 2.0.7, 2.0.7.1, 2.0.7.2, 2.0.8, 2.0.9, 2.1, 2.1.1, 2.1.2, 2.1.3, 2.1.4, 2.1.5, 2.1.5.1, 2.1.5.2, 2.1.6, 2.1.6.1, 2.1.6.2, 2.1.6.3, 2.1.6.4, 2.1.6.5, 2.1.7, 2.1.7.1, 2.1.8b0, 2.1.8, 2.1.8.1, 2.1.8.2, 2.1.9, 2.1.9.1, 2.1.10, 2.1.10.1, 2.1.10.2, 2.1.10.3, 2.1.10.4, 2.2b5, 2.2b6, 2.2b7, 2.2b8, 2.2rc1, 2.2rc2, 2.2rc3, 2.2.0.2, 2.2.0.3, 2.2.0.4, 2.2.0.5, 2.2.0.6, 2.2.1rc1, 2.2.1, 2.2.1.1, 2.2.2, 2.2.3, 2.3rc1, 2.3rc2, 2.3rc3, 2.3.0, 2.3.1, 2.3.2, 2.3.3, 2.3.4, 2.3.5)\n",
      "ERROR: No matching distribution found for deeplabcut==2.5.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==1.5.3 in c:\\users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages (from pandas==1.5.3) (1.21.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages (from pandas==1.5.3) (2022.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages (from pandas==1.5.3) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages (from python-dateutil>=2.8.1->pandas==1.5.3) (1.16.0)\n",
      "we updated your numpy version to 1.23.2 in your environment\n",
      "we updated your cv2 version to 4.7.0 in your environment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: 'numpy=1.23.2'\n",
      "Hint: = is not a valid operator. Did you mean == ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please restart your kernel and run the next cell to import packages with the correct version for this notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: 'cv2=4.7.0'\n",
      "Hint: = is not a valid operator. Did you mean == ?\n"
     ]
    }
   ],
   "source": [
    "#check dependencies \n",
    "print_request = False\n",
    "#if deeplabcut.__version__ != '2.3.5':\n",
    "#    print(\"Updated your DLC version to 2.3.5 in your environment\")\n",
    "#    !pip install deeplabcut==2.3.5\n",
    "#    print_request = True\n",
    "\n",
    "if deeplabcut.__version__ != '2.3.5':\n",
    "    print(\"Updated your DLC version to 2.3.5 in your environment\")\n",
    "    !pip install deeplabcut==2.3.5\n",
    "    print_request = True\n",
    "\n",
    "if pd.__version__ != '1.5.3':\n",
    "    print(\"we updated your Pandas version to 2.0.2 in your environment\")\n",
    "    !pip install pandas==1.5.3\n",
    "    print_request = True\n",
    "\n",
    "if np.__version__ != '1.23.2':\n",
    "    print(\"we updated your numpy version to 1.23.2 in your environment\")\n",
    "    !pip install numpy=1.23.2\n",
    "    print_request = True\n",
    "\n",
    "\n",
    "if cv2.__version__ != '4.7.0':\n",
    "    print(\"we updated your cv2 version to 4.7.0 in your environment\")\n",
    "    !pip install cv2=4.7.0\n",
    "    print_request = True\n",
    "\n",
    "\n",
    "if print_request:\n",
    "    print(\"Please restart your kernel and run the next cell to import packages with the correct version for this notebook\")\n",
    "\n",
    "\n",
    "#you might have to restart your kernel for the packages to be the correct "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: processing your video with DLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to process: example8.mp4\n"
     ]
    }
   ],
   "source": [
    "# load the pre-trained model settings\n",
    "config_path = \"./DLC/trained_model_and_metainfo/config.yaml\"\n",
    "\n",
    "# where are we going to save our tracked results to?\n",
    "output_dir = \"./DLC/output/\"\n",
    "\n",
    "# set videofolder from which we are going to process\n",
    "videofolder = \"../input/\"\n",
    "\n",
    "# loading in the videos\n",
    "vids = [f for f in os.listdir(videofolder) if isfile(join(videofolder, f))]\n",
    "for i in vids:\n",
    "    print('to process: ' + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'embedded'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [259]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# display the first video in the set\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mVideo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideofolder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvids\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedded\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'embedded'"
     ]
    }
   ],
   "source": [
    "# display the first video in the set\n",
    "Video(videofolder + vids[0], width=300, height=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-500000 for model ./DLC/trained_model_and_metainfo\\dlc-models\\iteration-0\\Deep_AirSacTrackingV1Jan1-trainset95shuffle1\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nGraph execution error:\n\nDetected at node 'save/RestoreV2' defined at (most recent call last):\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 461, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 450, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in dispatch_shell\n      await result\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 652, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2768, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2814, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3012, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3191, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3251, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\u668173\\AppData\\Local\\Temp\\ipykernel_992\\1381109926.py\", line 5, in <module>\n      deeplabcut.analyze_videos(\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\predict_videos.py\", line 602, in analyze_videos\n      sess, inputs, outputs = predict.setup_GPUpose_prediction(\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\core\\predict.py\", line 215, in setup_GPUpose_prediction\n      restorer = tf.compat.v1.train.Saver()\nNode: 'save/RestoreV2'\nDetected at node 'save/RestoreV2' defined at (most recent call last):\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 461, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 450, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in dispatch_shell\n      await result\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 652, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2768, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2814, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3012, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3191, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3251, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\u668173\\AppData\\Local\\Temp\\ipykernel_992\\1381109926.py\", line 5, in <module>\n      deeplabcut.analyze_videos(\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\predict_videos.py\", line 602, in analyze_videos\n      sess, inputs, outputs = predict.setup_GPUpose_prediction(\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\core\\predict.py\", line 215, in setup_GPUpose_prediction\n      restorer = tf.compat.v1.train.Saver()\nNode: 'save/RestoreV2'\n2 root error(s) found.\n  (0) NOT_FOUND: NewRandomAccessFile failed to Create/Open: ./DLC/trained_model_and_metainfo\\dlc-models\\iteration-0\\Deep_AirSacTrackingV1Jan1-trainset95shuffle1\\train\\snapshot-500000.data-00000-of-00001 : The system cannot find the file specified.\r\n; No such file or directory\n\t [[{{node save/RestoreV2}}]]\n\t [[save/RestoreV2/_79]]\n  (1) NOT_FOUND: NewRandomAccessFile failed to Create/Open: ./DLC/trained_model_and_metainfo\\dlc-models\\iteration-0\\Deep_AirSacTrackingV1Jan1-trainset95shuffle1\\train\\snapshot-500000.data-00000-of-00001 : The system cannot find the file specified.\r\n; No such file or directory\n\t [[{{node save/RestoreV2}}]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'save/RestoreV2':\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n    app.start()\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n    self.io_loop.start()\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n    self._run_once()\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n    handle._run()\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\asyncio\\events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 461, in dispatch_queue\n    await self.process_one()\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 450, in process_one\n    await dispatch(*args)\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in dispatch_shell\n    await result\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 652, in execute_request\n    reply_content = await reply_content\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2768, in run_cell\n    result = self._run_cell(\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2814, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3012, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3191, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3251, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"C:\\Users\\u668173\\AppData\\Local\\Temp\\ipykernel_992\\1381109926.py\", line 5, in <module>\n    deeplabcut.analyze_videos(\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\predict_videos.py\", line 602, in analyze_videos\n    sess, inputs, outputs = predict.setup_GPUpose_prediction(\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\core\\predict.py\", line 215, in setup_GPUpose_prediction\n    restorer = tf.compat.v1.train.Saver()\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 933, in __init__\n    self.build()\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 945, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 973, in _build\n    self.saver_def = self._builder._build_internal(  # pylint: disable=protected-access\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 543, in _build_internal\n    restore_op = self._AddRestoreOps(filename_tensor, saveables,\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 363, in _AddRestoreOps\n    all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 611, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1500, in restore_v2\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 797, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3754, in _create_op_internal\n    ret = Operation(\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2133, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1377\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1360\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1359\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_graph()\n\u001b[1;32m-> 1360\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_tf_sessionrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1361\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1453\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1451\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_tf_sessionrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[0;32m   1452\u001b[0m                         run_metadata):\n\u001b[1;32m-> 1453\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRun_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1454\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1455\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: 2 root error(s) found.\n  (0) NOT_FOUND: NewRandomAccessFile failed to Create/Open: ./DLC/trained_model_and_metainfo\\dlc-models\\iteration-0\\Deep_AirSacTrackingV1Jan1-trainset95shuffle1\\train\\snapshot-500000.data-00000-of-00001 : The system cannot find the file specified.\r\n; No such file or directory\n\t [[{{node save/RestoreV2}}]]\n\t [[save/RestoreV2/_79]]\n  (1) NOT_FOUND: NewRandomAccessFile failed to Create/Open: ./DLC/trained_model_and_metainfo\\dlc-models\\iteration-0\\Deep_AirSacTrackingV1Jan1-trainset95shuffle1\\train\\snapshot-500000.data-00000-of-00001 : The system cannot find the file specified.\r\n; No such file or directory\n\t [[{{node save/RestoreV2}}]]\n0 successful operations.\n0 derived errors ignored.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1417\u001b[0m, in \u001b[0;36mSaver.restore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1416\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1417\u001b[0m     \u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaver_def\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore_op_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1418\u001b[0m \u001b[43m             \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaver_def\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename_tensor_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1419\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1420\u001b[0m   \u001b[38;5;66;03m# There are three common conditions that might cause this error:\u001b[39;00m\n\u001b[0;32m   1421\u001b[0m   \u001b[38;5;66;03m# 0. The file is missing. We ignore here, as this is checked above.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1425\u001b[0m   \u001b[38;5;66;03m# 1. The checkpoint would not be loaded successfully as is. Try to parse\u001b[39;00m\n\u001b[0;32m   1426\u001b[0m   \u001b[38;5;66;03m# it as an object-based checkpoint.\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\client\\session.py:967\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 967\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    969\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n",
      "File \u001b[1;32m~\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1190\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_fetches \u001b[38;5;129;01mor\u001b[39;00m final_targets \u001b[38;5;129;01mor\u001b[39;00m (handle \u001b[38;5;129;01mand\u001b[39;00m feed_dict_tensor):\n\u001b[1;32m-> 1190\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_fetches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1191\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfeed_dict_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1370\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1370\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_run_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1371\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1372\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1396\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1392\u001b[0m   message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mA possible workaround: Try disabling Grappler optimizer\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1393\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mby modifying the config for creating the session eg.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1394\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124msession_config.graph_options.rewrite_options.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1395\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisable_meta_optimizer = True\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1396\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(node_def, op, message)\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Graph execution error:\n\nDetected at node 'save/RestoreV2' defined at (most recent call last):\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 461, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 450, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in dispatch_shell\n      await result\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 652, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2768, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2814, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3012, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3191, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3251, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\u668173\\AppData\\Local\\Temp\\ipykernel_992\\1381109926.py\", line 5, in <module>\n      deeplabcut.analyze_videos(\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\predict_videos.py\", line 602, in analyze_videos\n      sess, inputs, outputs = predict.setup_GPUpose_prediction(\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\core\\predict.py\", line 215, in setup_GPUpose_prediction\n      restorer = tf.compat.v1.train.Saver()\nNode: 'save/RestoreV2'\nDetected at node 'save/RestoreV2' defined at (most recent call last):\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 461, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 450, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in dispatch_shell\n      await result\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 652, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2768, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2814, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3012, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3191, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3251, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\u668173\\AppData\\Local\\Temp\\ipykernel_992\\1381109926.py\", line 5, in <module>\n      deeplabcut.analyze_videos(\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\predict_videos.py\", line 602, in analyze_videos\n      sess, inputs, outputs = predict.setup_GPUpose_prediction(\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\core\\predict.py\", line 215, in setup_GPUpose_prediction\n      restorer = tf.compat.v1.train.Saver()\nNode: 'save/RestoreV2'\n2 root error(s) found.\n  (0) NOT_FOUND: NewRandomAccessFile failed to Create/Open: ./DLC/trained_model_and_metainfo\\dlc-models\\iteration-0\\Deep_AirSacTrackingV1Jan1-trainset95shuffle1\\train\\snapshot-500000.data-00000-of-00001 : The system cannot find the file specified.\r\n; No such file or directory\n\t [[{{node save/RestoreV2}}]]\n\t [[save/RestoreV2/_79]]\n  (1) NOT_FOUND: NewRandomAccessFile failed to Create/Open: ./DLC/trained_model_and_metainfo\\dlc-models\\iteration-0\\Deep_AirSacTrackingV1Jan1-trainset95shuffle1\\train\\snapshot-500000.data-00000-of-00001 : The system cannot find the file specified.\r\n; No such file or directory\n\t [[{{node save/RestoreV2}}]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'save/RestoreV2':\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n    app.start()\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n    self.io_loop.start()\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n    self._run_once()\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n    handle._run()\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\asyncio\\events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 461, in dispatch_queue\n    await self.process_one()\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 450, in process_one\n    await dispatch(*args)\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in dispatch_shell\n    await result\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 652, in execute_request\n    reply_content = await reply_content\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2768, in run_cell\n    result = self._run_cell(\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2814, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3012, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3191, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3251, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"C:\\Users\\u668173\\AppData\\Local\\Temp\\ipykernel_992\\1381109926.py\", line 5, in <module>\n    deeplabcut.analyze_videos(\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\predict_videos.py\", line 602, in analyze_videos\n    sess, inputs, outputs = predict.setup_GPUpose_prediction(\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\core\\predict.py\", line 215, in setup_GPUpose_prediction\n    restorer = tf.compat.v1.train.Saver()\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 933, in __init__\n    self.build()\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 945, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 973, in _build\n    self.saver_def = self._builder._build_internal(  # pylint: disable=protected-access\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 543, in _build_internal\n    restore_op = self._AddRestoreOps(filename_tensor, saveables,\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 363, in _AddRestoreOps\n    all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 611, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1500, in restore_v2\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 797, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3754, in _create_op_internal\n    ret = Operation(\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2133, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py:66\u001b[0m, in \u001b[0;36mget_tensor\u001b[1;34m(self, tensor_str)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 66\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCheckpointReader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCheckpointReader_GetTensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_str\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# TODO(b/143319754): Remove the RuntimeError casting logic once we resolve the\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# issue with throwing python exceptions from C++.\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1428\u001b[0m, in \u001b[0;36mSaver.restore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1427\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1428\u001b[0m   names_to_keys \u001b[38;5;241m=\u001b[39m \u001b[43mobject_graph_key_mapping\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1429\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError:\n\u001b[0;32m   1430\u001b[0m   \u001b[38;5;66;03m# 2. This is not an object-based checkpoint, which likely means there\u001b[39;00m\n\u001b[0;32m   1431\u001b[0m   \u001b[38;5;66;03m# is a graph mismatch. Re-raise the original error with\u001b[39;00m\n\u001b[0;32m   1432\u001b[0m   \u001b[38;5;66;03m# a helpful message (b/110263146)\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1749\u001b[0m, in \u001b[0;36mobject_graph_key_mapping\u001b[1;34m(checkpoint_path)\u001b[0m\n\u001b[0;32m   1748\u001b[0m reader \u001b[38;5;241m=\u001b[39m py_checkpoint_reader\u001b[38;5;241m.\u001b[39mNewCheckpointReader(checkpoint_path)\n\u001b[1;32m-> 1749\u001b[0m object_graph_string \u001b[38;5;241m=\u001b[39m \u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrackable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOBJECT_GRAPH_PROTO_KEY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1750\u001b[0m object_graph_proto \u001b[38;5;241m=\u001b[39m (trackable_object_graph_pb2\u001b[38;5;241m.\u001b[39mTrackableObjectGraph())\n",
      "File \u001b[1;32m~\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py:71\u001b[0m, in \u001b[0;36mget_tensor\u001b[1;34m(self, tensor_str)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 71\u001b[0m   \u001b[43merror_translator\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py:31\u001b[0m, in \u001b[0;36merror_translator\u001b[1;34m(e)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot found in checkpoint\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_message \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to find any \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatching files for\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m error_message:\n\u001b[1;32m---> 31\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors_impl\u001b[38;5;241m.\u001b[39mNotFoundError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, error_message)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSliced checkpoints are not supported\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_message \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData type \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupported\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m error_message:\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [38]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m video_path \u001b[38;5;241m=\u001b[39m videofolder \u001b[38;5;241m+\u001b[39m i\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# analyze the video using the pre-trained model\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mdeeplabcut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze_videos\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_as_csv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvideotype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.mp4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdestfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# if you only want csv's than you uncomment the next line instead (note though that the labeling from deeplabcut requires .h5 instead of csv)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# deeplabcut.analyze_videos(config_path, [video_path],save_as_csv=False, videotype='.mp4', destfolder=output_dir)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m deeplabcut\u001b[38;5;241m.\u001b[39mcreate_labeled_video(config_path, [video_path], destfolder\u001b[38;5;241m=\u001b[39moutput_dir)\n",
      "File \u001b[1;32m~\\.conda\\envs\\multimodalmask\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\predict_videos.py:602\u001b[0m, in \u001b[0;36manalyze_videos\u001b[1;34m(config, videos, videotype, shuffle, trainingsetindex, gputouse, save_as_csv, in_random_order, destfolder, batchsize, cropping, TFGPUinference, dynamic, modelprefix, robust_nframes, allow_growth, use_shelve, auto_track, n_tracks, calibrate, identity_only, use_openvino)\u001b[0m\n\u001b[0;32m    598\u001b[0m     sess, inputs, outputs \u001b[38;5;241m=\u001b[39m predict\u001b[38;5;241m.\u001b[39msetup_openvino_pose_prediction(\n\u001b[0;32m    599\u001b[0m         dlc_cfg, device\u001b[38;5;241m=\u001b[39muse_openvino\n\u001b[0;32m    600\u001b[0m     )\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m TFGPUinference:\n\u001b[1;32m--> 602\u001b[0m     sess, inputs, outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_GPUpose_prediction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdlc_cfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_growth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_growth\u001b[49m\n\u001b[0;32m    604\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    606\u001b[0m     sess, inputs, outputs \u001b[38;5;241m=\u001b[39m predict\u001b[38;5;241m.\u001b[39msetup_pose_prediction(\n\u001b[0;32m    607\u001b[0m         dlc_cfg, allow_growth\u001b[38;5;241m=\u001b[39mallow_growth\n\u001b[0;32m    608\u001b[0m     )\n",
      "File \u001b[1;32m~\\.conda\\envs\\multimodalmask\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\core\\predict.py:228\u001b[0m, in \u001b[0;36msetup_GPUpose_prediction\u001b[1;34m(cfg, allow_growth)\u001b[0m\n\u001b[0;32m    225\u001b[0m sess\u001b[38;5;241m.\u001b[39mrun(tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mlocal_variables_initializer())\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# Restore variables from disk.\u001b[39;00m\n\u001b[1;32m--> 228\u001b[0m \u001b[43mrestorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43msess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_weights\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sess, inputs, outputs\n",
      "File \u001b[1;32m~\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1433\u001b[0m, in \u001b[0;36mSaver.restore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1428\u001b[0m   names_to_keys \u001b[38;5;241m=\u001b[39m object_graph_key_mapping(save_path)\n\u001b[0;32m   1429\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError:\n\u001b[0;32m   1430\u001b[0m   \u001b[38;5;66;03m# 2. This is not an object-based checkpoint, which likely means there\u001b[39;00m\n\u001b[0;32m   1431\u001b[0m   \u001b[38;5;66;03m# is a graph mismatch. Re-raise the original error with\u001b[39;00m\n\u001b[0;32m   1432\u001b[0m   \u001b[38;5;66;03m# a helpful message (b/110263146)\u001b[39;00m\n\u001b[1;32m-> 1433\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m _wrap_restore_error_with_msg(\n\u001b[0;32m   1434\u001b[0m       err, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma Variable name or other graph key that is missing\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1436\u001b[0m \u001b[38;5;66;03m# This is an object-based checkpoint. We'll print a warning and then do\u001b[39;00m\n\u001b[0;32m   1437\u001b[0m \u001b[38;5;66;03m# the restore.\u001b[39;00m\n\u001b[0;32m   1438\u001b[0m logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRestoring an object-based checkpoint using a name-based saver. This \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1440\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmay be somewhat fragile, and will re-build the Saver. Instead, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1441\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconsider loading object-based checkpoints using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1442\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.train.Checkpoint().\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nGraph execution error:\n\nDetected at node 'save/RestoreV2' defined at (most recent call last):\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 461, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 450, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in dispatch_shell\n      await result\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 652, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2768, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2814, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3012, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3191, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3251, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\u668173\\AppData\\Local\\Temp\\ipykernel_992\\1381109926.py\", line 5, in <module>\n      deeplabcut.analyze_videos(\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\predict_videos.py\", line 602, in analyze_videos\n      sess, inputs, outputs = predict.setup_GPUpose_prediction(\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\core\\predict.py\", line 215, in setup_GPUpose_prediction\n      restorer = tf.compat.v1.train.Saver()\nNode: 'save/RestoreV2'\nDetected at node 'save/RestoreV2' defined at (most recent call last):\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 461, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 450, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in dispatch_shell\n      await result\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 652, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2768, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2814, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3012, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3191, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3251, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\u668173\\AppData\\Local\\Temp\\ipykernel_992\\1381109926.py\", line 5, in <module>\n      deeplabcut.analyze_videos(\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\predict_videos.py\", line 602, in analyze_videos\n      sess, inputs, outputs = predict.setup_GPUpose_prediction(\n    File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\core\\predict.py\", line 215, in setup_GPUpose_prediction\n      restorer = tf.compat.v1.train.Saver()\nNode: 'save/RestoreV2'\n2 root error(s) found.\n  (0) NOT_FOUND: NewRandomAccessFile failed to Create/Open: ./DLC/trained_model_and_metainfo\\dlc-models\\iteration-0\\Deep_AirSacTrackingV1Jan1-trainset95shuffle1\\train\\snapshot-500000.data-00000-of-00001 : The system cannot find the file specified.\r\n; No such file or directory\n\t [[{{node save/RestoreV2}}]]\n\t [[save/RestoreV2/_79]]\n  (1) NOT_FOUND: NewRandomAccessFile failed to Create/Open: ./DLC/trained_model_and_metainfo\\dlc-models\\iteration-0\\Deep_AirSacTrackingV1Jan1-trainset95shuffle1\\train\\snapshot-500000.data-00000-of-00001 : The system cannot find the file specified.\r\n; No such file or directory\n\t [[{{node save/RestoreV2}}]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'save/RestoreV2':\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n    app.start()\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n    self.io_loop.start()\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n    self._run_once()\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n    handle._run()\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\asyncio\\events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 461, in dispatch_queue\n    await self.process_one()\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 450, in process_one\n    await dispatch(*args)\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in dispatch_shell\n    await result\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 652, in execute_request\n    reply_content = await reply_content\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2768, in run_cell\n    result = self._run_cell(\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2814, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3012, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3191, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3251, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"C:\\Users\\u668173\\AppData\\Local\\Temp\\ipykernel_992\\1381109926.py\", line 5, in <module>\n    deeplabcut.analyze_videos(\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\predict_videos.py\", line 602, in analyze_videos\n    sess, inputs, outputs = predict.setup_GPUpose_prediction(\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\core\\predict.py\", line 215, in setup_GPUpose_prediction\n    restorer = tf.compat.v1.train.Saver()\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 933, in __init__\n    self.build()\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 945, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 973, in _build\n    self.saver_def = self._builder._build_internal(  # pylint: disable=protected-access\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 543, in _build_internal\n    restore_op = self._AddRestoreOps(filename_tensor, saveables,\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 363, in _AddRestoreOps\n    all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 611, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1500, in restore_v2\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 797, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3754, in _create_op_internal\n    ret = Operation(\n  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2133, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n"
     ]
    }
   ],
   "source": [
    "# loop through each video and track using DLC\n",
    "for i in vids:  # add the image folder name to get the full path\n",
    "    video_path = videofolder + i\n",
    "    # analyze the video using the pre-trained model\n",
    "    deeplabcut.analyze_videos(\n",
    "        config_path,\n",
    "        [video_path],\n",
    "        save_as_csv=False,\n",
    "        videotype=\".mp4\",\n",
    "        destfolder=output_dir,\n",
    "    )\n",
    "    # if you only want csv's than you uncomment the next line instead (note though that the labeling from deeplabcut requires .h5 instead of csv)\n",
    "    # deeplabcut.analyze_videos(config_path, [video_path],save_as_csv=False, videotype='.mp4', destfolder=output_dir)\n",
    "    deeplabcut.create_labeled_video(config_path, [video_path], destfolder=output_dir)\n",
    "# convert H5 files to CSV files so you have the data in both extensions\n",
    "deeplabcut.analyze_videos_converth5_to_csv(output_dir, \".mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'example8DLC_resnet101_Deep_AirSacTrackingV1Jan1shuffle1_500000.mp4'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m         stored_video_names\u001b[38;5;241m.\u001b[39mappend(file)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(stored_video_names)):\n\u001b[1;32m----> 7\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstored_video_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./DLC/output/labeled_videos/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvids\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m renaming_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDLC_name:\u001b[39m\u001b[38;5;124m\"\u001b[39m: stored_video_names, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_label\u001b[39m\u001b[38;5;124m\"\u001b[39m: vids})\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have sucessfully renamed your labeled videos. Please do double check if the new labels correspont with the videos:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m )\n",
      "File \u001b[1;32m~\\.conda\\envs\\multimodalmask\\lib\\shutil.py:426\u001b[0m, in \u001b[0;36mcopy\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dst):\n\u001b[0;32m    425\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(src))\n\u001b[1;32m--> 426\u001b[0m \u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    427\u001b[0m copymode(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "File \u001b[1;32m~\\.conda\\envs\\multimodalmask\\lib\\shutil.py:265\u001b[0m, in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 265\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fsrc, \u001b[38;5;28mopen\u001b[39m(dst, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[0;32m    266\u001b[0m             \u001b[38;5;66;03m# macOS\u001b[39;00m\n\u001b[0;32m    267\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m _HAS_FCOPYFILE:\n\u001b[0;32m    268\u001b[0m                 \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'example8DLC_resnet101_Deep_AirSacTrackingV1Jan1shuffle1_500000.mp4'"
     ]
    }
   ],
   "source": [
    "stored_video_names = []\n",
    "for file in os.listdir(output_dir):\n",
    "    if file.endswith(\".mp4\"):\n",
    "        stored_video_names.append(file)\n",
    "\n",
    "for index in range(0, len(stored_video_names)):\n",
    "    shutil.copy(stored_video_names[index], \"./DLC/output/labeled_videos/\" + vids[index])\n",
    "\n",
    "renaming_df = pd.DataFrame({\"DLC_name:\": stored_video_names, \"new_label\": vids})\n",
    "print(\n",
    "    \"You have sucessfully renamed your labeled videos. Please do double check if the new labels correspont with the videos:\"\n",
    ")\n",
    "pprint(renaming_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a labeled video through DLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"./DLC/output/labeled_videos/example8.mp4\" controls  width=\"300\"  height=\"200\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the first video in the set\n",
    "Video(\"./DLC/output/labeled_videos/\" + vids[0], width=300, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from H5 to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E:\\\\AirSacTracker\\\\tk\\\\input\\\\example8.mp4']\n",
      "Found output file for scorer: DLC_resnet101_Deep_AirSacTrackingV1Jan1shuffle1_500000\n",
      "Converting E:\\AirSacTracker\\tk\\module_DLC+\\DLC\\output\\example8DLC_resnet101_Deep_AirSacTrackingV1Jan1shuffle1_500000.h5...\n",
      "All H5 files were converted to CSV.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "inputpath = os.path.abspath(\"../input/\")\n",
    "outputpath = os.path.abspath(\"./DLC/output/\")\n",
    "list_of_files = glob.glob(inputpath + '/*.mp4')\n",
    "print(list_of_files)\n",
    "# the original video needs to be in the same folder as the DLC data\n",
    "for i in list_of_files:\n",
    "    shutil.copyfile(i, outputpath +'/'+ os.path.basename(i))\n",
    "# use deeplabcut function to make .csv from .h5\n",
    "deeplabcut.analyze_videos_converth5_to_csv(outputpath,'.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Circle estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up some functions for circle estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the likelihood the points need to be for considering it for Landau estimation\n",
    "threshold = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimateInitialGuessCircle(XY):\n",
    "    # estimate initial guess for circle LM\n",
    "    x0 = np.mean(XY[\"x\"].values)\n",
    "    y0 = np.mean(XY[\"y\"].values)\n",
    "    r0 = np.mean(\n",
    "        np.sqrt((XY[\"x\"].values ** 2 + x0**2) + (XY[\"y\"].values ** 2 + y0**2))\n",
    "    )\n",
    "    ParIni = [x0, y0, r0]\n",
    "    return ParIni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Landau(XY, ParIni=np.NAN, epsilon=0.0001, IterMax=800):\n",
    "    if np.isnan(ParIni):\n",
    "        ParIni = estimateInitialGuessCircle(XY)\n",
    "    centroidx = np.mean(XY[\"x\"].values)\n",
    "    centroidy = np.mean(XY[\"y\"].values)\n",
    "    centroid = [centroidx, centroidy]\n",
    "    X = XY[\"x\"].values - centroid[0]\n",
    "    Y = XY[\"y\"].values - centroid[1]\n",
    "    centroid = centroid + [0]\n",
    "\n",
    "    ParNew = [a - b for a, b in zip(ParIni, centroid)]\n",
    "\n",
    "    for i in range(0, IterMax + 1):\n",
    "        ParOld = ParNew\n",
    "        Dx = X - ParOld[0]\n",
    "        Dy = Y - ParOld[1]\n",
    "        Dx_squared = Dx * Dx\n",
    "        Dy_squared = Dy * Dy\n",
    "        D = np.sqrt([sum(x) for x in zip(Dx_squared, Dy_squared)])\n",
    "        ParNew = [\n",
    "            -np.mean(Dx / D) * np.mean(D),\n",
    "            -np.mean(Dy / D) * np.mean(D),\n",
    "            np.mean(D),\n",
    "        ]\n",
    "\n",
    "        progress = np.linalg.norm([new - old for new, old in zip(ParNew, ParOld)]) / (\n",
    "            np.linalg.norm(ParOld) + epsilon\n",
    "        )\n",
    "\n",
    "        if progress < epsilon:\n",
    "            break\n",
    "\n",
    "    Par = [sum(x) for x in zip(ParOld, centroid)]\n",
    "\n",
    "    return Par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circle_format(df_sub):\n",
    "    df_all = []\n",
    "    df = pd.DataFrame(columns=[\"x\", \"y\", \"likelihood\", \"frame\"])\n",
    "    for frame in tqdm(range(1, df_sub.shape[0]), desc=\"Processing Frames\"):  # tqdm progress bar\n",
    "        for b in range(1, 6):\n",
    "            end_col = b * 3\n",
    "            start_col = end_col - 3\n",
    "\n",
    "            helper_list = (\n",
    "                df_sub.iloc[frame, start_col:end_col].values.flatten().tolist()\n",
    "            )\n",
    "            helper_list.append(frame)\n",
    "            df.loc[len(df)] = helper_list\n",
    "\n",
    "        df_all.append(df)\n",
    "\n",
    "    return pd.concat(df_all)\n",
    "\n",
    "def data_prep_radius_estim_DLC(data):\n",
    "    ## 01b: main ----\n",
    "\n",
    "    # list of columns needed for circle estimation used later in function\n",
    "    list_airsac_points = [\n",
    "        \"Start_outline_outer_left_x\",\n",
    "        \"Start_outline_outer_left_y\",\n",
    "        \"Start_outline_outer_left_likelihood\",\n",
    "        \"Start_outline_outer_right_x\",\n",
    "        \"Start_outline_outer_right_y\",\n",
    "        \"Start_outline_outer_right_likelihood\",\n",
    "        \"LowestPoint_outline_x\",\n",
    "        \"LowestPoint_outline_y\",\n",
    "        \"LowestPoint_outline_likelihood\",\n",
    "        \"MidLowleft_outline_x\",\n",
    "        \"MidLowleft_outline_y\",\n",
    "        \"MidLowleft_outline_likelihood\",\n",
    "        \"MidLowright_outline_x\",\n",
    "        \"MidLowright_outline_y\",\n",
    "        \"MidLowright_outline_likelihood\",\n",
    "    ]\n",
    "\n",
    "    colnames = []\n",
    "    colnames.append(\"frames\")  # first element is a string frames\n",
    "    for i in range(1, data.shape[1]):\n",
    "        colnames.append(\"_\".join([str(data.iloc[0, i]), str(data.iloc[1, i])]))\n",
    "\n",
    "    data.columns = colnames\n",
    "\n",
    "    df_all = data.iloc[2:, :]\n",
    "\n",
    "    df_sub = df_all.filter(list_airsac_points)\n",
    "    df_sub = df_sub.apply(pd.to_numeric)\n",
    "\n",
    "    circle_format_data = circle_format(df_sub)\n",
    "    return circle_format_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub functions for normalization\n",
    "def nose_eye_normalization(auto_data, min_frames=2, threshold_normalization=0.8):\n",
    "    norm_data = []\n",
    "    list_normalization_points = [\n",
    "        \"Nose_x\",\n",
    "        \"Nose_y\",\n",
    "        \"Nose_likelihood\",\n",
    "        \"EyeBridge_x\",\n",
    "        \"EyeBridge_y\",\n",
    "        \"EyeBridge_likelihood\",\n",
    "    ]\n",
    "\n",
    "    colnames = [\"frames\"]\n",
    "\n",
    "    for i in range(1, auto_data.shape[1]):\n",
    "        colnames.append(\n",
    "            \"_\".join([str(auto_data.iloc[0, i]), str(auto_data.iloc[1, i])])\n",
    "        )\n",
    "\n",
    "    auto_data.columns = colnames\n",
    "\n",
    "    df = auto_data.iloc[2:, :]\n",
    "    df_sub = df.filter(items=list_normalization_points)\n",
    "    df_sub = df_sub.apply(pd.to_numeric)\n",
    "\n",
    "    def euc_dist(xbridge, xnose, ybridge, ynose):\n",
    "        return np.sqrt((xbridge - xnose) ** 2 + (ybridge - ynose) ** 2)\n",
    "\n",
    "    df_sub_normalization = df_sub.loc[\n",
    "        df_sub[\"Nose_likelihood\"] >= threshold_normalization\n",
    "    ]\n",
    "    df_sub_normalization = df_sub_normalization.loc[\n",
    "        df_sub_normalization[\"EyeBridge_likelihood\"] >= threshold_normalization\n",
    "    ]\n",
    "\n",
    "    if df_sub_normalization.shape[0] >= min_frames:\n",
    "        distance = []\n",
    "        total_iterations = df_sub_normalization.shape[0]\n",
    "        for idx in tqdm(range(total_iterations), desc=\"Calculating distances\", unit=\" frames\"):\n",
    "            dist = euc_dist(\n",
    "                df_sub_normalization.iloc[idx][\"EyeBridge_x\"],\n",
    "                df_sub_normalization.iloc[idx][\"Nose_x\"],\n",
    "                df_sub_normalization.iloc[idx][\"EyeBridge_y\"],\n",
    "                df_sub_normalization.iloc[idx][\"Nose_y\"],\n",
    "            )\n",
    "            distance.append(dist)\n",
    "    else:\n",
    "        distance = [np.NAN] * df_sub_normalization.shape[0]\n",
    "\n",
    "    norm_data = np.nanmean(distance)\n",
    "\n",
    "    return norm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  # Import the tqdm library\n",
    "\n",
    "def from_DLC_to_circle_with_progress(input_file_path):\n",
    "    print('working in: ' + input_file_path)\n",
    "    matrix = np.empty((0, 5))\n",
    "    columnnames = [\"radius\", \"x\", \"y\", \"frame\", \"videofile\"]\n",
    "    radius_all = []\n",
    "    normalization_value = pd.DataFrame(\n",
    "        data=np.empty((1, 2)),\n",
    "        columns=[\"normalization_value\", \"videofile\"],\n",
    "    )\n",
    "    radius = pd.DataFrame(columns=columnnames)\n",
    "    print('loading in data')\n",
    "    auto_data = pd.read_csv(input_file_path)\n",
    "    print('data prepping')\n",
    "    data_circle_estimation = data_prep_radius_estim_DLC(data=auto_data)\n",
    "    data_circle_estimation = data_circle_estimation.astype({\"frame\": \"int\"})\n",
    "    grouped_data_circle_estimation = data_circle_estimation.loc[\n",
    "        data_circle_estimation[\"likelihood\"] > threshold\n",
    "    ]\n",
    "    grouped_data_circle_estimation = grouped_data_circle_estimation.groupby(\n",
    "        \"frame\", group_keys=False\n",
    "    )\n",
    "\n",
    "    count_n = 0\n",
    "    \n",
    "    print('landau estimation')\n",
    "    for name, group in tqdm(grouped_data_circle_estimation, total=len(grouped_data_circle_estimation)):\n",
    "        if len(grouped_data_circle_estimation) > 0:\n",
    "            frame_data = group\n",
    "            frame_data = frame_data.drop_duplicates()\n",
    "            if frame_data.shape[0] >= 3:\n",
    "                circles_LAN = Landau(\n",
    "                    frame_data.iloc[:, 0:2],\n",
    "                    ParIni=np.NAN,\n",
    "                    epsilon=1e-06,\n",
    "                    IterMax=500,\n",
    "                )\n",
    "            else:\n",
    "                circles_LAN = [np.NAN, np.NAN, np.NAN, np.NAN]\n",
    "            circles_res = [\n",
    "                circles_LAN[2],\n",
    "                circles_LAN[0],\n",
    "                circles_LAN[1],\n",
    "                count_n,\n",
    "                input_file_path,\n",
    "            ]\n",
    "\n",
    "            radius.loc[len(radius)] = circles_res\n",
    "\n",
    "        count_n += 1\n",
    "    print('normalization')\n",
    "    normalization_value[\"normalization_value\"][0] = nose_eye_normalization(auto_data)\n",
    "    normalization_value[\"videofile\"][0] = input_file_path\n",
    "    \n",
    "    radius_all.append(radius)\n",
    "    radius_all = pd.concat(radius_all)\n",
    "    results_I = [radius_all, normalization_value]\n",
    "    results = pd.merge(results_I[0], results_I[1], how=\"left\", on=\"videofile\")\n",
    "\n",
    "    results[\"norm_radius\"] = pd.to_numeric(\n",
    "        results[\"radius\"] / results[\"normalization_value\"]\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply circle estimation routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "these are the files that you selected to be processed:\n",
      "['./DLC/output\\\\example8DLC_resnet101_Deep_AirSacTrackingV1Jan1shuffle1_500000.csv']\n"
     ]
    }
   ],
   "source": [
    "# apply to sample\n",
    "path = \"./DLC/output/\"\n",
    "path_output = \"./intermediate_output/\"\n",
    "timeseries_folder = \"./intermediate_output/timeseries/\"\n",
    "pattern = \"*.csv\"\n",
    "list_of_files = glob.glob(path + pattern)\n",
    "\n",
    "print(\"these are the files that you selected to be processed:\")\n",
    "pprint(list_of_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working in: ./DLC/output\\example8DLC_resnet101_Deep_AirSacTrackingV1Jan1shuffle1_500000.csv\n",
      "loading in data\n",
      "data prepping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Frames: 100%|| 1194/1194 [00:03<00:00, 339.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "landau estimation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1190/1190 [00:07<00:00, 157.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating distances: 100%|| 1060/1060 [00:00<00:00, 9078.30 frames/s]\n"
     ]
    }
   ],
   "source": [
    "for i in list_of_files:\n",
    "    results = from_DLC_to_circle_with_progress(i)\n",
    "    results.to_csv(path_output + \"/\" + os.path.basename(i) + \"_DLC_toRadii.csv\")\n",
    "    results.to_csv(timeseries_folder + os.path.basename(i) + \".csv\", na_rep=\"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "these are the files that you selected to be processed:\n",
      "working in: H:/SiamangJaderpark_Processed/zoom\\Opp_August_12_Session_1_zoom_syncedboomDLC_resnet101_Deep_AirSacTrackingV1Jan1shuffle1_500000.csv\n",
      "loading in data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\u668173\\AppData\\Local\\Temp\\ipykernel_992\\3465366209.py:16: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  auto_data = pd.read_csv(input_file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data prepping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Frames: 100%|| 65063/65063 [35:10<00:00, 30.83it/s]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 158. GiB for an array with shape (21165969845,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [248]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthese are the files that you selected to be processed:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m list_of_files:\n\u001b[1;32m----> 8\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mfrom_DLC_to_circle_with_progress\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     results\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mH:/SiamangJaderpark_Processed/zoom/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_DLC_toRadii.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[1;32mIn [181]\u001b[0m, in \u001b[0;36mfrom_DLC_to_circle_with_progress\u001b[1;34m(input_file_path)\u001b[0m\n\u001b[0;32m     16\u001b[0m auto_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(input_file_path)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata prepping\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m data_circle_estimation \u001b[38;5;241m=\u001b[39m \u001b[43mdata_prep_radius_estim_DLC\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m data_circle_estimation \u001b[38;5;241m=\u001b[39m data_circle_estimation\u001b[38;5;241m.\u001b[39mastype({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m     20\u001b[0m grouped_data_circle_estimation \u001b[38;5;241m=\u001b[39m data_circle_estimation\u001b[38;5;241m.\u001b[39mloc[\n\u001b[0;32m     21\u001b[0m     data_circle_estimation[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlikelihood\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m threshold\n\u001b[0;32m     22\u001b[0m ]\n",
      "Input \u001b[1;32mIn [244]\u001b[0m, in \u001b[0;36mdata_prep_radius_estim_DLC\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     50\u001b[0m df_sub \u001b[38;5;241m=\u001b[39m df_all\u001b[38;5;241m.\u001b[39mfilter(list_airsac_points)\n\u001b[0;32m     51\u001b[0m df_sub \u001b[38;5;241m=\u001b[39m df_sub\u001b[38;5;241m.\u001b[39mapply(pd\u001b[38;5;241m.\u001b[39mto_numeric)\n\u001b[1;32m---> 53\u001b[0m circle_format_data \u001b[38;5;241m=\u001b[39m \u001b[43mcircle_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_sub\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m circle_format_data\n",
      "Input \u001b[1;32mIn [244]\u001b[0m, in \u001b[0;36mcircle_format\u001b[1;34m(df_sub)\u001b[0m\n\u001b[0;32m     13\u001b[0m         df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mlen\u001b[39m(df)] \u001b[38;5;241m=\u001b[39m helper_list\n\u001b[0;32m     15\u001b[0m     df_all\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_all\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\multimodalmask\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:372\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcat\u001b[39m(\n\u001b[0;32m    148\u001b[0m     objs: Iterable[NDFrame] \u001b[38;5;241m|\u001b[39m Mapping[HashableT, NDFrame],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m     copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    158\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m    159\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03m    Concatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;124;03m    1   3   4\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    368\u001b[0m     op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    369\u001b[0m         objs,\n\u001b[0;32m    370\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    371\u001b[0m         ignore_index\u001b[38;5;241m=\u001b[39mignore_index,\n\u001b[1;32m--> 372\u001b[0m         join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[0;32m    373\u001b[0m         keys\u001b[38;5;241m=\u001b[39mkeys,\n\u001b[0;32m    374\u001b[0m         levels\u001b[38;5;241m=\u001b[39mlevels,\n\u001b[0;32m    375\u001b[0m         names\u001b[38;5;241m=\u001b[39mnames,\n\u001b[0;32m    376\u001b[0m         verify_integrity\u001b[38;5;241m=\u001b[39mverify_integrity,\n\u001b[0;32m    377\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    378\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    379\u001b[0m     )\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\.conda\\envs\\multimodalmask\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:563\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[1;32m--> 563\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_new_axes()\n",
      "File \u001b[1;32m~\\.conda\\envs\\multimodalmask\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:633\u001b[0m, in \u001b[0;36m_Concatenator._get_new_axes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_new_axes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Index]:\n\u001b[0;32m    632\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_result_dim()\n\u001b[1;32m--> 633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_concat_axis \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_comb_axis(i)\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ndim)\n\u001b[0;32m    636\u001b[0m     ]\n",
      "File \u001b[1;32m~\\.conda\\envs\\multimodalmask\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:634\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_new_axes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Index]:\n\u001b[0;32m    632\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_result_dim()\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m--> 634\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concat_axis\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_comb_axis(i)\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ndim)\n\u001b[0;32m    636\u001b[0m     ]\n",
      "File \u001b[1;32m~\\.conda\\envs\\multimodalmask\\lib\\site-packages\\pandas\\_libs\\properties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\.conda\\envs\\multimodalmask\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:691\u001b[0m, in \u001b[0;36m_Concatenator._get_concat_axis\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    689\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlevels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    690\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlevels supported only when keys is not None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 691\u001b[0m     concat_axis \u001b[38;5;241m=\u001b[39m \u001b[43m_concat_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    693\u001b[0m     concat_axis \u001b[38;5;241m=\u001b[39m _make_concat_multiindex(\n\u001b[0;32m    694\u001b[0m         indexes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlevels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames\n\u001b[0;32m    695\u001b[0m     )\n",
      "File \u001b[1;32m~\\.conda\\envs\\multimodalmask\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:709\u001b[0m, in \u001b[0;36m_concat_indexes\u001b[1;34m(indexes)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_concat_indexes\u001b[39m(indexes) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[1;32m--> 709\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mindexes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\multimodalmask\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5258\u001b[0m, in \u001b[0;36mappend\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   5254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__contains__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m   5255\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5256\u001b[0m \u001b[38;5;124;03m    Return a boolean indicating whether the provided key is in the index.\u001b[39;00m\n\u001b[0;32m   5257\u001b[0m \n\u001b[1;32m-> 5258\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   5259\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[0;32m   5260\u001b[0m \u001b[38;5;124;03m    key : label\u001b[39;00m\n\u001b[0;32m   5261\u001b[0m \u001b[38;5;124;03m        The key to check if it is present in the index.\u001b[39;00m\n\u001b[0;32m   5262\u001b[0m \n\u001b[0;32m   5263\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[0;32m   5264\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[0;32m   5265\u001b[0m \u001b[38;5;124;03m    bool\u001b[39;00m\n\u001b[0;32m   5266\u001b[0m \u001b[38;5;124;03m        Whether the key search is in the index.\u001b[39;00m\n\u001b[0;32m   5267\u001b[0m \n\u001b[0;32m   5268\u001b[0m \u001b[38;5;124;03m    Raises\u001b[39;00m\n\u001b[0;32m   5269\u001b[0m \u001b[38;5;124;03m    ------\u001b[39;00m\n\u001b[0;32m   5270\u001b[0m \u001b[38;5;124;03m    TypeError\u001b[39;00m\n\u001b[0;32m   5271\u001b[0m \u001b[38;5;124;03m        If the key is not hashable.\u001b[39;00m\n\u001b[0;32m   5272\u001b[0m \n\u001b[0;32m   5273\u001b[0m \u001b[38;5;124;03m    See Also\u001b[39;00m\n\u001b[0;32m   5274\u001b[0m \u001b[38;5;124;03m    --------\u001b[39;00m\n\u001b[0;32m   5275\u001b[0m \u001b[38;5;124;03m    Index.isin : Returns an ndarray of boolean dtype indicating whether the\u001b[39;00m\n\u001b[0;32m   5276\u001b[0m \u001b[38;5;124;03m        list-like key is in the index.\u001b[39;00m\n\u001b[0;32m   5277\u001b[0m \n\u001b[0;32m   5278\u001b[0m \u001b[38;5;124;03m    Examples\u001b[39;00m\n\u001b[0;32m   5279\u001b[0m \u001b[38;5;124;03m    --------\u001b[39;00m\n\u001b[0;32m   5280\u001b[0m \u001b[38;5;124;03m    >>> idx = pd.Index([1, 2, 3, 4])\u001b[39;00m\n\u001b[0;32m   5281\u001b[0m \u001b[38;5;124;03m    >>> idx\u001b[39;00m\n\u001b[0;32m   5282\u001b[0m \u001b[38;5;124;03m    Int64Index([1, 2, 3, 4], dtype='int64')\u001b[39;00m\n\u001b[0;32m   5283\u001b[0m \n\u001b[0;32m   5284\u001b[0m \u001b[38;5;124;03m    >>> 2 in idx\u001b[39;00m\n\u001b[0;32m   5285\u001b[0m \u001b[38;5;124;03m    True\u001b[39;00m\n\u001b[0;32m   5286\u001b[0m \u001b[38;5;124;03m    >>> 6 in idx\u001b[39;00m\n\u001b[0;32m   5287\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[0;32m   5288\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   5289\u001b[0m     \u001b[38;5;28mhash\u001b[39m(key)\n\u001b[0;32m   5290\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\.conda\\envs\\multimodalmask\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5266\u001b[0m, in \u001b[0;36m_concat\u001b[1;34m(self, to_concat, name)\u001b[0m\n\u001b[0;32m   5254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__contains__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m   5255\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5256\u001b[0m \u001b[38;5;124;03m    Return a boolean indicating whether the provided key is in the index.\u001b[39;00m\n\u001b[0;32m   5257\u001b[0m \n\u001b[0;32m   5258\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   5259\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[0;32m   5260\u001b[0m \u001b[38;5;124;03m    key : label\u001b[39;00m\n\u001b[0;32m   5261\u001b[0m \u001b[38;5;124;03m        The key to check if it is present in the index.\u001b[39;00m\n\u001b[0;32m   5262\u001b[0m \n\u001b[0;32m   5263\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[0;32m   5264\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[0;32m   5265\u001b[0m \u001b[38;5;124;03m    bool\u001b[39;00m\n\u001b[1;32m-> 5266\u001b[0m \u001b[38;5;124;03m        Whether the key search is in the index.\u001b[39;00m\n\u001b[0;32m   5267\u001b[0m \n\u001b[0;32m   5268\u001b[0m \u001b[38;5;124;03m    Raises\u001b[39;00m\n\u001b[0;32m   5269\u001b[0m \u001b[38;5;124;03m    ------\u001b[39;00m\n\u001b[0;32m   5270\u001b[0m \u001b[38;5;124;03m    TypeError\u001b[39;00m\n\u001b[0;32m   5271\u001b[0m \u001b[38;5;124;03m        If the key is not hashable.\u001b[39;00m\n\u001b[0;32m   5272\u001b[0m \n\u001b[0;32m   5273\u001b[0m \u001b[38;5;124;03m    See Also\u001b[39;00m\n\u001b[0;32m   5274\u001b[0m \u001b[38;5;124;03m    --------\u001b[39;00m\n\u001b[0;32m   5275\u001b[0m \u001b[38;5;124;03m    Index.isin : Returns an ndarray of boolean dtype indicating whether the\u001b[39;00m\n\u001b[0;32m   5276\u001b[0m \u001b[38;5;124;03m        list-like key is in the index.\u001b[39;00m\n\u001b[0;32m   5277\u001b[0m \n\u001b[0;32m   5278\u001b[0m \u001b[38;5;124;03m    Examples\u001b[39;00m\n\u001b[0;32m   5279\u001b[0m \u001b[38;5;124;03m    --------\u001b[39;00m\n\u001b[0;32m   5280\u001b[0m \u001b[38;5;124;03m    >>> idx = pd.Index([1, 2, 3, 4])\u001b[39;00m\n\u001b[0;32m   5281\u001b[0m \u001b[38;5;124;03m    >>> idx\u001b[39;00m\n\u001b[0;32m   5282\u001b[0m \u001b[38;5;124;03m    Int64Index([1, 2, 3, 4], dtype='int64')\u001b[39;00m\n\u001b[0;32m   5283\u001b[0m \n\u001b[0;32m   5284\u001b[0m \u001b[38;5;124;03m    >>> 2 in idx\u001b[39;00m\n\u001b[0;32m   5285\u001b[0m \u001b[38;5;124;03m    True\u001b[39;00m\n\u001b[0;32m   5286\u001b[0m \u001b[38;5;124;03m    >>> 6 in idx\u001b[39;00m\n\u001b[0;32m   5287\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[0;32m   5288\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   5289\u001b[0m     \u001b[38;5;28mhash\u001b[39m(key)\n\u001b[0;32m   5290\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\.conda\\envs\\multimodalmask\\lib\\site-packages\\pandas\\core\\dtypes\\concat.py:117\u001b[0m, in \u001b[0;36mconcat_compat\u001b[1;34m(to_concat, axis, ea_compat_axis)\u001b[0m\n\u001b[0;32m    115\u001b[0m all_empty \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(non_empties)\n\u001b[0;32m    116\u001b[0m single_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m({x\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m to_concat}) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 117\u001b[0m any_ea \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m to_concat)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m contains_datetime:\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _concat_datetime(to_concat, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 158. GiB for an array with shape (21165969845,) and data type int64"
     ]
    }
   ],
   "source": [
    "# Running this on the entire siamang dataset (we can delete after)\n",
    "pattern = \"*.csv\"\n",
    "list_of_files = glob.glob('H:/SiamangJaderpark_Processed/zoom/' + pattern)\n",
    "\n",
    "for i in list_of_files:\n",
    "    results = from_DLC_to_circle_with_progress(input_file_path=i)\n",
    "    results.to_csv('H:/SiamangJaderpark_Processed/zoom/' + os.path.basename(i) + \"_DLC_toRadii.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on video: example8\n",
      "We are all done, go look into your output folder: E:\\AirSacTracker\\tk\\module_DLC+\\output\n"
     ]
    }
   ],
   "source": [
    "tsfol = \"./intermediate_output/timeseries/\"  # this is where your timeseries are with the same name as the complementary video\n",
    "vidfol = \"./DLC/output/labeled_videos/\"  # this is where the original videos are\n",
    "outfol = \"./output/\"  # this is where you can collect your output\n",
    "toprocess = os.listdir(tsfol)  # list all the time series files\n",
    "\n",
    "for tt in toprocess:\n",
    "    ts = pd.read_csv(tsfol + tt)  # get the time series\n",
    "    idname = tt[0 : len(tt) - 4]  # remove the .csv\n",
    "    vidloc = vidfol + idname + \".mp4\"  # add mp4 (we assume we only process mp4s!)\n",
    "    cap = cv2.VideoCapture(vidloc)  # open the video\n",
    "    frameWidth = cap.get(\n",
    "        cv2.CAP_PROP_FRAME_WIDTH\n",
    "    )  # get the framewidth, and use it for the new video\n",
    "    frameHeight = cap.get(\n",
    "        cv2.CAP_PROP_FRAME_HEIGHT\n",
    "    )  # get the framewidth, and use it for the new video\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)  # fps = frames per second\n",
    "    # what should we write to?\n",
    "    out = cv2.VideoWriter(\n",
    "        outfol + idname + \"_circle.mp4\",\n",
    "        cv2.VideoWriter_fourcc(*\"MP4V\"),\n",
    "        fps,\n",
    "        (int(frameWidth), int(frameHeight)),\n",
    "    )\n",
    "    print(\"working on video: \" + idname)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "        frame_number = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "\n",
    "        index_var = (\n",
    "            ts[\"frame\"] == frame_number\n",
    "        )  # get the index of the timeseries for the current frame number\n",
    "        dat = ts.loc[index_var, :]  # get the slice of data for this frame\n",
    "        for index, row in dat.iterrows():\n",
    "            if (\n",
    "                math.isnan(row[\"radius\"]) == False\n",
    "            ):  # only draw a circle when there a no NaN's\n",
    "                cv2.circle(\n",
    "                    frame,\n",
    "                    (int(row[\"x\"]), int(row[\"y\"])),\n",
    "                    int(row[\"radius\"]),\n",
    "                    (200, 0, 0),\n",
    "                    2,\n",
    "                )  # draw circle\n",
    "        out.write(frame)  # save it into a new frame\n",
    "\n",
    "# cleaning up\n",
    "out.release()  # release the output video\n",
    "cap.release()  # release the original video\n",
    "print(\n",
    "    \"We are all done, go look into your output folder: \" + str(os.path.abspath(outfol))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running this on the entire siamang\n",
    "\n",
    "tsfol = \"H:/SiamangJaderpark_Processed/zoom/\"  # this is where your timeseries are with the same name as the complementary video\n",
    "vidfol = \"H:/SiamangJaderpark_Processed/zoom/\"   # this is where the original videos are\n",
    "outfol = \"H:/SiamangJaderpark_Processed/zoom/\"  # this is where you can collect your output\n",
    "\n",
    "toprocess = glob.glob(path +_DLC_toRadii.csv)\n",
    "for tt in toprocess:\n",
    "    ts = pd.read_csv(tt)  # get the time series\n",
    "    idname = tt[0 : len(tt) - 4]  # remove the .csv\n",
    "    vidloc = vidfol + idname + \".mp4\"  # add mp4 (we assume we only process mp4s!)\n",
    "    cap = cv2.VideoCapture(vidloc)  # open the video\n",
    "    frameWidth = cap.get(\n",
    "        cv2.CAP_PROP_FRAME_WIDTH\n",
    "    )  # get the framewidth, and use it for the new video\n",
    "    frameHeight = cap.get(\n",
    "        cv2.CAP_PROP_FRAME_HEIGHT\n",
    "    )  # get the framewidth, and use it for the new video\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)  # fps = frames per second\n",
    "    # what should we write to?\n",
    "    out = cv2.VideoWriter(\n",
    "        outfol + idname + \"_circle.mp4\",\n",
    "        cv2.VideoWriter_fourcc(*\"MP4V\"),\n",
    "        fps,\n",
    "        (int(frameWidth), int(frameHeight)),\n",
    "    )\n",
    "    print(\"working on video: \" + idname)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "        frame_number = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "\n",
    "        index_var = (\n",
    "            ts[\"frame\"] == frame_number\n",
    "        )  # get the index of the timeseries for the current frame number\n",
    "        dat = ts.loc[index_var, :]  # get the slice of data for this frame\n",
    "        for index, row in dat.iterrows():\n",
    "            if (\n",
    "                math.isnan(row[\"radius\"]) == False\n",
    "            ):  # only draw a circle when there a no NaN's\n",
    "                cv2.circle(\n",
    "                    frame,\n",
    "                    (int(row[\"x\"]), int(row[\"y\"])),\n",
    "                    int(row[\"radius\"]),\n",
    "                    (200, 0, 0),\n",
    "                    2,\n",
    "                )  # draw circle\n",
    "        out.write(frame)  # save it into a new frame\n",
    "\n",
    "# cleaning up\n",
    "out.release()  # release the output video\n",
    "cap.release()  # release the original video\n",
    "print(\n",
    "    \"We are all done, go look into your output folder: \" + str(os.path.abspath(outfol))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
