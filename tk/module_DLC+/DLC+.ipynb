{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module to process video DLC model\n",
    "\n",
    "This module belongs to the manuscript \"Burchardt, L., Van de Sande, Y., Kehy, M., Gamba, M., Ravignani, A., Pouw, W. A complete computational and data toolkit for the dynamic study of laryngeal air sacs in Siamang (Symphalangus syndactylus) with applications for spherical tracking in other animals\".\n",
    "\n",
    "This contains a module for tracking Siamang head and air sack postures. The following keypoints will be tracked by a trained resnet 101 model:\n",
    "- UpperLip\n",
    "- LowerLip\n",
    "- Nose\n",
    "- EyeBridge\n",
    "- Start_outline_outer_left\n",
    "- Start_outline_outer_right\n",
    "- LowestPoint_outline\n",
    "- MidLowleft_outline\n",
    "- MidLowright_outline\n",
    "\n",
    "Note that Deeplabcut needs to be installed (in command prompt \"pip install -r requirements.txt\"). By default the CPU version is installed. Please see the original documentation of DeepLabCut to ensure GPU compatibility if you want to speed up the tracking process. We do recommend to use a GPU supported deeplabcut.\n",
    "\n",
    "The trained resnet101 model needs to be downloaded first from google drive; so please go to the following folder and follow the download link and download to that folder: \"./AirSacTracker/Toolkit/module_process_video_DLC_model/trained_model_and_metainfo/dlc-models/iteration-0/Deep_AirSacTrackingV1Jan1-trainset95shuffle1/train/\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in all the packages needed:\n",
    "\n",
    "# processing the videos with deeplabcut:\n",
    "import deeplabcut\n",
    "import os\n",
    "import shutil\n",
    "from os.path import isfile, join\n",
    "from IPython.display import Video\n",
    "\n",
    "# performing a circle estimation with Landau algorithm:\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "# plot landau circles on processed video:\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import cv2\n",
    "import shutil\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: processing your video with DLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pre-trained model settings\n",
    "config_path = \"./DLC/trained_model_and_metainfo/config.yaml\"\n",
    "\n",
    "# where are we going to save our tracked results to?\n",
    "output_dir = \"./DLC/output/\"\n",
    "\n",
    "# set videofolder from which we are going to process\n",
    "videofolder = \"../input/\"\n",
    "\n",
    "# loading in the videos\n",
    "vids = [f for f in os.listdir(videofolder) if isfile(join(videofolder, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"/Users/dlc/Documents/onderzoek/AirSacTracker/tk/input/example8.mp4\" controls  width=\"300\"  height=\"200\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the first video in the set\n",
    "Video(videofolder + vids[0], width=300, height=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through each video and track using DLC\n",
    "for i in vids:  # add the image folder name to get the full path\n",
    "    video_path = videofolder + i\n",
    "    # analyze the video using the pre-trained model\n",
    "    deeplabcut.analyze_videos(\n",
    "        config_path,\n",
    "        [video_path],\n",
    "        save_as_csv=True,\n",
    "        videotype=\".mp4\",\n",
    "        destfolder=output_dir,\n",
    "    )\n",
    "    # if you only want csv's than you uncomment the next line instead (note though that the labeling from deeplabcut requires .h5 instead of csv)\n",
    "    # deeplabcut.analyze_videos(config_path, [video_path],save_as_csv=False, videotype='.mp4', destfolder=output_dir)\n",
    "    deeplabcut.create_labeled_video(config_path, [video_path], destfolder=output_dir)\n",
    "# convert H5 files to CSV files so you have the data in both extensions\n",
    "deeplabcut.analyze_videos_converth5_to_csv(output_dir, \".mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored_video_names = []\n",
    "for file in os.listdir(output_dir):\n",
    "    if file.endswith(\".mp4\"):\n",
    "        stored_video_names.append(file)\n",
    "\n",
    "for index in range(0, len(stored_video_names)):\n",
    "    shutil.copy(stored_video_names[index], \"./DLC/output/labeled_videos/\" + vids[index])\n",
    "\n",
    "renaming_df = pd.DataFrame({\"DLC_name:\": stored_video_names, \"new_label\": vids})\n",
    "print(\n",
    "    \"You have sucessfully renamed your labeled videos. Please do double check if the new labels correspont with the videos:\"\n",
    ")\n",
    "pprint(renaming_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a labeled video through DLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the first video in the set\n",
    "Video(\"./DLC/output/labeled_videos/\" + vids[0], width=300, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Circle estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data:\n",
    "\n",
    "savename = \"example8\"\n",
    "path = \"./DLC/output/\"\n",
    "path_output = \"./intermediate_output/\"\n",
    "timeseries_folder = \"./intermediate_output/timeseries/\"\n",
    "pattern = \"*.csv\"\n",
    "list_of_files = glob.glob(path + pattern)\n",
    "\n",
    "print(\"these are the files that you selected to be processed:\")\n",
    "pprint(list_of_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "\n",
    "threshold = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimateInitialGuessCircle(XY):\n",
    "    # estimate initial guess for circle LM\n",
    "    x0 = np.mean(XY[\"x\"].values)\n",
    "    y0 = np.mean(XY[\"y\"].values)\n",
    "    r0 = np.mean(\n",
    "        np.sqrt((XY[\"x\"].values ** 2 + x0**2) + (XY[\"y\"].values ** 2 + y0**2))\n",
    "    )\n",
    "    ParIni = [x0, y0, r0]\n",
    "    return ParIni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Landau(XY, ParIni=np.NAN, epsilon=0.0001, IterMax=800):\n",
    "    if np.isnan(ParIni):\n",
    "        ParIni = estimateInitialGuessCircle(XY)\n",
    "\n",
    "    centroidx = np.mean(XY[\"x\"].values)\n",
    "    centroidy = np.mean(XY[\"y\"].values)\n",
    "    centroid = [centroidx, centroidy]\n",
    "    X = XY[\"x\"].values - centroid[0]\n",
    "    Y = XY[\"y\"].values - centroid[1]\n",
    "    centroid = centroid + [0]\n",
    "\n",
    "    ParNew = [a - b for a, b in zip(ParIni, centroid)]\n",
    "\n",
    "    for i in range(0, IterMax + 1):\n",
    "        ParOld = ParNew\n",
    "        Dx = X - ParOld[0]\n",
    "        Dy = Y - ParOld[1]\n",
    "        Dx_squared = Dx * Dx\n",
    "        Dy_squared = Dy * Dy\n",
    "        D = np.sqrt([sum(x) for x in zip(Dx_squared, Dy_squared)])\n",
    "        ParNew = [\n",
    "            -np.mean(Dx / D) * np.mean(D),\n",
    "            -np.mean(Dy / D) * np.mean(D),\n",
    "            np.mean(D),\n",
    "        ]\n",
    "\n",
    "        progress = np.linalg.norm([new - old for new, old in zip(ParNew, ParOld)]) / (\n",
    "            np.linalg.norm(ParOld) + epsilon\n",
    "        )\n",
    "\n",
    "        if progress < epsilon:\n",
    "            break\n",
    "\n",
    "    Par = [sum(x) for x in zip(ParOld, centroid)]\n",
    "\n",
    "    return Par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep_radius_estim_DLC(data):\n",
    "    def circle_format(df_sub):\n",
    "        df_all = []\n",
    "\n",
    "        df = pd.DataFrame(columns=[\"x\", \"y\", \"likelihood\", \"frame\"])\n",
    "        for frame in range(1, df_sub.shape[0]):  # hier kan een .unique() flag achter\n",
    "            for b in range(\n",
    "                1, 6\n",
    "            ):  # R starts with 1 but is inclusive in endpoint, range in Python is exclusive on endpoint\n",
    "                end_col = b * 3\n",
    "                start_col = end_col - 3\n",
    "\n",
    "                helper_list = (\n",
    "                    df_sub.iloc[frame, start_col:end_col].values.flatten().tolist()\n",
    "                )\n",
    "                helper_list.append(frame)\n",
    "                df.loc[len(df)] = helper_list  # add data in row b in dataframe\n",
    "\n",
    "            df_all.append(df)\n",
    "\n",
    "        return pd.concat(df_all)\n",
    "\n",
    "    ## 01b: main ----\n",
    "\n",
    "    # list of columns needed for circle estimation used later in function\n",
    "    list_airsac_points = [\n",
    "        \"Start_outline_outer_left_x\",\n",
    "        \"Start_outline_outer_left_y\",\n",
    "        \"Start_outline_outer_left_likelihood\",\n",
    "        \"Start_outline_outer_right_x\",\n",
    "        \"Start_outline_outer_right_y\",\n",
    "        \"Start_outline_outer_right_likelihood\",\n",
    "        \"LowestPoint_outline_x\",\n",
    "        \"LowestPoint_outline_y\",\n",
    "        \"LowestPoint_outline_likelihood\",\n",
    "        \"MidLowleft_outline_x\",\n",
    "        \"MidLowleft_outline_y\",\n",
    "        \"MidLowleft_outline_likelihood\",\n",
    "        \"MidLowright_outline_x\",\n",
    "        \"MidLowright_outline_y\",\n",
    "        \"MidLowright_outline_likelihood\",\n",
    "    ]\n",
    "\n",
    "    colnames = []\n",
    "    colnames.append(\"frames\")  # first element is a string frames\n",
    "    for i in range(1, data.shape[1]):\n",
    "        colnames.append(\"_\".join([str(data.iloc[0, i]), str(data.iloc[1, i])]))\n",
    "\n",
    "    data.columns = colnames\n",
    "\n",
    "    df_all = data.iloc[2:, :]\n",
    "\n",
    "    df_sub = df_all.filter(list_airsac_points)\n",
    "    df_sub = df_sub.apply(pd.to_numeric)\n",
    "\n",
    "    circle_format_data = circle_format(df_sub)\n",
    "    return circle_format_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub functions for normalization\n",
    "\n",
    "\n",
    "def nose_eye_normalization(auto_data, min_frames=2, threshold_normalization=0.8):\n",
    "    norm_data = []\n",
    "    list_normalization_points = [\n",
    "        \"Nose_x\",\n",
    "        \"Nose_y\",\n",
    "        \"Nose_likelihood\",\n",
    "        \"EyeBridge_x\",\n",
    "        \"EyeBridge_y\",\n",
    "        \"EyeBridge_likelihood\",\n",
    "    ]\n",
    "\n",
    "    colnames = [\"frames\"]\n",
    "\n",
    "    for i in range(1, auto_data.shape[1]):\n",
    "        colnames.append(\n",
    "            \"_\".join([str(auto_data.iloc[0, i]), str(auto_data.iloc[1, i])])\n",
    "        )\n",
    "\n",
    "    auto_data.columns = colnames\n",
    "\n",
    "    df = auto_data.iloc[2:, :]\n",
    "    df_sub = df.filter(items=list_normalization_points)\n",
    "    df_sub = df_sub.apply(pd.to_numeric)\n",
    "\n",
    "    def euc_dist(xbridge, xnose, ybridge, ynose):\n",
    "        return np.sqrt((xbridge - xnose) ** 2 + (ybridge - ynose) ** 2)\n",
    "\n",
    "    df_sub_normalization = df_sub.loc[\n",
    "        df_sub[\"Nose_likelihood\"] >= threshold_normalization\n",
    "    ]\n",
    "    df_sub_normalization = df_sub_normalization.loc[\n",
    "        df_sub_normalization[\"EyeBridge_likelihood\"] >= threshold_normalization\n",
    "    ]\n",
    "\n",
    "    if df_sub_normalization.shape[0] >= min_frames:\n",
    "        distance = [\n",
    "            euc_dist(\n",
    "                df_sub_normalization[\"EyeBridge_x\"],\n",
    "                df_sub_normalization[\"Nose_x\"],\n",
    "                df_sub_normalization[\"EyeBridge_y\"],\n",
    "                df_sub_normalization[\"Nose_y\"],\n",
    "            )\n",
    "            for i in range(0, df_sub_normalization.shape[0])\n",
    "        ]\n",
    "    else:\n",
    "        distance = np.NAN\n",
    "\n",
    "    norm_data = np.nanmean(distance)\n",
    "\n",
    "    return norm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_DLC_to_circle(path, list_of_files):\n",
    "    matrix = np.empty((0, 5))\n",
    "    columnnames = [\"radius\", \"x\", \"y\", \"frame\", \"videofile\"]\n",
    "    # radius_all = pd.DataFrame(matrix, columns= columnnames)\n",
    "    radius_all = []\n",
    "    normalization_value = pd.DataFrame(\n",
    "        data=np.empty((len(list_of_files), 2)),\n",
    "        columns=[\"normalization_value\", \"videofile\"],\n",
    "    )\n",
    "\n",
    "    for file in range(0, len(list_of_files)):\n",
    "        radius = pd.DataFrame(columns=columnnames)\n",
    "\n",
    "        auto_data = pd.read_csv(list_of_files[file])\n",
    "\n",
    "        data_circle_estimation = data_prep_radius_estim_DLC(data=auto_data)\n",
    "        data_circle_estimation = data_circle_estimation.astype({\"frame\": \"int\"})\n",
    "        grouped_data_circle_estimation = data_circle_estimation.loc[\n",
    "            data_circle_estimation[\"likelihood\"] > threshold\n",
    "        ]\n",
    "        grouped_data_circle_estimation = grouped_data_circle_estimation.groupby(\n",
    "            \"frame\", group_keys=False\n",
    "        )\n",
    "\n",
    "        count_n = 0\n",
    "        for name, group in grouped_data_circle_estimation:\n",
    "            if len(grouped_data_circle_estimation) > 0:\n",
    "                frame_data = group\n",
    "                frame_data = frame_data.drop_duplicates()\n",
    "                if frame_data.shape[0] >= 3:\n",
    "                    circles_LAN = Landau(\n",
    "                        frame_data.iloc[:, 0:2],\n",
    "                        ParIni=np.NAN,\n",
    "                        epsilon=1e-06,\n",
    "                        IterMax=500,\n",
    "                    )\n",
    "                else:\n",
    "                    circles_LAN = [np.NAN, np.NAN, np.NAN, np.NAN]\n",
    "                circles_res = [\n",
    "                    circles_LAN[2],\n",
    "                    circles_LAN[0],\n",
    "                    circles_LAN[1],\n",
    "                    count_n,\n",
    "                    list_of_files[file],\n",
    "                ]\n",
    "\n",
    "                radius.loc[len(radius)] = circles_res\n",
    "\n",
    "            count_n += 1\n",
    "        radius_all.append(radius)\n",
    "        normalization_value[\"normalization_value\"][file] = nose_eye_normalization(\n",
    "            auto_data\n",
    "        )\n",
    "        normalization_value[\"videofile\"][file] = list_of_files[file]\n",
    "    radius_all = pd.concat(radius_all)\n",
    "    results_I = [radius_all, normalization_value]\n",
    "    results = pd.merge(results_I[0], results_I[1], how=\"left\", on=\"videofile\")\n",
    "\n",
    "    results[\"norm_radius\"] = pd.to_numeric(\n",
    "        results[\"radius\"] / results[\"normalization_value\"]\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = from_DLC_to_circle(path=path, list_of_files=list_of_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(path_output + \"/\" + savename + \"_DLC_toRadii.csv\")\n",
    "results.to_csv(timeseries_folder + savename + \".csv\", na_rep=\"NA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfol = \"./intermediate_output/timeseries/\"  # this is where your timeseries are with the same name as the complementary video\n",
    "vidfol = \"./DLC/output/labeled_videos/\"  # this is where the original videos are\n",
    "outfol = \"./output/\"  # this is where you can collect your output\n",
    "toprocess = os.listdir(tsfol)  # list all the time series files\n",
    "\n",
    "for tt in toprocess:\n",
    "    ts = pd.read_csv(tsfol + tt)  # get the time series\n",
    "    idname = tt[0 : len(tt) - 4]  # remove the .csv\n",
    "    vidloc = vidfol + idname + \".mp4\"  # add mp4 (we assume we only process mp4s!)\n",
    "    cap = cv2.VideoCapture(vidloc)  # open the video\n",
    "    frameWidth = cap.get(\n",
    "        cv2.CAP_PROP_FRAME_WIDTH\n",
    "    )  # get the framewidth, and use it for the new video\n",
    "    frameHeight = cap.get(\n",
    "        cv2.CAP_PROP_FRAME_HEIGHT\n",
    "    )  # get the framewidth, and use it for the new video\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)  # fps = frames per second\n",
    "    # what should we write to?\n",
    "    out = cv2.VideoWriter(\n",
    "        outfol + idname + \"_circle.mp4\",\n",
    "        cv2.VideoWriter_fourcc(*\"MP4V\"),\n",
    "        fps,\n",
    "        (int(frameWidth), int(frameHeight)),\n",
    "    )\n",
    "    print(\"working on video: \" + idname)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "        frame_number = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "\n",
    "        index_var = (\n",
    "            ts[\"frame\"] == frame_number\n",
    "        )  # get the index of the timeseries for the current frame number\n",
    "        dat = ts.loc[index_var, :]  # get the slice of data for this frame\n",
    "        for index, row in dat.iterrows():\n",
    "            if (\n",
    "                math.isnan(row[\"radius\"]) == False\n",
    "            ):  # only draw a circle when there a no NaN's\n",
    "                cv2.circle(\n",
    "                    frame,\n",
    "                    (int(row[\"x\"]), int(row[\"y\"])),\n",
    "                    int(row[\"radius\"]),\n",
    "                    (200, 0, 0),\n",
    "                    2,\n",
    "                )  # draw circle\n",
    "        out.write(frame)  # save it into a new frame\n",
    "\n",
    "# cleaning up\n",
    "out.release()  # release the output video\n",
    "cap.release()  # release the original video\n",
    "print(\n",
    "    \"We are all done, go look into your output folder: \" + str(os.path.abspath(outfol))\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEEPLABCUT_M1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
